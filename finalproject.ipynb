{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "first-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bridal-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def torch_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "torch_device = torch_device()\n",
    "\n",
    "def shuffle_arrays(data, labels):\n",
    "    indexes = [i for i in range(data.shape[0])]\n",
    "    random.shuffle(indexes)\n",
    "    return data[indexes], labels[indexes]\n",
    "    \n",
    "\n",
    "def read_data():\n",
    "    \"\"\"\n",
    "    labels: 0, 1, 2, 3 corresponding to the original labels 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    raw_data1 = sio.loadmat(\"S1.mat\")\n",
    "    raw_data2 = sio.loadmat(\"S2.mat\")\n",
    "    raw_labels1 = sio.loadmat(\"TrueLabelsS1.mat\")['TrueLabelsS1']\n",
    "    raw_labels2 = sio.loadmat(\"TrueLabelsS2.mat\")['TrueLabelsS2']\n",
    "    \n",
    "    #print(raw_data1['test_data'].shape)\n",
    "    \n",
    "    training_set1 = torch.zeros((160, 400, 10), dtype=torch.float, device=torch_device)\n",
    "    training_labels1 = torch.tensor([i//40 for i in range(160)], dtype=torch.long, device=torch_device)\n",
    "    test_set1 = torch.tensor(raw_data1['test_data'], dtype=torch.float, device=torch_device)\n",
    "    test_labels1 = torch.tensor(raw_labels1, dtype=torch.long, device=torch_device) - 1\n",
    "    \n",
    "    training_set2 = torch.zeros((160, 400, 10), dtype=torch.float, device=torch_device)\n",
    "    training_labels2 = torch.tensor([i//40 for i in range(160)], dtype=torch.long, device=torch_device)\n",
    "    test_set2 = torch.tensor(raw_data2['test_data'], dtype=torch.float, device=torch_device)\n",
    "    test_labels2 = torch.tensor(raw_labels2, dtype=torch.long, device=torch_device) - 1\n",
    "\n",
    "    \n",
    "    for i in range(4):\n",
    "        start = i*40\n",
    "        end = start + 40\n",
    "        training_set1[start:end, :, :] = \\\n",
    "            torch.tensor(raw_data1['training_data'][0, i], dtype=torch.float, device=torch_device)\n",
    "        training_set2[start:end, :, :] = \\\n",
    "            torch.tensor(raw_data2['training_data'][0, i], dtype=torch.float, device=torch_device)\n",
    "        \n",
    "    #print(test_labels1.shape, test_labels2.shape)\n",
    "    return *shuffle_arrays(torch.cat((training_set1, training_set2), 0), \n",
    "                            torch.cat((training_labels1, training_labels2), 0)),\\\n",
    "            *shuffle_arrays(torch.cat((test_set1, test_set2), 0),\n",
    "                            torch.cat((test_labels1[0], test_labels2[0]), 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, training_labels,test_data, test_labels = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-eating",
   "metadata": {},
   "source": [
    "### Bidirection LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "structural-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, fc_hidden_size, num_outputs, seq_len, device=torch_device):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fc_hidden_size = fc_hidden_size\n",
    "        self.device = device\n",
    "        self.num_outputs = num_outputs\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, 1, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.attention_fc = nn.Linear(seq_len*hidden_size*2, seq_len)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.hidden_size*2, self.fc_hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.fc_hidden_size, self.num_outputs)\n",
    "        self.relu2 = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size, dtype=torch.float).to(self.device)\n",
    "        c0 = torch.zeros(2, x.size(0), self.hidden_size, dtype=torch.float).to(self.device)\n",
    "        \n",
    "        lstm_out, (h1, c1) = self.lstm(x, (h0, c0))\n",
    "        #print(out.shape)\n",
    "        #find attention: N, L, 2H -> N, L\n",
    "        out = self.attention_fc(lstm_out.reshape(lstm_out.shape[0], lstm_out.shape[1]*lstm_out.shape[2]))\n",
    "        attention = torch.softmax(out, dim=1).reshape(out.shape[0], out.shape[1], 1)\n",
    "        #attension layer: (N, L) * (N, L, 2H) -> N, 2H   \n",
    "        #print(attention.shape, lstm_out.shape)\n",
    "        out = torch.mul(attention, lstm_out).sum(axis=1)\n",
    "        \n",
    "        # N,2H -> N, hidden_size\n",
    "        out = self.relu1(self.fc1(out))\n",
    "        out = self.relu2(self.fc2(out))\n",
    "        \n",
    "        # N, num_outputs\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "humanitarian-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data, labels, lamb=0.01, device=torch_device, pr=True):\n",
    "    \"\"\"\n",
    "    data: N * L * input_size\n",
    "    labels: 1 * N\n",
    "    \"\"\"\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():   \n",
    "        out = model(data)\n",
    "        \n",
    "        #print(out.shape, labels.shape)\n",
    "        loss = loss_func(out, labels.reshape(-1))\n",
    "\n",
    "        l2reg = torch.tensor(0, dtype=torch.float, device=device)\n",
    "        for p in model.parameters():\n",
    "            l2reg += torch.pow(p, 2).sum()\n",
    "        loss = loss + lamb * l2reg            \n",
    "\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        _, y_hat = softmax(out).max(axis=1)\n",
    "        correct = (y_hat == labels).sum().item()\n",
    "        total = y_hat.shape[0]\n",
    "\n",
    "        if pr:\n",
    "            print(\"result:\", y_hat)\n",
    "            print(\"labels:\", labels)\n",
    "            print(\"Loss:\", loss.item(), \"Correct Rate:\", correct/total)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dated-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, labels, test_data, test_labels, epoch, hidden_size, fc_hidden_size, \n",
    "                num_outputs=4, seq_len=400, lr=0.0005, \n",
    "                lamb=0.01, batch_size=32, device=torch_device):\n",
    "    \"\"\"\n",
    "    data: N * L * input_size\n",
    "    labels: 1 * N\n",
    "    \"\"\"\n",
    "    #print(\"============ hidden_size:\", hidden_size, \"fc_hidden_size:\", fc_hidden_size, \n",
    "#           \"learning rate:\", lr, \"lambda:\", lamb, \"batch size:\", batch_size, \n",
    "#           \"============\")\n",
    "    input_size = data.shape[2]\n",
    "    num_classes = 4\n",
    "    num_samples = data.shape[0]\n",
    "    \n",
    "    model = LSTMNetwork(input_size, hidden_size, fc_hidden_size, num_classes, \n",
    "                        seq_len, device=torch_device).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    num_batches = math.ceil(num_samples/batch_size)\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_state = None\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for e in range(epoch):\n",
    "        epoch_correct = 0\n",
    "        epoch_loss = 0\n",
    "        for i in range(num_batches):\n",
    "            start = i * batch_size\n",
    "            end = (i+1) * batch_size\n",
    "            if end > num_samples:\n",
    "                end = num-samples\n",
    "            \n",
    "            batch_data = data[start:end]\n",
    "            batch_labels = labels[start:end]\n",
    "            \n",
    "            #print(batch_data.shape)\n",
    "            out = model(batch_data)\n",
    "            #print(batch_labels)\n",
    "            #print(out)\n",
    "            loss = loss_func(out, batch_labels)\n",
    "\n",
    "            l2reg = torch.tensor(0, dtype=torch.float, device=device)\n",
    "            for p in model.parameters():\n",
    "                l2reg += torch.pow(p, 2).sum()\n",
    "            loss = loss + lamb * l2reg            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                softmax = nn.Softmax(dim=1)\n",
    "                _, y_hat = softmax(out).max(axis=1)\n",
    "                batch_correct = (y_hat == batch_labels).sum().item()\n",
    "                epoch_correct += batch_correct\n",
    "                batch_total = y_hat.shape[0]\n",
    "                epoch_loss += loss.item()\n",
    "#                 print(\"result:\", y_hat)\n",
    "#                 print(\"labels:\", batch_labels)\n",
    "#                 print(\"Epoch:\", e, \"Batch \", i, \"Loss:\", loss.item(), \n",
    "#                       \"Correct Rate:\", batch_correct/batch_total)\n",
    "                test_accuracy = predict(model, test_data, test_labels, device=torch_device, pr=False)\n",
    "                if test_accuracy > best_acc:\n",
    "                    best_acc = test_accuracy\n",
    "                    best_state = copy.deepcopy(model.state_dict())\n",
    "        losses.append(epoch_loss/num_batches)\n",
    "        accs.append(test_accuracy)\n",
    "        print(\"Epoch:\", e, \"Avg_loss:\", epoch_loss/num_batches, \n",
    "              \"training accuracy:\", epoch_correct/num_samples,\n",
    "              \"test accuracy:\", test_accuracy)\n",
    "    print(\"best accuracy:\", best_acc)\n",
    "    return model, best_state, best_acc, losses, accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "subjective-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Avg_loss: 1.858587634563446 training accuracy: 0.25 test accuracy: 0.2653061224489796\n",
      "Epoch: 1 Avg_loss: 1.7489727795124055 training accuracy: 0.25625 test accuracy: 0.2653061224489796\n",
      "Epoch: 2 Avg_loss: 1.6701273560523986 training accuracy: 0.39375 test accuracy: 0.25170068027210885\n",
      "Epoch: 3 Avg_loss: 1.6119879364967347 training accuracy: 0.490625 test accuracy: 0.2653061224489796\n",
      "Epoch: 4 Avg_loss: 1.5592638790607452 training accuracy: 0.55625 test accuracy: 0.25170068027210885\n",
      "Epoch: 5 Avg_loss: 1.5082694053649903 training accuracy: 0.58125 test accuracy: 0.25170068027210885\n",
      "Epoch: 6 Avg_loss: 1.4538520276546478 training accuracy: 0.615625 test accuracy: 0.21768707482993196\n",
      "Epoch: 7 Avg_loss: 1.4029042303562165 training accuracy: 0.625 test accuracy: 0.23129251700680273\n",
      "Epoch: 8 Avg_loss: 1.3514792442321777 training accuracy: 0.640625 test accuracy: 0.23129251700680273\n",
      "Epoch: 9 Avg_loss: 1.2991986274719238 training accuracy: 0.64375 test accuracy: 0.24489795918367346\n",
      "Epoch: 10 Avg_loss: 1.25066779255867 training accuracy: 0.665625 test accuracy: 0.23809523809523808\n",
      "Epoch: 11 Avg_loss: 1.202153354883194 training accuracy: 0.690625 test accuracy: 0.2585034013605442\n",
      "Epoch: 12 Avg_loss: 1.1586796283721923 training accuracy: 0.715625 test accuracy: 0.22448979591836735\n",
      "Epoch: 13 Avg_loss: 1.111683589220047 training accuracy: 0.7375 test accuracy: 0.19047619047619047\n",
      "Epoch: 14 Avg_loss: 1.069131463766098 training accuracy: 0.75625 test accuracy: 0.23809523809523808\n",
      "Epoch: 15 Avg_loss: 1.023073673248291 training accuracy: 0.765625 test accuracy: 0.19047619047619047\n",
      "Epoch: 16 Avg_loss: 0.9809652119874954 training accuracy: 0.778125 test accuracy: 0.21768707482993196\n",
      "Epoch: 17 Avg_loss: 0.9359237521886825 training accuracy: 0.80625 test accuracy: 0.1836734693877551\n",
      "Epoch: 18 Avg_loss: 0.8958428800106049 training accuracy: 0.83125 test accuracy: 0.2585034013605442\n",
      "Epoch: 19 Avg_loss: 0.855981519818306 training accuracy: 0.853125 test accuracy: 0.2108843537414966\n",
      "Epoch: 20 Avg_loss: 0.8184076845645905 training accuracy: 0.85625 test accuracy: 0.24489795918367346\n",
      "Epoch: 21 Avg_loss: 0.7932993441820144 training accuracy: 0.865625 test accuracy: 0.24489795918367346\n",
      "Epoch: 22 Avg_loss: 0.7604629933834076 training accuracy: 0.884375 test accuracy: 0.1836734693877551\n",
      "Epoch: 23 Avg_loss: 0.7217490673065186 training accuracy: 0.890625 test accuracy: 0.24489795918367346\n",
      "Epoch: 24 Avg_loss: 0.6904601812362671 training accuracy: 0.9125 test accuracy: 0.21768707482993196\n",
      "Epoch: 25 Avg_loss: 0.6651887446641922 training accuracy: 0.921875 test accuracy: 0.2653061224489796\n",
      "Epoch: 26 Avg_loss: 0.6375169277191162 training accuracy: 0.934375 test accuracy: 0.22448979591836735\n",
      "Epoch: 27 Avg_loss: 0.6088231563568115 training accuracy: 0.95 test accuracy: 0.23129251700680273\n",
      "Epoch: 28 Avg_loss: 0.5869788199663162 training accuracy: 0.953125 test accuracy: 0.24489795918367346\n",
      "Epoch: 29 Avg_loss: 0.5696038171648979 training accuracy: 0.959375 test accuracy: 0.25170068027210885\n",
      "Epoch: 30 Avg_loss: 0.5465428844094277 training accuracy: 0.965625 test accuracy: 0.25170068027210885\n",
      "Epoch: 31 Avg_loss: 0.527385775744915 training accuracy: 0.959375 test accuracy: 0.25170068027210885\n",
      "Epoch: 32 Avg_loss: 0.5168191760778427 training accuracy: 0.95 test accuracy: 0.2585034013605442\n",
      "Epoch: 33 Avg_loss: 0.5007450819015503 training accuracy: 0.959375 test accuracy: 0.2857142857142857\n",
      "Epoch: 34 Avg_loss: 0.4810767754912376 training accuracy: 0.959375 test accuracy: 0.2585034013605442\n",
      "Epoch: 35 Avg_loss: 0.45566839575767515 training accuracy: 0.971875 test accuracy: 0.25170068027210885\n",
      "Epoch: 36 Avg_loss: 0.436060243844986 training accuracy: 0.971875 test accuracy: 0.25170068027210885\n",
      "Epoch: 37 Avg_loss: 0.41922755539417267 training accuracy: 0.971875 test accuracy: 0.24489795918367346\n",
      "Epoch: 38 Avg_loss: 0.41184833496809004 training accuracy: 0.96875 test accuracy: 0.2925170068027211\n",
      "Epoch: 39 Avg_loss: 0.39039543867111204 training accuracy: 0.9875 test accuracy: 0.22448979591836735\n",
      "Epoch: 40 Avg_loss: 0.3709370970726013 training accuracy: 0.9875 test accuracy: 0.29931972789115646\n",
      "Epoch: 41 Avg_loss: 0.35513692200183866 training accuracy: 0.990625 test accuracy: 0.29931972789115646\n",
      "Epoch: 42 Avg_loss: 0.3411025531589985 training accuracy: 0.990625 test accuracy: 0.30612244897959184\n",
      "Epoch: 43 Avg_loss: 0.3281485676765442 training accuracy: 0.990625 test accuracy: 0.3129251700680272\n",
      "Epoch: 44 Avg_loss: 0.31575542539358137 training accuracy: 0.99375 test accuracy: 0.29931972789115646\n",
      "Epoch: 45 Avg_loss: 0.30489711463451385 training accuracy: 0.99375 test accuracy: 0.3197278911564626\n",
      "Epoch: 46 Avg_loss: 0.2991387262940407 training accuracy: 0.99375 test accuracy: 0.2925170068027211\n",
      "Epoch: 47 Avg_loss: 0.28602204844355583 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 48 Avg_loss: 0.2753521017730236 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 49 Avg_loss: 0.2656989574432373 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 50 Avg_loss: 0.25649997815489767 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 51 Avg_loss: 0.24828753918409346 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 52 Avg_loss: 0.23990156278014182 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 53 Avg_loss: 0.23624358475208282 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 54 Avg_loss: 0.24870104864239692 training accuracy: 0.990625 test accuracy: 0.23809523809523808\n",
      "Epoch: 55 Avg_loss: 0.22819637805223464 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 56 Avg_loss: 0.21774920225143432 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 57 Avg_loss: 0.2108066625893116 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 58 Avg_loss: 0.20396685600280762 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 59 Avg_loss: 0.19774765223264695 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 60 Avg_loss: 0.1917658641934395 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 61 Avg_loss: 0.20319220796227455 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 62 Avg_loss: 0.19783201366662978 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 63 Avg_loss: 0.19894029274582864 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 64 Avg_loss: 0.25035496726632117 training accuracy: 0.978125 test accuracy: 0.25170068027210885\n",
      "Epoch: 65 Avg_loss: 0.20542715713381768 training accuracy: 0.990625 test accuracy: 0.2108843537414966\n",
      "Epoch: 66 Avg_loss: 0.19202970266342162 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 67 Avg_loss: 0.1859450161457062 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 68 Avg_loss: 0.17592044174671173 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 69 Avg_loss: 0.17049336954951286 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 70 Avg_loss: 0.16582698449492456 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 71 Avg_loss: 0.16154425218701363 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 72 Avg_loss: 0.15780519247055053 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 73 Avg_loss: 0.1539498932659626 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 74 Avg_loss: 0.15066921710968018 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 75 Avg_loss: 0.14756498485803604 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 76 Avg_loss: 0.14468949660658836 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 77 Avg_loss: 0.14200281873345375 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 78 Avg_loss: 0.13944042287766933 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 79 Avg_loss: 0.13800494708120822 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 80 Avg_loss: 0.13630843348801136 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 81 Avg_loss: 0.13359807543456553 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 82 Avg_loss: 0.1312858946621418 training accuracy: 1.0 test accuracy: 0.24489795918367346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83 Avg_loss: 0.1291828092187643 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 84 Avg_loss: 0.12712659277021884 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 85 Avg_loss: 0.12515566423535346 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 86 Avg_loss: 0.12326503060758114 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 87 Avg_loss: 0.1214447233825922 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 88 Avg_loss: 0.11964516900479794 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 89 Avg_loss: 0.11787703596055507 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 90 Avg_loss: 0.1162541825324297 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 91 Avg_loss: 0.11641581542789936 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 92 Avg_loss: 0.11350857056677341 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 93 Avg_loss: 0.11194662824273109 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 94 Avg_loss: 0.11051223911345005 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 95 Avg_loss: 0.10913131162524223 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 96 Avg_loss: 0.10779815837740898 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 97 Avg_loss: 0.10648306608200073 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 98 Avg_loss: 0.10531589277088642 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 99 Avg_loss: 0.1040952317416668 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 100 Avg_loss: 0.10292884111404418 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 101 Avg_loss: 0.10181043967604637 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 102 Avg_loss: 0.10068795904517173 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 103 Avg_loss: 0.0996168877929449 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 104 Avg_loss: 0.09853124618530273 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 105 Avg_loss: 0.0975145421922207 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 106 Avg_loss: 0.09653071500360966 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 107 Avg_loss: 0.0955350611358881 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 108 Avg_loss: 0.09458152614533902 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 109 Avg_loss: 0.09364009276032448 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 110 Avg_loss: 0.09272182621061802 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 111 Avg_loss: 0.09180228784680367 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 112 Avg_loss: 0.09103923551738262 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 113 Avg_loss: 0.09022119715809822 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 114 Avg_loss: 0.08953512459993362 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 115 Avg_loss: 0.08878146521747113 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 116 Avg_loss: 0.08795558288693428 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 117 Avg_loss: 0.08714382015168667 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 118 Avg_loss: 0.08635799586772919 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 119 Avg_loss: 0.08568800911307335 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 120 Avg_loss: 0.08493110686540603 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 121 Avg_loss: 0.08419855758547783 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 122 Avg_loss: 0.0835865505039692 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 123 Avg_loss: 0.0828702911734581 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 124 Avg_loss: 0.08225576430559159 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 125 Avg_loss: 0.08154413551092148 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 126 Avg_loss: 0.08099036291241646 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 127 Avg_loss: 0.08038233406841755 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 128 Avg_loss: 0.07972955629229546 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 129 Avg_loss: 0.07910905741155147 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 130 Avg_loss: 0.0785479985177517 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 131 Avg_loss: 0.07797101065516472 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 132 Avg_loss: 0.07746917679905892 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 133 Avg_loss: 0.07691649161279202 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 134 Avg_loss: 0.07642629481852055 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 135 Avg_loss: 0.07589359171688556 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 136 Avg_loss: 0.075409447401762 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 137 Avg_loss: 0.07491182908415794 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 138 Avg_loss: 0.07438023686408997 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 139 Avg_loss: 0.07394168339669704 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 140 Avg_loss: 0.07349625118076801 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 141 Avg_loss: 0.07294135168194771 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 142 Avg_loss: 0.07249033898115158 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 143 Avg_loss: 0.07203409597277641 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 144 Avg_loss: 0.07163292802870273 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 145 Avg_loss: 0.07118865996599197 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 146 Avg_loss: 0.07075204253196717 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 147 Avg_loss: 0.07043214850127696 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 148 Avg_loss: 0.06997654773294926 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 149 Avg_loss: 0.06961906850337982 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 150 Avg_loss: 0.06930480189621449 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 151 Avg_loss: 0.06888011880218983 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 152 Avg_loss: 0.06846000105142594 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 153 Avg_loss: 0.06807640381157398 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 154 Avg_loss: 0.06771178618073463 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 155 Avg_loss: 0.06735762171447277 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 156 Avg_loss: 0.06698490157723427 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 157 Avg_loss: 0.06666325516998768 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 158 Avg_loss: 0.06638715378940105 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 159 Avg_loss: 0.06601372137665748 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 160 Avg_loss: 0.06565232332795859 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 161 Avg_loss: 0.06536417137831449 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 162 Avg_loss: 0.0650829965248704 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 163 Avg_loss: 0.06472410168498755 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 164 Avg_loss: 0.06440225914120674 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 165 Avg_loss: 0.06409813445061445 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 166 Avg_loss: 0.06382300220429897 training accuracy: 1.0 test accuracy: 0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167 Avg_loss: 0.06357639599591494 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 168 Avg_loss: 0.06323468424379826 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 169 Avg_loss: 0.0628777852281928 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 170 Avg_loss: 0.06257536709308624 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 171 Avg_loss: 0.06227417271584272 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 172 Avg_loss: 0.06198471058160067 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 173 Avg_loss: 0.06174509860575199 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 174 Avg_loss: 0.06145312562584877 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 175 Avg_loss: 0.061181171983480456 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 176 Avg_loss: 0.06092646811157465 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 177 Avg_loss: 0.060775288939476015 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 178 Avg_loss: 0.06050377357751131 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 179 Avg_loss: 0.060147500969469546 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 180 Avg_loss: 0.05989730004221201 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 181 Avg_loss: 0.059639493189752105 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 182 Avg_loss: 0.05933406092226505 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 183 Avg_loss: 0.059095089137554166 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 184 Avg_loss: 0.05890340320765972 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 185 Avg_loss: 0.058707561902701856 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 186 Avg_loss: 0.05847560055553913 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 187 Avg_loss: 0.05823438465595245 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 188 Avg_loss: 0.05790748968720436 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 189 Avg_loss: 0.05767916683107614 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 190 Avg_loss: 0.05746611095964908 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 191 Avg_loss: 0.05720645897090435 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 192 Avg_loss: 0.05692866835743189 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 193 Avg_loss: 0.05668935384601355 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 194 Avg_loss: 0.056483546271920204 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 195 Avg_loss: 0.05627663675695658 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 196 Avg_loss: 0.05601802971214056 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 197 Avg_loss: 0.05581376906484366 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 198 Avg_loss: 0.05558196436613798 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 199 Avg_loss: 0.05541444234549999 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 200 Avg_loss: 0.05527788605540991 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 201 Avg_loss: 0.05508992075920105 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 202 Avg_loss: 0.05478790290653705 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 203 Avg_loss: 0.05453236997127533 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 204 Avg_loss: 0.054299700818955896 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 205 Avg_loss: 0.0541092898696661 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 206 Avg_loss: 0.0538823090493679 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 207 Avg_loss: 0.053660308197140696 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 208 Avg_loss: 0.05348147489130497 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 209 Avg_loss: 0.053300161845982075 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 210 Avg_loss: 0.05311604645103216 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 211 Avg_loss: 0.05293539427220821 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 212 Avg_loss: 0.052724928967654704 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 213 Avg_loss: 0.052472593076527116 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 214 Avg_loss: 0.052241815626621245 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 215 Avg_loss: 0.05205639898777008 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 216 Avg_loss: 0.05190397333353758 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 217 Avg_loss: 0.05186938717961311 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 218 Avg_loss: 0.05180733129382133 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 219 Avg_loss: 0.05153559558093548 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 220 Avg_loss: 0.0512510608881712 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 221 Avg_loss: 0.051015155389904976 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 222 Avg_loss: 0.05080487988889217 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 223 Avg_loss: 0.05054507553577423 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 224 Avg_loss: 0.0503685237839818 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 225 Avg_loss: 0.05017803814262152 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 226 Avg_loss: 0.05003067087382078 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 227 Avg_loss: 0.049871375784277916 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 228 Avg_loss: 0.04971550423651934 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 229 Avg_loss: 0.04949925597757101 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 230 Avg_loss: 0.04931193478405475 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 231 Avg_loss: 0.04927315004169941 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 232 Avg_loss: 0.049249449372291566 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 233 Avg_loss: 0.04897088650614023 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 234 Avg_loss: 0.048651070520281794 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 235 Avg_loss: 0.04843047950416803 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 236 Avg_loss: 0.048329252563416955 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 237 Avg_loss: 0.04818807374686003 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 238 Avg_loss: 0.04797940757125616 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 239 Avg_loss: 0.047748883999884126 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 240 Avg_loss: 0.047621485963463786 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 241 Avg_loss: 0.047544807009398934 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 242 Avg_loss: 0.5776891835033894 training accuracy: 0.859375 test accuracy: 0.2585034013605442\n",
      "Epoch: 243 Avg_loss: 1.8078571885824204 training accuracy: 0.49375 test accuracy: 0.272108843537415\n",
      "Epoch: 244 Avg_loss: 1.2382658958435058 training accuracy: 0.6125 test accuracy: 0.25170068027210885\n",
      "Epoch: 245 Avg_loss: 0.7965150162577629 training accuracy: 0.78125 test accuracy: 0.2789115646258503\n",
      "Epoch: 246 Avg_loss: 0.6152902171015739 training accuracy: 0.85 test accuracy: 0.2653061224489796\n",
      "Epoch: 247 Avg_loss: 0.5252554804086685 training accuracy: 0.884375 test accuracy: 0.2653061224489796\n",
      "Epoch: 248 Avg_loss: 0.4503988936543465 training accuracy: 0.91875 test accuracy: 0.25170068027210885\n",
      "Epoch: 249 Avg_loss: 0.41369943618774413 training accuracy: 0.9375 test accuracy: 0.25170068027210885\n",
      "Epoch: 250 Avg_loss: 0.38163098841905596 training accuracy: 0.940625 test accuracy: 0.2653061224489796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251 Avg_loss: 0.3558800175786018 training accuracy: 0.95 test accuracy: 0.24489795918367346\n",
      "Epoch: 252 Avg_loss: 0.33559834137558936 training accuracy: 0.953125 test accuracy: 0.24489795918367346\n",
      "Epoch: 253 Avg_loss: 0.3170922093093395 training accuracy: 0.959375 test accuracy: 0.24489795918367346\n",
      "Epoch: 254 Avg_loss: 0.3020668588578701 training accuracy: 0.96875 test accuracy: 0.24489795918367346\n",
      "Epoch: 255 Avg_loss: 0.28984596505761145 training accuracy: 0.96875 test accuracy: 0.2585034013605442\n",
      "Epoch: 256 Avg_loss: 0.27894559502601624 training accuracy: 0.96875 test accuracy: 0.25170068027210885\n",
      "Epoch: 257 Avg_loss: 0.2700342804193497 training accuracy: 0.96875 test accuracy: 0.2585034013605442\n",
      "Epoch: 258 Avg_loss: 0.2620001696050167 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 259 Avg_loss: 0.2531756035983562 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 260 Avg_loss: 0.24538801684975625 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 261 Avg_loss: 0.23784666359424592 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 262 Avg_loss: 0.23157925978302957 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 263 Avg_loss: 0.22448487877845763 training accuracy: 0.971875 test accuracy: 0.2585034013605442\n",
      "Epoch: 264 Avg_loss: 0.21604007482528687 training accuracy: 0.978125 test accuracy: 0.2789115646258503\n",
      "Epoch: 265 Avg_loss: 0.20861098915338516 training accuracy: 0.98125 test accuracy: 0.2857142857142857\n",
      "Epoch: 266 Avg_loss: 0.2027937076985836 training accuracy: 0.98125 test accuracy: 0.2857142857142857\n",
      "Epoch: 267 Avg_loss: 0.19771679267287254 training accuracy: 0.984375 test accuracy: 0.2857142857142857\n",
      "Epoch: 268 Avg_loss: 0.19309922382235528 training accuracy: 0.984375 test accuracy: 0.2857142857142857\n",
      "Epoch: 269 Avg_loss: 0.1890417106449604 training accuracy: 0.984375 test accuracy: 0.2857142857142857\n",
      "Epoch: 270 Avg_loss: 0.18555196151137351 training accuracy: 0.984375 test accuracy: 0.2857142857142857\n",
      "Epoch: 271 Avg_loss: 0.18221141397953033 training accuracy: 0.984375 test accuracy: 0.2857142857142857\n",
      "Epoch: 272 Avg_loss: 0.17910152450203895 training accuracy: 0.984375 test accuracy: 0.2857142857142857\n",
      "Epoch: 273 Avg_loss: 0.17617301866412163 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 274 Avg_loss: 0.1732190053910017 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 275 Avg_loss: 0.17062345445156096 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 276 Avg_loss: 0.16815337873995304 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 277 Avg_loss: 0.16591113917529582 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 278 Avg_loss: 0.16384864300489427 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 279 Avg_loss: 0.1616122003644705 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 280 Avg_loss: 0.1596421554684639 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 281 Avg_loss: 0.15771103873848916 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 282 Avg_loss: 0.15597092509269714 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 283 Avg_loss: 0.1542561214417219 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 284 Avg_loss: 0.15262899920344353 training accuracy: 0.984375 test accuracy: 0.2789115646258503\n",
      "Epoch: 285 Avg_loss: 0.15105405375361441 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 286 Avg_loss: 0.14954301491379737 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 287 Avg_loss: 0.14812250025570392 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 288 Avg_loss: 0.14684439785778522 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 289 Avg_loss: 0.145616801828146 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 290 Avg_loss: 0.14430841393768787 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 291 Avg_loss: 0.1431072473526001 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 292 Avg_loss: 0.14194494374096395 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 293 Avg_loss: 0.14081543497741222 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 294 Avg_loss: 0.13971429392695428 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 295 Avg_loss: 0.13862878009676932 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 296 Avg_loss: 0.1375704888254404 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 297 Avg_loss: 0.1365122925490141 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 298 Avg_loss: 0.13554859422147275 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 299 Avg_loss: 0.13433571793138982 training accuracy: 0.9875 test accuracy: 0.272108843537415\n",
      "Epoch: 300 Avg_loss: 0.133027483522892 training accuracy: 0.9875 test accuracy: 0.272108843537415\n",
      "Epoch: 301 Avg_loss: 0.13102743588387966 training accuracy: 0.9875 test accuracy: 0.2789115646258503\n",
      "Epoch: 302 Avg_loss: 0.12873336486518383 training accuracy: 0.9875 test accuracy: 0.272108843537415\n",
      "Epoch: 303 Avg_loss: 0.12698587849736215 training accuracy: 0.990625 test accuracy: 0.272108843537415\n",
      "Epoch: 304 Avg_loss: 0.12427894473075866 training accuracy: 0.990625 test accuracy: 0.2857142857142857\n",
      "Epoch: 305 Avg_loss: 0.12206223681569099 training accuracy: 0.990625 test accuracy: 0.2857142857142857\n",
      "Epoch: 306 Avg_loss: 0.12015937678515912 training accuracy: 0.990625 test accuracy: 0.2789115646258503\n",
      "Epoch: 307 Avg_loss: 0.11840439103543758 training accuracy: 0.99375 test accuracy: 0.2789115646258503\n",
      "Epoch: 308 Avg_loss: 0.11671384498476982 training accuracy: 0.99375 test accuracy: 0.2789115646258503\n",
      "Epoch: 309 Avg_loss: 0.11534736193716526 training accuracy: 0.99375 test accuracy: 0.2789115646258503\n",
      "Epoch: 310 Avg_loss: 0.1141385655850172 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 311 Avg_loss: 0.11304204277694226 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 312 Avg_loss: 0.11200211085379123 training accuracy: 0.99375 test accuracy: 0.2925170068027211\n",
      "Epoch: 313 Avg_loss: 0.11077002361416817 training accuracy: 0.99375 test accuracy: 0.29931972789115646\n",
      "Epoch: 314 Avg_loss: 0.1084804505109787 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 315 Avg_loss: 0.10607819855213166 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 316 Avg_loss: 0.10483861118555068 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 317 Avg_loss: 0.10384296663105488 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 318 Avg_loss: 0.10292504392564297 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 319 Avg_loss: 0.10210117436945439 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 320 Avg_loss: 0.10131459459662437 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 321 Avg_loss: 0.10059598907828331 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 322 Avg_loss: 0.0998563926666975 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 323 Avg_loss: 0.09914911426603794 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 324 Avg_loss: 0.09849289879202842 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 325 Avg_loss: 0.09784960485994816 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 326 Avg_loss: 0.09721549116075039 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 327 Avg_loss: 0.09661864042282105 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 328 Avg_loss: 0.09600431323051453 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 329 Avg_loss: 0.09544840902090072 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 330 Avg_loss: 0.09482821486890317 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 331 Avg_loss: 0.09420604072511196 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 332 Avg_loss: 0.09361046701669692 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 333 Avg_loss: 0.09299983382225037 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 334 Avg_loss: 0.09248368889093399 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 335 Avg_loss: 0.09199794717133045 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 336 Avg_loss: 0.09149864353239537 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 337 Avg_loss: 0.09101678058505058 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 338 Avg_loss: 0.09055250845849513 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 339 Avg_loss: 0.09008402191102505 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 340 Avg_loss: 0.08964115753769875 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 341 Avg_loss: 0.08920563198626041 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 342 Avg_loss: 0.08875871375203133 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 343 Avg_loss: 0.08833721950650215 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 344 Avg_loss: 0.0879040639847517 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 345 Avg_loss: 0.08746848553419113 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 346 Avg_loss: 0.087059186398983 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 347 Avg_loss: 0.08664347231388092 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 348 Avg_loss: 0.08623290695250034 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 349 Avg_loss: 0.08584577180445194 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 350 Avg_loss: 0.0854510422796011 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 351 Avg_loss: 0.08505324982106685 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 352 Avg_loss: 0.08468180261552334 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 353 Avg_loss: 0.08429570868611336 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 354 Avg_loss: 0.08390776216983795 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 355 Avg_loss: 0.08354351297020912 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 356 Avg_loss: 0.08317392505705357 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 357 Avg_loss: 0.08280646614730358 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 358 Avg_loss: 0.08245486244559289 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 359 Avg_loss: 0.08213797211647034 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 360 Avg_loss: 0.08177146911621094 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 361 Avg_loss: 0.08144903853535652 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 362 Avg_loss: 0.08107520379126072 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 363 Avg_loss: 0.0807439286261797 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 364 Avg_loss: 0.08035044148564338 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 365 Avg_loss: 0.07997054308652878 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 366 Avg_loss: 0.07961015850305557 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 367 Avg_loss: 0.07926210835576057 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 368 Avg_loss: 0.07889500595629215 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 369 Avg_loss: 0.07852959483861924 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 370 Avg_loss: 0.07814528532326222 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 371 Avg_loss: 0.07740140371024609 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 372 Avg_loss: 0.07653330564498902 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 373 Avg_loss: 0.07524845600128174 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 374 Avg_loss: 0.07446494959294796 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 375 Avg_loss: 0.07413390092551708 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 376 Avg_loss: 0.07335393242537976 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 377 Avg_loss: 0.07284867316484452 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 378 Avg_loss: 0.0724410641938448 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 379 Avg_loss: 0.0720465436577797 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 380 Avg_loss: 0.07158196866512298 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 381 Avg_loss: 0.07121221162378788 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 382 Avg_loss: 0.07083913385868072 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 383 Avg_loss: 0.07045024447143078 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 384 Avg_loss: 0.070086320489645 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 385 Avg_loss: 0.06975988149642945 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 386 Avg_loss: 0.06946372650563717 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 387 Avg_loss: 0.06917323619127273 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 388 Avg_loss: 0.06887874007225037 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 389 Avg_loss: 0.06859949491918087 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 390 Avg_loss: 0.0683157280087471 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 391 Avg_loss: 0.06804423481225967 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 392 Avg_loss: 0.06776209585368634 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 393 Avg_loss: 0.0674866247922182 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 394 Avg_loss: 0.06721886061131954 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 395 Avg_loss: 0.06694932021200657 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 396 Avg_loss: 0.06667597703635693 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 397 Avg_loss: 0.066413888707757 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 398 Avg_loss: 0.06615190170705318 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 399 Avg_loss: 0.06589019782841206 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 400 Avg_loss: 0.06562789157032967 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 401 Avg_loss: 0.06537316404283047 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 402 Avg_loss: 0.0651093490421772 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 403 Avg_loss: 0.06485249735414982 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 404 Avg_loss: 0.06460556089878082 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 405 Avg_loss: 0.0643530635163188 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 406 Avg_loss: 0.06409697234630585 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 407 Avg_loss: 0.06384763978421688 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 408 Avg_loss: 0.06359540093690157 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 409 Avg_loss: 0.06333054434508086 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 410 Avg_loss: 0.06308458503335715 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 411 Avg_loss: 0.06283831857144832 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 412 Avg_loss: 0.06259195934981107 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 413 Avg_loss: 0.06234505660831928 training accuracy: 1.0 test accuracy: 0.25170068027210885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 414 Avg_loss: 0.062101555056869984 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 415 Avg_loss: 0.061859232001006605 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 416 Avg_loss: 0.061615463346242905 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 417 Avg_loss: 0.061380619369447234 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 418 Avg_loss: 0.06115097906440496 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 419 Avg_loss: 0.06091433446854353 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 420 Avg_loss: 0.06068243868649006 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 421 Avg_loss: 0.06045941077172756 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 422 Avg_loss: 0.060233252309262755 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 423 Avg_loss: 0.059992754645645616 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 424 Avg_loss: 0.05977160800248384 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 425 Avg_loss: 0.059555076994001865 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 426 Avg_loss: 0.05932543016970158 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 427 Avg_loss: 0.05909109991043806 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 428 Avg_loss: 0.05887504778802395 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 429 Avg_loss: 0.058653628826141356 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 430 Avg_loss: 0.05843056440353393 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 431 Avg_loss: 0.05821253135800362 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 432 Avg_loss: 0.05799640603363514 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 433 Avg_loss: 0.057778728939592836 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 434 Avg_loss: 0.057563811913132666 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 435 Avg_loss: 0.05734942741692066 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 436 Avg_loss: 0.05713164936751127 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 437 Avg_loss: 0.05691788215190172 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 438 Avg_loss: 0.05671093054115772 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 439 Avg_loss: 0.056507264450192454 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 440 Avg_loss: 0.05630035698413849 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 441 Avg_loss: 0.05609404798597097 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 442 Avg_loss: 0.05589299071580171 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 443 Avg_loss: 0.05568544641137123 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 444 Avg_loss: 0.0554893646389246 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 445 Avg_loss: 0.0552864633500576 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 446 Avg_loss: 0.05509171038866043 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 447 Avg_loss: 0.05488986074924469 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 448 Avg_loss: 0.05469250548630953 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 449 Avg_loss: 0.05449643135070801 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 450 Avg_loss: 0.05430050287395716 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 451 Avg_loss: 0.05410918649286032 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 452 Avg_loss: 0.05392087772488594 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 453 Avg_loss: 0.05372363831847906 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 454 Avg_loss: 0.05353850871324539 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 455 Avg_loss: 0.053349597938358785 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 456 Avg_loss: 0.05316224079579115 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 457 Avg_loss: 0.05297549422830343 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 458 Avg_loss: 0.05279239397495985 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 459 Avg_loss: 0.05260688401758671 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 460 Avg_loss: 0.05242486093193292 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 461 Avg_loss: 0.05223878622055054 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 462 Avg_loss: 0.05206143669784069 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 463 Avg_loss: 0.051877637021243574 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 464 Avg_loss: 0.05169505830854178 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 465 Avg_loss: 0.051512446440756324 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 466 Avg_loss: 0.05133973564952612 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 467 Avg_loss: 0.05115867760032415 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 468 Avg_loss: 0.051068723760545255 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 469 Avg_loss: 0.05102104227989912 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 470 Avg_loss: 0.05079707242548466 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 471 Avg_loss: 0.05060846004635096 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 472 Avg_loss: 0.050421923585236075 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 473 Avg_loss: 0.050240648165345195 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 474 Avg_loss: 0.05006634071469307 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 475 Avg_loss: 0.04988482668995857 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 476 Avg_loss: 0.04971532747149467 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 477 Avg_loss: 0.049544833973050116 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 478 Avg_loss: 0.049372055754065516 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 479 Avg_loss: 0.04920942671597004 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 480 Avg_loss: 0.049035616032779214 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 481 Avg_loss: 0.04887193441390991 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 482 Avg_loss: 0.04870652854442596 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 483 Avg_loss: 0.04854703228920698 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 484 Avg_loss: 0.04837607443332672 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 485 Avg_loss: 0.04821496494114399 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 486 Avg_loss: 0.048039892502129075 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 487 Avg_loss: 0.04787707924842834 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 488 Avg_loss: 0.04770360309630632 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 489 Avg_loss: 0.047543646581470964 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 490 Avg_loss: 0.04738132134079933 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 491 Avg_loss: 0.04722919464111328 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 492 Avg_loss: 0.04707161728292704 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 493 Avg_loss: 0.04692032691091299 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 494 Avg_loss: 0.046766492910683154 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 495 Avg_loss: 0.046614992432296276 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 496 Avg_loss: 0.0464673675596714 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 497 Avg_loss: 0.046316921897232535 training accuracy: 1.0 test accuracy: 0.272108843537415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 498 Avg_loss: 0.04617134016007185 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 499 Avg_loss: 0.046029155142605305 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 500 Avg_loss: 0.04588539637625218 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 501 Avg_loss: 0.04574506804347038 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 502 Avg_loss: 0.045599641278386116 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 503 Avg_loss: 0.04547120686620474 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 504 Avg_loss: 0.04533203411847353 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 505 Avg_loss: 0.04519341178238392 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 506 Avg_loss: 0.04505781661719084 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 507 Avg_loss: 0.044919725880026816 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 508 Avg_loss: 0.04478261433541775 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 509 Avg_loss: 0.044654655829072 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 510 Avg_loss: 0.044529040902853013 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 511 Avg_loss: 0.04439832326024771 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 512 Avg_loss: 0.04426250401884317 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 513 Avg_loss: 0.04413599595427513 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 514 Avg_loss: 0.043996240198612216 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 515 Avg_loss: 0.043880391493439676 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 516 Avg_loss: 0.04374858643859625 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 517 Avg_loss: 0.04362653288990259 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 518 Avg_loss: 0.04350539389997721 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 519 Avg_loss: 0.04337696302682161 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 520 Avg_loss: 0.04324207752943039 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 521 Avg_loss: 0.04312216136604548 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 522 Avg_loss: 0.04299235362559557 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 523 Avg_loss: 0.04287562444806099 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 524 Avg_loss: 0.04272025544196367 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 525 Avg_loss: 0.042562305368483065 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 526 Avg_loss: 0.042448462918400764 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 527 Avg_loss: 0.042341130785644054 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 528 Avg_loss: 0.04221357870846987 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 529 Avg_loss: 0.04209728837013245 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 530 Avg_loss: 0.04197864960879087 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 531 Avg_loss: 0.041846648417413236 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 532 Avg_loss: 0.04172906652092934 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 533 Avg_loss: 0.04161461070179939 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 534 Avg_loss: 0.04150881487876177 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 535 Avg_loss: 0.04137665405869484 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 536 Avg_loss: 0.04125942662358284 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 537 Avg_loss: 0.04114468656480312 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 538 Avg_loss: 0.04105111639946699 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 539 Avg_loss: 0.04093855135142803 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 540 Avg_loss: 0.040824278444051745 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 541 Avg_loss: 0.04072313420474529 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 542 Avg_loss: 0.04059043731540442 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 543 Avg_loss: 0.040469948574900626 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 544 Avg_loss: 0.040433311834931374 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 545 Avg_loss: 0.040387816913425925 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 546 Avg_loss: 0.042759015783667566 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 547 Avg_loss: 0.3461567685008049 training accuracy: 0.896875 test accuracy: 0.25170068027210885\n",
      "Epoch: 548 Avg_loss: 0.4265019655227661 training accuracy: 0.89375 test accuracy: 0.2653061224489796\n",
      "Epoch: 549 Avg_loss: 0.34106103926897047 training accuracy: 0.9375 test accuracy: 0.3469387755102041\n",
      "Epoch: 550 Avg_loss: 0.20843718573451042 training accuracy: 0.978125 test accuracy: 0.2789115646258503\n",
      "Epoch: 551 Avg_loss: 0.16887101978063584 training accuracy: 0.99375 test accuracy: 0.2653061224489796\n",
      "Epoch: 552 Avg_loss: 0.15100689083337784 training accuracy: 0.99375 test accuracy: 0.2653061224489796\n",
      "Epoch: 553 Avg_loss: 0.13728635832667352 training accuracy: 0.99375 test accuracy: 0.2585034013605442\n",
      "Epoch: 554 Avg_loss: 0.12966167293488978 training accuracy: 0.99375 test accuracy: 0.2585034013605442\n",
      "Epoch: 555 Avg_loss: 0.12419952526688575 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 556 Avg_loss: 0.11991299204528331 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 557 Avg_loss: 0.1163269441574812 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 558 Avg_loss: 0.1133105780929327 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 559 Avg_loss: 0.11089154407382011 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 560 Avg_loss: 0.10883314944803715 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 561 Avg_loss: 0.10699737817049026 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 562 Avg_loss: 0.10526145845651627 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 563 Avg_loss: 0.1037083923816681 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 564 Avg_loss: 0.10226194187998772 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 565 Avg_loss: 0.10094523020088672 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 566 Avg_loss: 0.09971288666129112 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 567 Avg_loss: 0.09859999381005764 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 568 Avg_loss: 0.09758468084037304 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 569 Avg_loss: 0.09655146822333335 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 570 Avg_loss: 0.09560010023415089 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 571 Avg_loss: 0.09471079334616661 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 572 Avg_loss: 0.09385646693408489 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 573 Avg_loss: 0.09279215224087238 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 574 Avg_loss: 0.0917412381619215 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 575 Avg_loss: 0.090626797452569 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 576 Avg_loss: 0.08895637616515159 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 577 Avg_loss: 0.0869993545114994 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 578 Avg_loss: 0.08580409251153469 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 579 Avg_loss: 0.08506618477404118 training accuracy: 1.0 test accuracy: 0.25170068027210885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 580 Avg_loss: 0.08435588479042053 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 581 Avg_loss: 0.08364051356911659 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 582 Avg_loss: 0.08297425881028175 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 583 Avg_loss: 0.08237416967749596 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 584 Avg_loss: 0.08180462904274463 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 585 Avg_loss: 0.0812205035239458 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 586 Avg_loss: 0.08066442534327507 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 587 Avg_loss: 0.0801190335303545 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 588 Avg_loss: 0.0796135026961565 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 589 Avg_loss: 0.07911586202681065 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 590 Avg_loss: 0.07856060452759266 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 591 Avg_loss: 0.07804713398218155 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 592 Avg_loss: 0.07759177833795547 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 593 Avg_loss: 0.07713520973920822 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 594 Avg_loss: 0.0766231331974268 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 595 Avg_loss: 0.076162214204669 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 596 Avg_loss: 0.07573544606566429 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 597 Avg_loss: 0.07530291080474853 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 598 Avg_loss: 0.07490831837058068 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 599 Avg_loss: 0.07448423579335213 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 600 Avg_loss: 0.07401155717670918 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 601 Avg_loss: 0.07356719747185707 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 602 Avg_loss: 0.07313457168638707 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 603 Avg_loss: 0.07275782935321332 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 604 Avg_loss: 0.07237048074603081 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 605 Avg_loss: 0.07196924015879631 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 606 Avg_loss: 0.0715633150190115 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 607 Avg_loss: 0.07117283791303634 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 608 Avg_loss: 0.07082920074462891 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 609 Avg_loss: 0.0704596508294344 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 610 Avg_loss: 0.07006946764886379 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 611 Avg_loss: 0.06967694871127605 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 612 Avg_loss: 0.0693217821419239 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 613 Avg_loss: 0.06895245313644409 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 614 Avg_loss: 0.06855676285922527 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 615 Avg_loss: 0.06816405728459358 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 616 Avg_loss: 0.06781894490122795 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 617 Avg_loss: 0.0674873024225235 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 618 Avg_loss: 0.0671183031052351 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 619 Avg_loss: 0.06674884110689164 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 620 Avg_loss: 0.06639428660273552 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 621 Avg_loss: 0.0660727608948946 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 622 Avg_loss: 0.06576974801719189 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 623 Avg_loss: 0.06547831520438194 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 624 Avg_loss: 0.06514809280633926 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 625 Avg_loss: 0.06481401212513446 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 626 Avg_loss: 0.06449230574071407 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 627 Avg_loss: 0.06417490504682064 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 628 Avg_loss: 0.06387286428362131 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 629 Avg_loss: 0.06360311973839998 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 630 Avg_loss: 0.06329759377986192 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 631 Avg_loss: 0.06301349326968193 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 632 Avg_loss: 0.06268752049654722 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 633 Avg_loss: 0.06237468849867582 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 634 Avg_loss: 0.06205118428915739 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 635 Avg_loss: 0.0617548068985343 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 636 Avg_loss: 0.06146461591124534 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 637 Avg_loss: 0.061211584508419035 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 638 Avg_loss: 0.06095951311290264 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 639 Avg_loss: 0.06067858599126339 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 640 Avg_loss: 0.06036413609981537 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 641 Avg_loss: 0.06009212676435709 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 642 Avg_loss: 0.059807277657091616 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 643 Avg_loss: 0.05952714122831822 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 644 Avg_loss: 0.05923693962395191 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 645 Avg_loss: 0.05897330548614264 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 646 Avg_loss: 0.05874636005610227 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 647 Avg_loss: 0.05850027203559875 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 648 Avg_loss: 0.058207285962998866 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 649 Avg_loss: 0.05793991405516863 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 650 Avg_loss: 0.05773853994905949 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 651 Avg_loss: 0.05753001067787409 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 652 Avg_loss: 0.057244152575731275 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 653 Avg_loss: 0.05694616511464119 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 654 Avg_loss: 0.05666507463902235 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 655 Avg_loss: 0.05642444267868996 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 656 Avg_loss: 0.056193030439317226 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 657 Avg_loss: 0.055918694287538526 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 658 Avg_loss: 0.055643478967249395 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 659 Avg_loss: 0.055401405319571495 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 660 Avg_loss: 0.0551864730194211 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 661 Avg_loss: 0.05493936911225319 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 662 Avg_loss: 0.05466099511831999 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 663 Avg_loss: 0.05439444538205862 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 664 Avg_loss: 0.054158668592572214 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 665 Avg_loss: 0.05392599068582058 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 666 Avg_loss: 0.053657644614577296 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 667 Avg_loss: 0.05338131301105022 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 668 Avg_loss: 0.05312718208879232 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 669 Avg_loss: 0.05289538577198982 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 670 Avg_loss: 0.052655169367790224 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 671 Avg_loss: 0.05243288669735193 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 672 Avg_loss: 0.052215179055929185 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 673 Avg_loss: 0.052000160329043865 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 674 Avg_loss: 0.05174097660928965 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 675 Avg_loss: 0.051500148884952066 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 676 Avg_loss: 0.051299881935119626 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 677 Avg_loss: 0.05109893325716257 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 678 Avg_loss: 0.05089151170104742 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 679 Avg_loss: 0.050643626414239404 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 680 Avg_loss: 0.05039454959332943 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 681 Avg_loss: 0.05017972961068153 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 682 Avg_loss: 0.04997220523655414 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 683 Avg_loss: 0.04976226110011339 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 684 Avg_loss: 0.04955543037503958 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 685 Avg_loss: 0.049335303343832494 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 686 Avg_loss: 0.049126442335546014 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 687 Avg_loss: 0.04895855151116848 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 688 Avg_loss: 0.04874801859259605 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 689 Avg_loss: 0.04852781631052494 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 690 Avg_loss: 0.04829917810857296 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 691 Avg_loss: 0.04808632507920265 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 692 Avg_loss: 0.04791250098496676 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 693 Avg_loss: 0.047750828228890894 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 694 Avg_loss: 0.047524523362517355 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 695 Avg_loss: 0.047311171516776086 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 696 Avg_loss: 0.047110901586711405 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 697 Avg_loss: 0.046929591707885264 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 698 Avg_loss: 0.0467389851808548 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 699 Avg_loss: 0.046550086326897146 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 700 Avg_loss: 0.04634423963725567 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 701 Avg_loss: 0.0461395550519228 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 702 Avg_loss: 0.04595823436975479 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 703 Avg_loss: 0.045787658914923667 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 704 Avg_loss: 0.04560436364263296 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 705 Avg_loss: 0.04541480951011181 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 706 Avg_loss: 0.045230303145945075 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 707 Avg_loss: 0.04505437556654215 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 708 Avg_loss: 0.044875933602452275 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 709 Avg_loss: 0.0446967426687479 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 710 Avg_loss: 0.04453108254820108 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 711 Avg_loss: 0.04437801036983728 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 712 Avg_loss: 0.04420528467744589 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 713 Avg_loss: 0.04404409658163786 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 714 Avg_loss: 0.0438531443476677 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 715 Avg_loss: 0.04369844477623701 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 716 Avg_loss: 0.04353943038731813 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 717 Avg_loss: 0.04337351657450199 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 718 Avg_loss: 0.043186309188604353 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 719 Avg_loss: 0.043004279397428034 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 720 Avg_loss: 0.04285169895738363 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 721 Avg_loss: 0.04269787333905697 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 722 Avg_loss: 0.04252695217728615 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 723 Avg_loss: 0.042364248633384706 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 724 Avg_loss: 0.04221800472587347 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 725 Avg_loss: 0.04207318890839815 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 726 Avg_loss: 0.04190458711236715 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 727 Avg_loss: 0.04175158254802227 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 728 Avg_loss: 0.041604107990860936 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 729 Avg_loss: 0.04144613109529018 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 730 Avg_loss: 0.04129044804722071 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 731 Avg_loss: 0.041195501759648326 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 732 Avg_loss: 0.041070698760449886 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 733 Avg_loss: 0.040897159837186337 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 734 Avg_loss: 0.04075465817004442 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 735 Avg_loss: 0.04060706403106451 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 736 Avg_loss: 0.04048647116869688 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 737 Avg_loss: 0.04032872505486011 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 738 Avg_loss: 0.040153407491743565 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 739 Avg_loss: 0.04001081101596356 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 740 Avg_loss: 0.03986876718699932 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 741 Avg_loss: 0.039761843532323836 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 742 Avg_loss: 0.03961976058781147 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 743 Avg_loss: 0.039494432881474494 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 744 Avg_loss: 0.039345255494117735 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 745 Avg_loss: 0.03919483944773674 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 746 Avg_loss: 0.03909835889935494 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 747 Avg_loss: 0.03898917082697153 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 748 Avg_loss: 0.0388415539637208 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 749 Avg_loss: 0.03871674910187721 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 750 Avg_loss: 0.03864902351051569 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 751 Avg_loss: 0.03856616206467152 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 752 Avg_loss: 0.03839873727411032 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 753 Avg_loss: 0.038225176930427554 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 754 Avg_loss: 0.03807731326669454 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 755 Avg_loss: 0.03796445354819298 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 756 Avg_loss: 0.03785562552511692 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 757 Avg_loss: 0.03772554993629455 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 758 Avg_loss: 0.03762375470250845 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 759 Avg_loss: 0.037549044191837314 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 760 Avg_loss: 0.037479250505566594 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 761 Avg_loss: 0.037347161956131456 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 762 Avg_loss: 0.03717581313103437 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 763 Avg_loss: 0.03703564405441284 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 764 Avg_loss: 0.036974379792809486 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 765 Avg_loss: 0.03687345925718546 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 766 Avg_loss: 0.03675928562879562 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 767 Avg_loss: 0.036724884808063504 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 768 Avg_loss: 0.036719081178307536 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 769 Avg_loss: 0.036568178609013555 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 770 Avg_loss: 0.03639297429472208 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 771 Avg_loss: 0.03636399675160647 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 772 Avg_loss: 0.03620489481836557 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 773 Avg_loss: 0.03612340539693833 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 774 Avg_loss: 0.036041632667183875 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 775 Avg_loss: 0.035873929411172865 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 776 Avg_loss: 0.03571909870952368 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 777 Avg_loss: 0.035610188730061054 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 778 Avg_loss: 0.03554018773138523 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 779 Avg_loss: 0.03542785551398993 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 780 Avg_loss: 0.0353110808879137 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 781 Avg_loss: 0.03520801961421967 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 782 Avg_loss: 0.035113835148513316 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 783 Avg_loss: 0.035139144584536555 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 784 Avg_loss: 0.03511036988347769 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 785 Avg_loss: 0.03498470261693001 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 786 Avg_loss: 0.03480496779084206 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 787 Avg_loss: 0.03468656707555055 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 788 Avg_loss: 0.034660354070365426 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 789 Avg_loss: 0.03460313864052296 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 790 Avg_loss: 0.034506898000836374 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 791 Avg_loss: 0.03442620486021042 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 792 Avg_loss: 0.03427550364285707 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 793 Avg_loss: 0.03419981449842453 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 794 Avg_loss: 0.034136738441884515 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 795 Avg_loss: 0.03401961773633957 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 796 Avg_loss: 0.03398007601499557 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 797 Avg_loss: 0.0339537600055337 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 798 Avg_loss: 0.03392825443297624 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 799 Avg_loss: 0.03377897497266531 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 800 Avg_loss: 0.03366594128310681 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 801 Avg_loss: 0.033597922325134276 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 802 Avg_loss: 0.03352969847619534 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 803 Avg_loss: 0.03402101192623377 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 804 Avg_loss: 0.03373349029570818 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 805 Avg_loss: 0.033603662997484206 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 806 Avg_loss: 0.033500817604362965 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 807 Avg_loss: 0.03331381566822529 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 808 Avg_loss: 0.03316080253571272 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 809 Avg_loss: 0.03324358314275742 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 810 Avg_loss: 0.03314815759658814 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 811 Avg_loss: 0.03296629879623651 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 812 Avg_loss: 0.032909978181123734 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 813 Avg_loss: 0.03282845672219992 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 814 Avg_loss: 0.032745306566357615 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 815 Avg_loss: 0.03261369355022907 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 816 Avg_loss: 0.03250236939638853 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 817 Avg_loss: 0.032373695820569995 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 818 Avg_loss: 0.032296435162425044 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 819 Avg_loss: 0.0322676744312048 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 820 Avg_loss: 0.032193659152835605 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 821 Avg_loss: 0.03210580833256245 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 822 Avg_loss: 0.032052166666835545 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 823 Avg_loss: 0.031986149679869416 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 824 Avg_loss: 0.032011326123028996 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 825 Avg_loss: 0.03198291640728712 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 826 Avg_loss: 0.0319705200381577 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 827 Avg_loss: 0.032143722474575046 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 828 Avg_loss: 0.03208828400820494 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 829 Avg_loss: 0.031912428047508004 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 830 Avg_loss: 0.03197361072525382 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 831 Avg_loss: 0.031955167092382906 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 832 Avg_loss: 0.03188026184216142 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 833 Avg_loss: 0.03178866859525442 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 834 Avg_loss: 0.03171248622238636 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 835 Avg_loss: 0.03156283097341657 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 836 Avg_loss: 0.031400269269943236 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 837 Avg_loss: 0.03126650182530284 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 838 Avg_loss: 0.031169467885047198 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 839 Avg_loss: 0.031090890802443028 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 840 Avg_loss: 0.031026860885322093 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 841 Avg_loss: 0.030972116533666848 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 842 Avg_loss: 0.030885003879666327 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 843 Avg_loss: 0.03085654219612479 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 844 Avg_loss: 0.030864330008625984 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 845 Avg_loss: 0.030879933387041092 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 846 Avg_loss: 0.030740568414330482 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 847 Avg_loss: 0.03062793370336294 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 848 Avg_loss: 0.0306272029876709 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 849 Avg_loss: 0.03064547721296549 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 850 Avg_loss: 0.03055320829153061 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 851 Avg_loss: 0.0304457432590425 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 852 Avg_loss: 0.03039158582687378 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 853 Avg_loss: 0.03032727027311921 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 854 Avg_loss: 0.030352424085140228 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 855 Avg_loss: 0.030250535905361177 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 856 Avg_loss: 0.030199631210416557 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 857 Avg_loss: 0.03013442913070321 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 858 Avg_loss: 0.03011735612526536 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 859 Avg_loss: 0.03003907985985279 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 860 Avg_loss: 0.029986467957496644 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 861 Avg_loss: 0.030059147719293834 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 862 Avg_loss: 0.030302152782678605 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 863 Avg_loss: 0.030236301105469467 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 864 Avg_loss: 0.030050677992403508 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 865 Avg_loss: 0.029890026617795228 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 866 Avg_loss: 0.029864908196032047 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 867 Avg_loss: 0.029883914347738027 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 868 Avg_loss: 0.02979413578286767 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 869 Avg_loss: 0.029646239895373582 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 870 Avg_loss: 0.029589894320815803 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 871 Avg_loss: 0.029551551211625338 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 872 Avg_loss: 0.02945602620020509 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 873 Avg_loss: 0.029372422397136687 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 874 Avg_loss: 0.029272369761019944 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 875 Avg_loss: 0.029220724012702703 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 876 Avg_loss: 0.02919369200244546 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 877 Avg_loss: 0.029091692250221967 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 878 Avg_loss: 0.029028565809130668 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 879 Avg_loss: 0.02905464917421341 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 880 Avg_loss: 0.028964429069310425 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 881 Avg_loss: 0.028914665523916482 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 882 Avg_loss: 0.028909995499998332 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 883 Avg_loss: 0.028892980236560107 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 884 Avg_loss: 0.03252417286857963 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 885 Avg_loss: 0.5337160784751177 training accuracy: 0.8375 test accuracy: 0.30612244897959184\n",
      "Epoch: 886 Avg_loss: 0.6571148633956909 training accuracy: 0.8375 test accuracy: 0.29931972789115646\n",
      "Epoch: 887 Avg_loss: 0.42562869042158125 training accuracy: 0.9375 test accuracy: 0.2789115646258503\n",
      "Epoch: 888 Avg_loss: 0.3062719292938709 training accuracy: 0.9625 test accuracy: 0.2653061224489796\n",
      "Epoch: 889 Avg_loss: 0.24495234861969947 training accuracy: 0.984375 test accuracy: 0.2857142857142857\n",
      "Epoch: 890 Avg_loss: 0.21312206611037254 training accuracy: 0.990625 test accuracy: 0.2857142857142857\n",
      "Epoch: 891 Avg_loss: 0.19361093640327454 training accuracy: 0.990625 test accuracy: 0.2857142857142857\n",
      "Epoch: 892 Avg_loss: 0.18111074715852737 training accuracy: 0.990625 test accuracy: 0.29931972789115646\n",
      "Epoch: 893 Avg_loss: 0.1706789806485176 training accuracy: 0.990625 test accuracy: 0.29931972789115646\n",
      "Epoch: 894 Avg_loss: 0.1599796734750271 training accuracy: 0.99375 test accuracy: 0.2925170068027211\n",
      "Epoch: 895 Avg_loss: 0.1517838016152382 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 896 Avg_loss: 0.14523805305361748 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 897 Avg_loss: 0.1399873323738575 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 898 Avg_loss: 0.1354184616357088 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 899 Avg_loss: 0.13123224303126335 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 900 Avg_loss: 0.12716442681849002 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 901 Avg_loss: 0.12251293994486331 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 902 Avg_loss: 0.11898159198462963 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 903 Avg_loss: 0.11598050370812416 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 904 Avg_loss: 0.11332031972706318 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 905 Avg_loss: 0.11089426875114441 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 906 Avg_loss: 0.10864056311547757 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 907 Avg_loss: 0.10650519244372844 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 908 Avg_loss: 0.10452678240835667 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 909 Avg_loss: 0.10268676429986953 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 910 Avg_loss: 0.10092748031020164 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 911 Avg_loss: 0.09919347316026687 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 912 Avg_loss: 0.09773937352001667 training accuracy: 1.0 test accuracy: 0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 913 Avg_loss: 0.09646247774362564 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 914 Avg_loss: 0.09499972127377987 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 915 Avg_loss: 0.0935826350003481 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 916 Avg_loss: 0.09226408153772354 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 917 Avg_loss: 0.09098605252802372 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 918 Avg_loss: 0.08976242765784263 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 919 Avg_loss: 0.08858266398310662 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 920 Avg_loss: 0.08743434399366379 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 921 Avg_loss: 0.08635539337992668 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 922 Avg_loss: 0.08527978472411632 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 923 Avg_loss: 0.08425543196499348 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 924 Avg_loss: 0.08330354653298855 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 925 Avg_loss: 0.0823239490389824 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 926 Avg_loss: 0.08138811141252518 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 927 Avg_loss: 0.08051977455615997 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 928 Avg_loss: 0.07966825701296329 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 929 Avg_loss: 0.07879094555974006 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 930 Avg_loss: 0.07795246578752994 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 931 Avg_loss: 0.07710731886327267 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 932 Avg_loss: 0.07630070000886917 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 933 Avg_loss: 0.07554931938648224 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 934 Avg_loss: 0.07478876374661922 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 935 Avg_loss: 0.07403137423098087 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 936 Avg_loss: 0.07333110943436623 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 937 Avg_loss: 0.0726494949311018 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 938 Avg_loss: 0.07197193428874016 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 939 Avg_loss: 0.07126789651811123 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 940 Avg_loss: 0.07058694399893284 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 941 Avg_loss: 0.06995043382048607 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 942 Avg_loss: 0.06931807398796082 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 943 Avg_loss: 0.06873705871403217 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 944 Avg_loss: 0.06813216581940651 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 945 Avg_loss: 0.06750673092901707 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 946 Avg_loss: 0.06692316308617592 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 947 Avg_loss: 0.06634939201176167 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 948 Avg_loss: 0.06578366868197918 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 949 Avg_loss: 0.06524517349898815 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 950 Avg_loss: 0.06470097005367278 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 951 Avg_loss: 0.0641939977183938 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 952 Avg_loss: 0.06368220448493958 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 953 Avg_loss: 0.06319590043276549 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 954 Avg_loss: 0.06274597533047199 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 955 Avg_loss: 0.06223463863134384 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 956 Avg_loss: 0.06174292527139187 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 957 Avg_loss: 0.06123784575611353 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 958 Avg_loss: 0.06078250259160996 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 959 Avg_loss: 0.060320707783102986 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 960 Avg_loss: 0.05985709559172392 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 961 Avg_loss: 0.059434990584850314 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 962 Avg_loss: 0.05903053302317858 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 963 Avg_loss: 0.05861173123121262 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 964 Avg_loss: 0.058149739354848864 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 965 Avg_loss: 0.0577079001814127 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 966 Avg_loss: 0.057328686490654944 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 967 Avg_loss: 0.05695492140948773 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 968 Avg_loss: 0.05653770044445992 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 969 Avg_loss: 0.05612012930214405 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 970 Avg_loss: 0.05574658662080765 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 971 Avg_loss: 0.05536716673523188 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 972 Avg_loss: 0.05496109686791897 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 973 Avg_loss: 0.05459931716322899 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 974 Avg_loss: 0.05424426682293415 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 975 Avg_loss: 0.053899789974093434 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 976 Avg_loss: 0.05356943979859352 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 977 Avg_loss: 0.053198146261274816 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 978 Avg_loss: 0.05281422473490238 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 979 Avg_loss: 0.05246491823345423 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 980 Avg_loss: 0.05211337562650442 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 981 Avg_loss: 0.051785103417932986 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 982 Avg_loss: 0.05145247578620911 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 983 Avg_loss: 0.05112697556614876 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 984 Avg_loss: 0.05080815646797419 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 985 Avg_loss: 0.05049838870763779 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 986 Avg_loss: 0.0501913670450449 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 987 Avg_loss: 0.04989065155386925 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 988 Avg_loss: 0.0495723744854331 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 989 Avg_loss: 0.04925449769943953 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 990 Avg_loss: 0.04897808916866779 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 991 Avg_loss: 0.048679751716554163 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 992 Avg_loss: 0.04838216584175825 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 993 Avg_loss: 0.04809746015816927 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 994 Avg_loss: 0.04779824949800968 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 995 Avg_loss: 0.047520844638347624 training accuracy: 1.0 test accuracy: 0.2925170068027211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 996 Avg_loss: 0.04726096168160439 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 997 Avg_loss: 0.046967181377112865 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 998 Avg_loss: 0.04672219101339579 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 999 Avg_loss: 0.04648846108466387 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1000 Avg_loss: 0.04620275441557169 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1001 Avg_loss: 0.0459204226732254 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1002 Avg_loss: 0.04566030614078045 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1003 Avg_loss: 0.04538922198116779 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1004 Avg_loss: 0.04510658401995897 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1005 Avg_loss: 0.04486171118915081 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1006 Avg_loss: 0.04464252404868603 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1007 Avg_loss: 0.04439614359289408 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1008 Avg_loss: 0.04415558502078056 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1009 Avg_loss: 0.04390353299677372 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1010 Avg_loss: 0.04365459959954023 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1011 Avg_loss: 0.04344928991049528 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1012 Avg_loss: 0.0431965347379446 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1013 Avg_loss: 0.04295328427106142 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1014 Avg_loss: 0.04279350247234106 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1015 Avg_loss: 0.04256019219756126 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1016 Avg_loss: 0.04229739401489496 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1017 Avg_loss: 0.042091885954141615 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1018 Avg_loss: 0.04187123440206051 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1019 Avg_loss: 0.041652440652251245 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1020 Avg_loss: 0.04146447274833918 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1021 Avg_loss: 0.041254249028861524 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1022 Avg_loss: 0.04104445744305849 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1023 Avg_loss: 0.04083039201796055 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1024 Avg_loss: 0.04061271883547306 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1025 Avg_loss: 0.04042676817625761 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1026 Avg_loss: 0.04023882821202278 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1027 Avg_loss: 0.040038065426051615 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1028 Avg_loss: 0.03984028119593859 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1029 Avg_loss: 0.03967241533100605 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1030 Avg_loss: 0.039492919109761715 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1031 Avg_loss: 0.03932240474969149 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1032 Avg_loss: 0.039136136323213576 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1033 Avg_loss: 0.038916714303195474 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1034 Avg_loss: 0.03873292244970798 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1035 Avg_loss: 0.03860681764781475 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1036 Avg_loss: 0.0384220015257597 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1037 Avg_loss: 0.03821308556944132 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1038 Avg_loss: 0.03804685603827238 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1039 Avg_loss: 0.037869175896048546 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1040 Avg_loss: 0.037705324776470664 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1041 Avg_loss: 0.03754762317985296 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1042 Avg_loss: 0.03736487030982971 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1043 Avg_loss: 0.037206622399389745 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1044 Avg_loss: 0.03704061377793551 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1045 Avg_loss: 0.03686135821044445 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1046 Avg_loss: 0.036741172708570954 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1047 Avg_loss: 0.03662780486047268 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1048 Avg_loss: 0.03644467033445835 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1049 Avg_loss: 0.03624170850962401 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1050 Avg_loss: 0.03609244972467422 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1051 Avg_loss: 0.03602166138589382 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1052 Avg_loss: 0.03587863277643919 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1053 Avg_loss: 0.0356964310631156 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1054 Avg_loss: 0.03554466646164656 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1055 Avg_loss: 0.035419501923024656 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1056 Avg_loss: 0.035282164067029956 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1057 Avg_loss: 0.03510597888380289 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1058 Avg_loss: 0.03496001735329628 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1059 Avg_loss: 0.034859922528266904 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1060 Avg_loss: 0.03472420200705528 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1061 Avg_loss: 0.03460006844252348 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1062 Avg_loss: 0.0344644021242857 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1063 Avg_loss: 0.03436068706214428 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1064 Avg_loss: 0.034255124256014825 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1065 Avg_loss: 0.03409858047962189 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1066 Avg_loss: 0.033994578011333945 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1067 Avg_loss: 0.03389491643756628 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1068 Avg_loss: 0.033725828118622306 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1069 Avg_loss: 0.03355738427489996 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1070 Avg_loss: 0.03342277128249407 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1071 Avg_loss: 0.03336881548166275 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1072 Avg_loss: 0.03327666763216257 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1073 Avg_loss: 0.033123050816357136 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1074 Avg_loss: 0.03297716118395329 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1075 Avg_loss: 0.03287254795432091 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1076 Avg_loss: 0.03274946939200163 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1077 Avg_loss: 0.03265931624919176 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1078 Avg_loss: 0.03262464012950659 training accuracy: 1.0 test accuracy: 0.3197278911564626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1079 Avg_loss: 0.03255373556166887 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1080 Avg_loss: 0.03238160852342844 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1081 Avg_loss: 0.03227316085249186 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1082 Avg_loss: 0.032189793139696124 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1083 Avg_loss: 0.03209793688729405 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1084 Avg_loss: 0.0320220198482275 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1085 Avg_loss: 0.03198244823142886 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1086 Avg_loss: 0.031803755834698674 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1087 Avg_loss: 0.031633139867335555 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1088 Avg_loss: 0.03153947573155165 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1089 Avg_loss: 0.031471874285489324 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1090 Avg_loss: 0.031375956069678065 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1091 Avg_loss: 0.03129672640934587 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1092 Avg_loss: 0.0312792788259685 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1093 Avg_loss: 0.031240836810320617 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1094 Avg_loss: 0.031133153662085532 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1095 Avg_loss: 0.031035424396395683 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1096 Avg_loss: 0.030961461924016477 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1097 Avg_loss: 0.03083424540236592 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1098 Avg_loss: 0.0307178589515388 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1099 Avg_loss: 0.030672646686434747 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1100 Avg_loss: 0.030628058314323425 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1101 Avg_loss: 0.030550343822687863 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1102 Avg_loss: 0.030435954965651036 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1103 Avg_loss: 0.030292624793946742 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1104 Avg_loss: 0.03021924998611212 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1105 Avg_loss: 0.030130960699170827 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1106 Avg_loss: 0.030037170555442572 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1107 Avg_loss: 0.02993157971650362 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1108 Avg_loss: 0.02999931527301669 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1109 Avg_loss: 0.03009163709357381 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1110 Avg_loss: 0.02996180737391114 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1111 Avg_loss: 0.02981255007907748 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1112 Avg_loss: 0.02969143372029066 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1113 Avg_loss: 0.029711086116731168 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1114 Avg_loss: 0.029626622051000594 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1115 Avg_loss: 0.02949208114296198 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1116 Avg_loss: 0.02935764444991946 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1117 Avg_loss: 0.02927952716127038 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1118 Avg_loss: 0.029182319156825544 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1119 Avg_loss: 0.029081606585532428 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1120 Avg_loss: 0.029216392338275908 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1121 Avg_loss: 0.029323430638760327 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1122 Avg_loss: 0.029126816149801015 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1123 Avg_loss: 0.02899032449349761 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1124 Avg_loss: 0.028890324290841818 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1125 Avg_loss: 0.028813495952636003 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1126 Avg_loss: 0.028763326350599527 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1127 Avg_loss: 0.02876506047323346 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1128 Avg_loss: 0.028625928051769733 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1129 Avg_loss: 0.028536127880215645 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1130 Avg_loss: 0.02844257801771164 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1131 Avg_loss: 0.028603010065853595 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1132 Avg_loss: 0.028585111163556574 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1133 Avg_loss: 0.028366983961313964 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1134 Avg_loss: 0.028201874811202288 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1135 Avg_loss: 0.028134870156645776 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1136 Avg_loss: 0.028072740137577056 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1137 Avg_loss: 0.028039153665304184 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1138 Avg_loss: 0.028052826598286628 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1139 Avg_loss: 0.02796735633164644 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1140 Avg_loss: 0.027878390904515982 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1141 Avg_loss: 0.027833206113427877 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1142 Avg_loss: 0.027782212756574155 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1143 Avg_loss: 0.027750903367996217 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1144 Avg_loss: 0.027712848037481308 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1145 Avg_loss: 0.027732831053435804 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1146 Avg_loss: 0.027671732380986212 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1147 Avg_loss: 0.02771438118070364 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1148 Avg_loss: 0.027640325576066972 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1149 Avg_loss: 0.027531739976257085 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1150 Avg_loss: 0.027499405015259982 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1151 Avg_loss: 0.027458412386476994 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1152 Avg_loss: 0.027423544228076933 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1153 Avg_loss: 0.0273624986410141 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1154 Avg_loss: 0.027465610299259424 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1155 Avg_loss: 0.027513718232512474 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1156 Avg_loss: 0.027390738762915135 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1157 Avg_loss: 0.027370405569672584 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1158 Avg_loss: 0.02733902130275965 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1159 Avg_loss: 0.027190701197832824 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1160 Avg_loss: 0.02707126075401902 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1161 Avg_loss: 0.026999616995453835 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1162 Avg_loss: 0.026959355734288693 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1163 Avg_loss: 0.02691850457340479 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1164 Avg_loss: 0.026821483857929707 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1165 Avg_loss: 0.026764411106705667 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1166 Avg_loss: 0.026979155000299217 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1167 Avg_loss: 0.02713358262553811 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1168 Avg_loss: 0.026973938476294278 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1169 Avg_loss: 0.026835174672305583 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1170 Avg_loss: 0.02677145255729556 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1171 Avg_loss: 0.08086926899850369 training accuracy: 0.98125 test accuracy: 0.23129251700680273\n",
      "Epoch: 1172 Avg_loss: 0.402190625667572 training accuracy: 0.896875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1173 Avg_loss: 0.46024961322546004 training accuracy: 0.921875 test accuracy: 0.2585034013605442\n",
      "Epoch: 1174 Avg_loss: 0.2878022015094757 training accuracy: 0.965625 test accuracy: 0.23809523809523808\n",
      "Epoch: 1175 Avg_loss: 0.2021738201379776 training accuracy: 0.984375 test accuracy: 0.2585034013605442\n",
      "Epoch: 1176 Avg_loss: 0.171302992105484 training accuracy: 0.990625 test accuracy: 0.2789115646258503\n",
      "Epoch: 1177 Avg_loss: 0.1506502017378807 training accuracy: 0.99375 test accuracy: 0.2925170068027211\n",
      "Epoch: 1178 Avg_loss: 0.14084228612482547 training accuracy: 0.99375 test accuracy: 0.2925170068027211\n",
      "Epoch: 1179 Avg_loss: 0.13363507501780986 training accuracy: 0.99375 test accuracy: 0.29931972789115646\n",
      "Epoch: 1180 Avg_loss: 0.12741353064775468 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 1181 Avg_loss: 0.12132789678871632 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 1182 Avg_loss: 0.11535679511725902 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 1183 Avg_loss: 0.11019095033407211 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1184 Avg_loss: 0.10568926110863686 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1185 Avg_loss: 0.10245836190879345 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1186 Avg_loss: 0.09977295696735382 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1187 Avg_loss: 0.0973748054355383 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1188 Avg_loss: 0.09524157457053661 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1189 Avg_loss: 0.09344306774437428 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1190 Avg_loss: 0.09167183414101601 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1191 Avg_loss: 0.08990298546850681 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1192 Avg_loss: 0.0882621567696333 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1193 Avg_loss: 0.0867739636451006 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1194 Avg_loss: 0.08535096198320388 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1195 Avg_loss: 0.08400056138634682 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1196 Avg_loss: 0.08275474682450294 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1197 Avg_loss: 0.0815665613859892 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1198 Avg_loss: 0.08043798841536046 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1199 Avg_loss: 0.07936620078980923 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1200 Avg_loss: 0.07826972268521785 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1201 Avg_loss: 0.07723912112414837 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1202 Avg_loss: 0.07621466293931008 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1203 Avg_loss: 0.07520322874188423 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1204 Avg_loss: 0.074298807233572 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1205 Avg_loss: 0.07342852391302586 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1206 Avg_loss: 0.07256364673376084 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1207 Avg_loss: 0.07177825868129731 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1208 Avg_loss: 0.0710005048662424 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1209 Avg_loss: 0.07025958821177483 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1210 Avg_loss: 0.06958405002951622 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1211 Avg_loss: 0.06893244348466396 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1212 Avg_loss: 0.06822984851896763 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1213 Avg_loss: 0.06748982630670071 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1214 Avg_loss: 0.06676913313567638 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1215 Avg_loss: 0.06609387211501598 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1216 Avg_loss: 0.06550162844359875 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1217 Avg_loss: 0.06490404047071933 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1218 Avg_loss: 0.06427412666380405 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1219 Avg_loss: 0.06368629261851311 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1220 Avg_loss: 0.06313306763768196 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1221 Avg_loss: 0.06256233751773835 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1222 Avg_loss: 0.06202971693128347 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1223 Avg_loss: 0.06150167416781187 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1224 Avg_loss: 0.06094594188034534 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1225 Avg_loss: 0.06041523702442646 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1226 Avg_loss: 0.05994610618799925 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1227 Avg_loss: 0.05944436080753803 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1228 Avg_loss: 0.058915534429252146 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1229 Avg_loss: 0.05846393294632435 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1230 Avg_loss: 0.05800009276717901 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1231 Avg_loss: 0.05750129520893097 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1232 Avg_loss: 0.05707345064729452 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1233 Avg_loss: 0.056655692867934704 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1234 Avg_loss: 0.05619696695357561 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1235 Avg_loss: 0.05573768559843302 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1236 Avg_loss: 0.055289806239306925 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1237 Avg_loss: 0.054892569035291675 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1238 Avg_loss: 0.05448111537843943 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1239 Avg_loss: 0.05408512558788061 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1240 Avg_loss: 0.05367497447878122 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1241 Avg_loss: 0.05325513519346714 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1242 Avg_loss: 0.0528906162828207 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1243 Avg_loss: 0.052535402588546276 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1244 Avg_loss: 0.052141016349196434 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1245 Avg_loss: 0.05175280570983887 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1246 Avg_loss: 0.05136675350368023 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1247 Avg_loss: 0.050996392592787744 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1248 Avg_loss: 0.05067271254956722 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1249 Avg_loss: 0.05033227819949389 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1250 Avg_loss: 0.04996717926114798 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1251 Avg_loss: 0.04960042014718056 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1252 Avg_loss: 0.049283971264958384 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1253 Avg_loss: 0.04897078163921833 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1254 Avg_loss: 0.04860260877758264 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1255 Avg_loss: 0.04829458277672529 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1256 Avg_loss: 0.0479968985542655 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1257 Avg_loss: 0.04766014441847801 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1258 Avg_loss: 0.047308332100510594 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1259 Avg_loss: 0.046987931989133355 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1260 Avg_loss: 0.04670383781194687 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1261 Avg_loss: 0.04643590729683637 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1262 Avg_loss: 0.04614414013922215 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1263 Avg_loss: 0.04583399165421724 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1264 Avg_loss: 0.045507348887622354 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1265 Avg_loss: 0.04521536864340305 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1266 Avg_loss: 0.04496344476938248 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1267 Avg_loss: 0.04467732477933169 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1268 Avg_loss: 0.044391377829015255 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1269 Avg_loss: 0.044153261184692386 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1270 Avg_loss: 0.04392835386097431 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1271 Avg_loss: 0.04363016206771135 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1272 Avg_loss: 0.043361263908445837 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1273 Avg_loss: 0.04316053744405508 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1274 Avg_loss: 0.04292548391968012 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1275 Avg_loss: 0.042735175043344495 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1276 Avg_loss: 0.04243600536137819 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1277 Avg_loss: 0.042182833701372144 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1278 Avg_loss: 0.04189624842256308 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1279 Avg_loss: 0.041584102995693685 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1280 Avg_loss: 0.041294340416789053 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1281 Avg_loss: 0.04108515325933695 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1282 Avg_loss: 0.04087955038994551 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1283 Avg_loss: 0.040626602992415425 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1284 Avg_loss: 0.04037342742085457 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1285 Avg_loss: 0.04016076661646366 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1286 Avg_loss: 0.04003364685922861 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1287 Avg_loss: 0.03979297932237387 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1288 Avg_loss: 0.03951065372675657 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1289 Avg_loss: 0.03928029295057058 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1290 Avg_loss: 0.03907154761254787 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1291 Avg_loss: 0.0388630298897624 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1292 Avg_loss: 0.03862840160727501 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1293 Avg_loss: 0.03838448375463486 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1294 Avg_loss: 0.03822144716978073 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1295 Avg_loss: 0.038044930621981624 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1296 Avg_loss: 0.03779205251485109 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1297 Avg_loss: 0.03757010307163 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1298 Avg_loss: 0.03737001251429319 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1299 Avg_loss: 0.03720276113599539 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1300 Avg_loss: 0.03702421635389328 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1301 Avg_loss: 0.03683224990963936 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1302 Avg_loss: 0.036616375669837 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1303 Avg_loss: 0.03643396999686956 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1304 Avg_loss: 0.03626097273081541 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1305 Avg_loss: 0.03606820423156023 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1306 Avg_loss: 0.035888081230223176 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1307 Avg_loss: 0.0357171293348074 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1308 Avg_loss: 0.03555810526013374 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1309 Avg_loss: 0.03535251095890999 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1310 Avg_loss: 0.03515092395246029 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1311 Avg_loss: 0.035003204829990864 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1312 Avg_loss: 0.03480785563588142 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1313 Avg_loss: 0.03460050486028195 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1314 Avg_loss: 0.03444418720901012 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1315 Avg_loss: 0.03430009186267853 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1316 Avg_loss: 0.03416726849973202 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1317 Avg_loss: 0.03397733345627785 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1318 Avg_loss: 0.033848782628774644 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1319 Avg_loss: 0.033811256662011145 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1320 Avg_loss: 0.03358988892287016 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1321 Avg_loss: 0.033432294800877574 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1322 Avg_loss: 0.033404679223895076 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1323 Avg_loss: 0.033267096430063245 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1324 Avg_loss: 0.03300031367689371 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1325 Avg_loss: 0.032866796106100084 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1326 Avg_loss: 0.03272786736488342 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1327 Avg_loss: 0.03271171897649765 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1328 Avg_loss: 0.03249953128397465 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1329 Avg_loss: 0.03227999545633793 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1330 Avg_loss: 0.03211009446531534 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1331 Avg_loss: 0.031921911798417565 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1332 Avg_loss: 0.031756483111530544 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1333 Avg_loss: 0.031605344358831645 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1334 Avg_loss: 0.03147424282506108 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1335 Avg_loss: 0.031363429594784976 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1336 Avg_loss: 0.031244912836700677 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1337 Avg_loss: 0.03113061496987939 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1338 Avg_loss: 0.031040233001112937 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1339 Avg_loss: 0.030944269429892302 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1340 Avg_loss: 0.03077014172449708 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1341 Avg_loss: 0.030652879271656275 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1342 Avg_loss: 0.03051598174497485 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1343 Avg_loss: 0.03037017025053501 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1344 Avg_loss: 0.030272020492702723 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1345 Avg_loss: 0.030246111284941434 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1346 Avg_loss: 0.030159459542483093 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1347 Avg_loss: 0.03000568598508835 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1348 Avg_loss: 0.029882436152547598 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1349 Avg_loss: 0.029750331677496432 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1350 Avg_loss: 0.029607183858752252 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1351 Avg_loss: 0.02949734926223755 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1352 Avg_loss: 0.029426603764295577 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1353 Avg_loss: 0.029363193176686765 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1354 Avg_loss: 0.029217955470085145 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1355 Avg_loss: 0.029115389194339515 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1356 Avg_loss: 0.029045784380286932 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1357 Avg_loss: 0.02913146447390318 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1358 Avg_loss: 0.029092139285057782 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1359 Avg_loss: 0.028859981894493104 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1360 Avg_loss: 0.028710300102829933 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1361 Avg_loss: 0.028574578650295734 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1362 Avg_loss: 0.028600574377924202 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1363 Avg_loss: 0.02850006613880396 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1364 Avg_loss: 0.02837022775784135 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1365 Avg_loss: 0.028277953155338764 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1366 Avg_loss: 0.028130101878196 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1367 Avg_loss: 0.02798837274312973 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1368 Avg_loss: 0.02792949788272381 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1369 Avg_loss: 0.027904058899730445 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1370 Avg_loss: 0.027838915959000586 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1371 Avg_loss: 0.027746136859059335 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1372 Avg_loss: 0.027904926892369987 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1373 Avg_loss: 0.027830750867724418 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1374 Avg_loss: 0.02768683396279812 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1375 Avg_loss: 0.027482393477112056 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1376 Avg_loss: 0.02728874059394002 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1377 Avg_loss: 0.02715729847550392 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1378 Avg_loss: 0.027103360556066037 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1379 Avg_loss: 0.027111341059207917 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1380 Avg_loss: 0.027025945764034987 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1381 Avg_loss: 0.026869302988052367 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1382 Avg_loss: 0.026756109762936832 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1383 Avg_loss: 0.026741589605808257 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1384 Avg_loss: 0.02679818505421281 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1385 Avg_loss: 0.026684277784079315 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1386 Avg_loss: 0.026543260645121337 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1387 Avg_loss: 0.026467421371489764 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1388 Avg_loss: 0.0265983528457582 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1389 Avg_loss: 0.02652890244498849 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1390 Avg_loss: 0.026363762840628625 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1391 Avg_loss: 0.026305066142231225 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1392 Avg_loss: 0.026271738950163125 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1393 Avg_loss: 0.026233702525496484 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1394 Avg_loss: 0.026259579788893463 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1395 Avg_loss: 0.026172072999179362 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1396 Avg_loss: 0.02610825840383768 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1397 Avg_loss: 0.02596946628764272 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1398 Avg_loss: 0.02585740201175213 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1399 Avg_loss: 0.02593702934682369 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1400 Avg_loss: 0.025904409028589724 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1401 Avg_loss: 0.025772895477712155 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1402 Avg_loss: 0.025737199280411006 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1403 Avg_loss: 0.025734590366482735 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1404 Avg_loss: 0.025586291495710612 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1405 Avg_loss: 0.025414572656154634 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1406 Avg_loss: 0.025343864783644678 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1407 Avg_loss: 0.02532983208075166 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1408 Avg_loss: 0.025288823619484903 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1409 Avg_loss: 0.025201961677521468 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1410 Avg_loss: 0.025199350900948048 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1411 Avg_loss: 0.02516753729432821 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1412 Avg_loss: 0.025086579844355583 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1413 Avg_loss: 0.025002027675509454 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1414 Avg_loss: 0.02500784369185567 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1415 Avg_loss: 0.02520087966695428 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1416 Avg_loss: 0.025222407653927803 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1417 Avg_loss: 0.024993999116122722 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1418 Avg_loss: 0.024891695566475393 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1419 Avg_loss: 0.02497022496536374 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1420 Avg_loss: 0.024975753854960203 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1421 Avg_loss: 0.02490134136751294 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1422 Avg_loss: 0.024785310588777067 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1423 Avg_loss: 0.024615224823355673 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1424 Avg_loss: 0.024574328772723676 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1425 Avg_loss: 0.024576135072857143 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1426 Avg_loss: 0.024661684595048427 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1427 Avg_loss: 0.024716777820140125 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1428 Avg_loss: 0.024482424836605787 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1429 Avg_loss: 0.024297580774873494 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1430 Avg_loss: 0.024274578038603067 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1431 Avg_loss: 0.024272595066577196 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1432 Avg_loss: 0.024211713578552008 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1433 Avg_loss: 0.02412945218384266 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1434 Avg_loss: 0.024042751360684633 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1435 Avg_loss: 0.0240026680752635 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1436 Avg_loss: 0.024097346235066652 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1437 Avg_loss: 0.024221128225326537 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1438 Avg_loss: 0.024142021592706443 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1439 Avg_loss: 0.024171259626746176 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1440 Avg_loss: 0.02410752885043621 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1441 Avg_loss: 0.02397210309281945 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1442 Avg_loss: 0.02385106524452567 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1443 Avg_loss: 0.02377572124823928 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1444 Avg_loss: 0.02374864248558879 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1445 Avg_loss: 0.023830239847302436 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1446 Avg_loss: 0.02425200827419758 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1447 Avg_loss: 0.5052032632753253 training accuracy: 0.865625 test accuracy: 0.19727891156462585\n",
      "Epoch: 1448 Avg_loss: 0.750848799943924 training accuracy: 0.796875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1449 Avg_loss: 0.5005449086427689 training accuracy: 0.909375 test accuracy: 0.22448979591836735\n",
      "Epoch: 1450 Avg_loss: 0.3626211449503899 training accuracy: 0.946875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1451 Avg_loss: 0.28225444853305814 training accuracy: 0.971875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1452 Avg_loss: 0.24535339772701265 training accuracy: 0.978125 test accuracy: 0.2108843537414966\n",
      "Epoch: 1453 Avg_loss: 0.21723134219646453 training accuracy: 0.9875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1454 Avg_loss: 0.19843025654554367 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n",
      "Epoch: 1455 Avg_loss: 0.18504699394106866 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1456 Avg_loss: 0.17541071400046349 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1457 Avg_loss: 0.16765087544918061 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1458 Avg_loss: 0.16114823669195175 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1459 Avg_loss: 0.155529747903347 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1460 Avg_loss: 0.15063682198524475 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1461 Avg_loss: 0.14598567336797713 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1462 Avg_loss: 0.1420044858008623 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1463 Avg_loss: 0.13849934786558152 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1464 Avg_loss: 0.13509027659893036 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1465 Avg_loss: 0.13207262828946115 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1466 Avg_loss: 0.12919683530926704 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1467 Avg_loss: 0.12650430835783483 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1468 Avg_loss: 0.12398723289370536 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n",
      "Epoch: 1469 Avg_loss: 0.12172815687954426 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1470 Avg_loss: 0.11958752200007439 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n",
      "Epoch: 1471 Avg_loss: 0.11725793816149235 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1472 Avg_loss: 0.1143940094858408 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1473 Avg_loss: 0.11140760779380798 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1474 Avg_loss: 0.1090182539075613 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1475 Avg_loss: 0.10707854926586151 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1476 Avg_loss: 0.10530088990926742 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1477 Avg_loss: 0.10367736630141736 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1478 Avg_loss: 0.10213917642831802 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1479 Avg_loss: 0.10060782171785831 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1480 Avg_loss: 0.09920764900743961 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1481 Avg_loss: 0.09784060530364513 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1482 Avg_loss: 0.09647610895335675 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1483 Avg_loss: 0.09517060108482837 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1484 Avg_loss: 0.09393500313162803 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1485 Avg_loss: 0.0927678644657135 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1486 Avg_loss: 0.09161318093538284 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1487 Avg_loss: 0.09047734066843986 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1488 Avg_loss: 0.08943691700696946 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1489 Avg_loss: 0.08843725733458996 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1490 Avg_loss: 0.08740533702075481 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1491 Avg_loss: 0.08637434393167495 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1492 Avg_loss: 0.0850577063858509 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1493 Avg_loss: 0.08398763425648212 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1494 Avg_loss: 0.08307772725820542 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1495 Avg_loss: 0.08214694075286388 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1496 Avg_loss: 0.0812083575874567 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1497 Avg_loss: 0.08037260919809341 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1498 Avg_loss: 0.07958136089146137 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1499 Avg_loss: 0.07873012647032737 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1500 Avg_loss: 0.07790523283183574 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1501 Avg_loss: 0.0770785603672266 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1502 Avg_loss: 0.07624860517680646 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1503 Avg_loss: 0.07549640350043774 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1504 Avg_loss: 0.07476646974682807 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1505 Avg_loss: 0.07407609038054944 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1506 Avg_loss: 0.07332698814570904 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1507 Avg_loss: 0.0726022657006979 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1508 Avg_loss: 0.07192530483007431 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1509 Avg_loss: 0.07127457447350025 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1510 Avg_loss: 0.07062484361231328 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1511 Avg_loss: 0.06994480080902576 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1512 Avg_loss: 0.06929562650620938 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1513 Avg_loss: 0.0686825729906559 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1514 Avg_loss: 0.06805338785052299 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1515 Avg_loss: 0.06745587587356568 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1516 Avg_loss: 0.0668371070176363 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1517 Avg_loss: 0.06621790211647749 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1518 Avg_loss: 0.06563115492463112 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1519 Avg_loss: 0.06508438847959042 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1520 Avg_loss: 0.06445871628820896 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1521 Avg_loss: 0.06376590933650732 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1522 Avg_loss: 0.06318358033895492 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1523 Avg_loss: 0.06252911407500505 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1524 Avg_loss: 0.06193899642676115 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1525 Avg_loss: 0.06136179529130459 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1526 Avg_loss: 0.06070741023868322 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1527 Avg_loss: 0.05995042473077774 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1528 Avg_loss: 0.05865892264991999 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1529 Avg_loss: 0.05791437570005655 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1530 Avg_loss: 0.05724191963672638 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1531 Avg_loss: 0.05662984792143107 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1532 Avg_loss: 0.05605100095272064 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1533 Avg_loss: 0.05553247034549713 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1534 Avg_loss: 0.05501233022660017 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1535 Avg_loss: 0.05447563268244267 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1536 Avg_loss: 0.05396602023392916 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1537 Avg_loss: 0.05348672345280647 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1538 Avg_loss: 0.053037347830832006 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1539 Avg_loss: 0.052580618485808375 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1540 Avg_loss: 0.05213034991174936 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1541 Avg_loss: 0.05167691390961408 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1542 Avg_loss: 0.05125275570899248 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1543 Avg_loss: 0.050853401981294157 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1544 Avg_loss: 0.0504337515681982 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1545 Avg_loss: 0.049997590109705926 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1546 Avg_loss: 0.049575213342905045 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1547 Avg_loss: 0.049187935143709186 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1548 Avg_loss: 0.04881698489189148 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1549 Avg_loss: 0.048425575532019136 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1550 Avg_loss: 0.04802692960947752 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1551 Avg_loss: 0.047681832872331145 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1552 Avg_loss: 0.047363417036831376 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1553 Avg_loss: 0.04699335005134344 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1554 Avg_loss: 0.04662147033959627 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1555 Avg_loss: 0.04626120869070292 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1556 Avg_loss: 0.045932356268167496 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1557 Avg_loss: 0.04564210195094347 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1558 Avg_loss: 0.04532787203788757 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1559 Avg_loss: 0.04497037529945373 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1560 Avg_loss: 0.044620309770107267 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1561 Avg_loss: 0.04430978205054999 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1562 Avg_loss: 0.04401627257466316 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1563 Avg_loss: 0.043699886091053484 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1564 Avg_loss: 0.0433711051940918 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1565 Avg_loss: 0.043073888309299944 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1566 Avg_loss: 0.042800967767834666 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1567 Avg_loss: 0.04248458221554756 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1568 Avg_loss: 0.04217110704630613 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1569 Avg_loss: 0.04190005194395781 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1570 Avg_loss: 0.04161755703389645 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1571 Avg_loss: 0.04130817428231239 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1572 Avg_loss: 0.041031735576689245 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1573 Avg_loss: 0.040758230909705165 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1574 Avg_loss: 0.040490546450018886 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1575 Avg_loss: 0.040224059112370016 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1576 Avg_loss: 0.0399497963488102 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1577 Avg_loss: 0.03968829065561295 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1578 Avg_loss: 0.03945220373570919 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1579 Avg_loss: 0.03918588478118181 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1580 Avg_loss: 0.03893113099038601 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1581 Avg_loss: 0.03868187926709652 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1582 Avg_loss: 0.03848745170980692 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1583 Avg_loss: 0.038237241096794605 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1584 Avg_loss: 0.037970388680696486 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1585 Avg_loss: 0.03771290984004736 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1586 Avg_loss: 0.037492239847779274 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1587 Avg_loss: 0.03727216795086861 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1588 Avg_loss: 0.037038561515510084 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1589 Avg_loss: 0.036806815303862095 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1590 Avg_loss: 0.03658679705113173 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1591 Avg_loss: 0.03638025335967541 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1592 Avg_loss: 0.03619037084281444 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1593 Avg_loss: 0.03597223907709122 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1594 Avg_loss: 0.03573551867157221 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1595 Avg_loss: 0.03552218452095986 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1596 Avg_loss: 0.035353606566786766 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1597 Avg_loss: 0.03515042103827 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1598 Avg_loss: 0.03492405191063881 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1599 Avg_loss: 0.034716591238975525 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1600 Avg_loss: 0.03452377952635288 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1601 Avg_loss: 0.03432217910885811 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1602 Avg_loss: 0.03413847275078297 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1603 Avg_loss: 0.033975029923021795 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1604 Avg_loss: 0.03380661644041538 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1605 Avg_loss: 0.03361904732882977 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1606 Avg_loss: 0.033438277430832386 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1607 Avg_loss: 0.03323114011436701 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1608 Avg_loss: 0.033073556050658225 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1609 Avg_loss: 0.03293738439679146 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1610 Avg_loss: 0.032744037359952925 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1611 Avg_loss: 0.03254876583814621 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1612 Avg_loss: 0.03240154758095741 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1613 Avg_loss: 0.03234505988657475 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1614 Avg_loss: 0.03216441022232175 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1615 Avg_loss: 0.03194162650033831 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1616 Avg_loss: 0.03175845062360168 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1617 Avg_loss: 0.031606235168874265 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1618 Avg_loss: 0.03146618967875838 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1619 Avg_loss: 0.03133243750780821 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1620 Avg_loss: 0.03115721046924591 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1621 Avg_loss: 0.031033393833786248 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1622 Avg_loss: 0.03096440127119422 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1623 Avg_loss: 0.03087125476449728 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1624 Avg_loss: 0.03068005759268999 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1625 Avg_loss: 0.03054303294047713 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1626 Avg_loss: 0.030405479297041894 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1627 Avg_loss: 0.030296578537672758 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1628 Avg_loss: 0.030138258356601 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1629 Avg_loss: 0.029945877287536858 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1630 Avg_loss: 0.02983419904485345 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1631 Avg_loss: 0.02976362658664584 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1632 Avg_loss: 0.029603085666894912 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1633 Avg_loss: 0.02945488803088665 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1634 Avg_loss: 0.029317902214825154 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1635 Avg_loss: 0.02921619126573205 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1636 Avg_loss: 0.02913113934919238 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1637 Avg_loss: 0.028995410073548555 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1638 Avg_loss: 0.02886984162032604 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1639 Avg_loss: 0.028738353587687015 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1640 Avg_loss: 0.028629419021308423 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1641 Avg_loss: 0.028573473263531924 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1642 Avg_loss: 0.028538647387176753 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1643 Avg_loss: 0.028376889973878862 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1644 Avg_loss: 0.02822023257613182 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1645 Avg_loss: 0.028188356943428517 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1646 Avg_loss: 0.02813154263421893 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1647 Avg_loss: 0.02797383116558194 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1648 Avg_loss: 0.027825836278498172 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1649 Avg_loss: 0.0276973239146173 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1650 Avg_loss: 0.027610022109001875 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1651 Avg_loss: 0.02756265066564083 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1652 Avg_loss: 0.0274631654843688 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1653 Avg_loss: 0.027329374197870494 training accuracy: 1.0 test accuracy: 0.25170068027210885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1654 Avg_loss: 0.027248430345207453 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1655 Avg_loss: 0.027190298400819303 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1656 Avg_loss: 0.02709284219890833 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1657 Avg_loss: 0.027108015585690738 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1658 Avg_loss: 0.028325047064572572 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1659 Avg_loss: 0.11620278172194957 training accuracy: 0.98125 test accuracy: 0.2585034013605442\n",
      "Epoch: 1660 Avg_loss: 0.24944529458880424 training accuracy: 0.953125 test accuracy: 0.19727891156462585\n",
      "Epoch: 1661 Avg_loss: 0.35125477612018585 training accuracy: 0.91875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1662 Avg_loss: 0.22473815679550171 training accuracy: 0.978125 test accuracy: 0.25170068027210885\n",
      "Epoch: 1663 Avg_loss: 0.15633589997887612 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 1664 Avg_loss: 0.1321123581379652 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1665 Avg_loss: 0.12163249477744102 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1666 Avg_loss: 0.1151871107518673 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1667 Avg_loss: 0.11024967283010483 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1668 Avg_loss: 0.10604192055761814 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1669 Avg_loss: 0.1030422143638134 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1670 Avg_loss: 0.09937521144747734 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1671 Avg_loss: 0.09728975258767605 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1672 Avg_loss: 0.09509432539343834 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1673 Avg_loss: 0.09314580075442791 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1674 Avg_loss: 0.09116699658334255 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1675 Avg_loss: 0.08925518207252026 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1676 Avg_loss: 0.08749261200428009 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1677 Avg_loss: 0.08582794070243835 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1678 Avg_loss: 0.084272101521492 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1679 Avg_loss: 0.08281309306621551 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1680 Avg_loss: 0.08144490271806717 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1681 Avg_loss: 0.08013144358992577 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1682 Avg_loss: 0.07887517586350441 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1683 Avg_loss: 0.07767088897526264 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1684 Avg_loss: 0.07651093043386936 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1685 Avg_loss: 0.07539373673498631 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1686 Avg_loss: 0.07433887012302876 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1687 Avg_loss: 0.07332664802670479 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1688 Avg_loss: 0.07237008735537528 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1689 Avg_loss: 0.07145390473306179 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1690 Avg_loss: 0.07055744603276252 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1691 Avg_loss: 0.06969763934612275 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1692 Avg_loss: 0.06892118863761425 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1693 Avg_loss: 0.06813150644302368 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1694 Avg_loss: 0.06731533259153366 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1695 Avg_loss: 0.06652390882372856 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1696 Avg_loss: 0.06577008366584777 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1697 Avg_loss: 0.06502833887934685 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1698 Avg_loss: 0.06433938778936862 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1699 Avg_loss: 0.0636710662394762 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1700 Avg_loss: 0.0629976537078619 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1701 Avg_loss: 0.06231960654258728 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1702 Avg_loss: 0.06167113147675991 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1703 Avg_loss: 0.061058482900261876 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1704 Avg_loss: 0.06046658884733915 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1705 Avg_loss: 0.05986505001783371 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1706 Avg_loss: 0.059261598810553553 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1707 Avg_loss: 0.05867212526500225 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1708 Avg_loss: 0.058137369155883786 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1709 Avg_loss: 0.057592577487230304 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1710 Avg_loss: 0.057043986208736894 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1711 Avg_loss: 0.05650792345404625 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1712 Avg_loss: 0.055970712564885616 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1713 Avg_loss: 0.05545418411493301 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1714 Avg_loss: 0.05493880435824394 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1715 Avg_loss: 0.05444200374186039 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1716 Avg_loss: 0.053972885385155676 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1717 Avg_loss: 0.05349864065647125 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1718 Avg_loss: 0.05302456356585026 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1719 Avg_loss: 0.052566535957157615 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1720 Avg_loss: 0.05212584119290113 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1721 Avg_loss: 0.051691784709692004 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1722 Avg_loss: 0.051255791634321216 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1723 Avg_loss: 0.050822683796286586 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1724 Avg_loss: 0.05040578655898571 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1725 Avg_loss: 0.050012051686644556 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1726 Avg_loss: 0.049615785293281076 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1727 Avg_loss: 0.049207479879260066 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1728 Avg_loss: 0.048804101534187794 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1729 Avg_loss: 0.04842186458408833 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1730 Avg_loss: 0.04805118888616562 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1731 Avg_loss: 0.04767906162887812 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1732 Avg_loss: 0.04729630332440138 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1733 Avg_loss: 0.04692747425287962 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1734 Avg_loss: 0.04656549170613289 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1735 Avg_loss: 0.04621049240231514 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1736 Avg_loss: 0.04582353699952364 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1737 Avg_loss: 0.04547926690429449 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1738 Avg_loss: 0.04514094740152359 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1739 Avg_loss: 0.044808370247483256 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1740 Avg_loss: 0.04447731655091047 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1741 Avg_loss: 0.04414577968418598 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1742 Avg_loss: 0.04380885362625122 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1743 Avg_loss: 0.04349514674395323 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1744 Avg_loss: 0.043218493834137915 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1745 Avg_loss: 0.04290646854788065 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1746 Avg_loss: 0.04258185029029846 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1747 Avg_loss: 0.04227741919457913 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1748 Avg_loss: 0.04197509549558163 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1749 Avg_loss: 0.04167623911052942 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1750 Avg_loss: 0.041389566101133826 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1751 Avg_loss: 0.04112556017935276 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1752 Avg_loss: 0.04089641068130732 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1753 Avg_loss: 0.04062161929905415 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1754 Avg_loss: 0.04034664947539568 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1755 Avg_loss: 0.040039886720478535 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1756 Avg_loss: 0.03977814670652151 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1757 Avg_loss: 0.03952887207269669 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1758 Avg_loss: 0.03926611915230751 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1759 Avg_loss: 0.03898713532835245 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1760 Avg_loss: 0.038732759281992914 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1761 Avg_loss: 0.03849965482950211 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1762 Avg_loss: 0.03825249783694744 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1763 Avg_loss: 0.03798702862113714 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1764 Avg_loss: 0.037748496793210504 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1765 Avg_loss: 0.03752874545753002 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1766 Avg_loss: 0.037287583015859126 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1767 Avg_loss: 0.03704346176236868 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1768 Avg_loss: 0.036821084655821325 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1769 Avg_loss: 0.036620966345071795 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1770 Avg_loss: 0.03639469556510448 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1771 Avg_loss: 0.03616190142929554 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1772 Avg_loss: 0.035954609513282776 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1773 Avg_loss: 0.03575849998742342 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1774 Avg_loss: 0.03552133273333311 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1775 Avg_loss: 0.03531438857316971 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1776 Avg_loss: 0.03513773288577795 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1777 Avg_loss: 0.03496404141187668 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1778 Avg_loss: 0.03472767323255539 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1779 Avg_loss: 0.03451594635844231 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1780 Avg_loss: 0.03431660421192646 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1781 Avg_loss: 0.0341337775811553 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1782 Avg_loss: 0.03395434804260731 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1783 Avg_loss: 0.03376002945005894 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1784 Avg_loss: 0.033561686240136626 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1785 Avg_loss: 0.03337742500007153 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1786 Avg_loss: 0.03321165516972542 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1787 Avg_loss: 0.0330304816365242 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1788 Avg_loss: 0.032845955714583396 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1789 Avg_loss: 0.03268512524664402 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1790 Avg_loss: 0.032518517971038816 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1791 Avg_loss: 0.03233253881335259 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1792 Avg_loss: 0.03212858736515045 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1793 Avg_loss: 0.03193376082926989 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1794 Avg_loss: 0.03177002463489771 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1795 Avg_loss: 0.031606830283999444 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1796 Avg_loss: 0.0314403616823256 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1797 Avg_loss: 0.03138077203184366 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1798 Avg_loss: 0.031224143505096436 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1799 Avg_loss: 0.031007612589746714 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1800 Avg_loss: 0.03081518867984414 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1801 Avg_loss: 0.03065983848646283 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1802 Avg_loss: 0.030514881759881974 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1803 Avg_loss: 0.03041121633723378 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1804 Avg_loss: 0.030257837381213903 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1805 Avg_loss: 0.03011096380650997 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1806 Avg_loss: 0.02995819514617324 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1807 Avg_loss: 0.029820771794766186 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1808 Avg_loss: 0.029673250485211612 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1809 Avg_loss: 0.029537433944642543 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1810 Avg_loss: 0.02940232716500759 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1811 Avg_loss: 0.029249530844390394 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1812 Avg_loss: 0.029094797652214767 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1813 Avg_loss: 0.02897685021162033 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1814 Avg_loss: 0.028993779979646205 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1815 Avg_loss: 0.028903968911617995 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1816 Avg_loss: 0.0286379586905241 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1817 Avg_loss: 0.028652591165155172 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1818 Avg_loss: 0.03418556647375226 training accuracy: 1.0 test accuracy: 0.24489795918367346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1819 Avg_loss: 0.16075260527431964 training accuracy: 0.96875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1820 Avg_loss: 0.4019081130623817 training accuracy: 0.903125 test accuracy: 0.21768707482993196\n",
      "Epoch: 1821 Avg_loss: 0.38221232816576955 training accuracy: 0.9375 test accuracy: 0.2653061224489796\n",
      "Epoch: 1822 Avg_loss: 0.30356378853321075 training accuracy: 0.965625 test accuracy: 0.23809523809523808\n",
      "Epoch: 1823 Avg_loss: 0.22309357449412345 training accuracy: 0.990625 test accuracy: 0.2653061224489796\n",
      "Epoch: 1824 Avg_loss: 0.18267636597156525 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 1825 Avg_loss: 0.16275155618786813 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1826 Avg_loss: 0.15200342163443564 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1827 Avg_loss: 0.14445050433278084 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1828 Avg_loss: 0.1385899968445301 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1829 Avg_loss: 0.1336586020886898 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1830 Avg_loss: 0.1293754894286394 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1831 Avg_loss: 0.12569007873535157 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1832 Avg_loss: 0.12234875857830048 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1833 Avg_loss: 0.11927658580243587 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1834 Avg_loss: 0.11649449057877063 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1835 Avg_loss: 0.11408653520047665 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1836 Avg_loss: 0.11173643060028553 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1837 Avg_loss: 0.10951548404991626 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1838 Avg_loss: 0.10742311887443065 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1839 Avg_loss: 0.10548964291810989 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1840 Avg_loss: 0.10370340459048748 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1841 Avg_loss: 0.10201013833284378 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1842 Avg_loss: 0.10038508363068104 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1843 Avg_loss: 0.09878675192594528 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1844 Avg_loss: 0.09724434018135071 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1845 Avg_loss: 0.09578144028782845 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1846 Avg_loss: 0.09441907294094562 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1847 Avg_loss: 0.09311107099056244 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1848 Avg_loss: 0.09188224412500859 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1849 Avg_loss: 0.09065763801336288 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1850 Avg_loss: 0.0895053032785654 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1851 Avg_loss: 0.08839120753109456 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1852 Avg_loss: 0.08732241541147232 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1853 Avg_loss: 0.08625626489520073 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1854 Avg_loss: 0.08519802875816822 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1855 Avg_loss: 0.08423667959868908 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1856 Avg_loss: 0.08325955048203468 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1857 Avg_loss: 0.08228099271655083 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1858 Avg_loss: 0.08144391924142838 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1859 Avg_loss: 0.08065346516668796 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1860 Avg_loss: 0.07978087849915028 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1861 Avg_loss: 0.07888933755457402 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1862 Avg_loss: 0.07801892906427384 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1863 Avg_loss: 0.07718109376728535 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1864 Avg_loss: 0.07639124505221843 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1865 Avg_loss: 0.07561101019382477 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1866 Avg_loss: 0.07483440674841405 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1867 Avg_loss: 0.07407256029546261 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1868 Avg_loss: 0.07341831848025322 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1869 Avg_loss: 0.07275873385369777 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1870 Avg_loss: 0.07204662375152111 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1871 Avg_loss: 0.07132466174662114 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1872 Avg_loss: 0.07066651731729508 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1873 Avg_loss: 0.0700081642717123 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1874 Avg_loss: 0.06935643590986729 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1875 Avg_loss: 0.06872248500585557 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1876 Avg_loss: 0.06811189875006676 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1877 Avg_loss: 0.06751012578606605 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1878 Avg_loss: 0.06696970872581005 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1879 Avg_loss: 0.06646177433431148 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1880 Avg_loss: 0.06589068397879601 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1881 Avg_loss: 0.06531555838882923 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1882 Avg_loss: 0.06474409848451615 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1883 Avg_loss: 0.06418593302369117 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1884 Avg_loss: 0.06361467763781548 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1885 Avg_loss: 0.06309766825288535 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1886 Avg_loss: 0.06256675701588392 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1887 Avg_loss: 0.062052246369421485 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1888 Avg_loss: 0.061525159515440464 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1889 Avg_loss: 0.06102291084825993 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1890 Avg_loss: 0.06053157653659582 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1891 Avg_loss: 0.060063021071255204 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1892 Avg_loss: 0.05957699790596962 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1893 Avg_loss: 0.05908128470182419 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1894 Avg_loss: 0.05859750099480152 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1895 Avg_loss: 0.05818852782249451 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1896 Avg_loss: 0.05778425391763449 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1897 Avg_loss: 0.05732046440243721 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1898 Avg_loss: 0.05683475453406572 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1899 Avg_loss: 0.056393003836274144 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1900 Avg_loss: 0.05596024803817272 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1901 Avg_loss: 0.05555502288043499 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1902 Avg_loss: 0.05515629705041647 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1903 Avg_loss: 0.054730449058115485 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1904 Avg_loss: 0.054334111511707306 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1905 Avg_loss: 0.05393608808517456 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1906 Avg_loss: 0.05348636955022812 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1907 Avg_loss: 0.05302883237600327 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1908 Avg_loss: 0.05263795889914036 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1909 Avg_loss: 0.05229272600263357 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1910 Avg_loss: 0.05190126076340675 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1911 Avg_loss: 0.05152410306036472 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1912 Avg_loss: 0.05114453621208668 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1913 Avg_loss: 0.0507422586902976 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1914 Avg_loss: 0.05034672487527132 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1915 Avg_loss: 0.05003952942788601 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1916 Avg_loss: 0.04969513770192861 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1917 Avg_loss: 0.04932435508817434 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1918 Avg_loss: 0.04900715071707964 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1919 Avg_loss: 0.04863290190696716 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1920 Avg_loss: 0.048260082677006724 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1921 Avg_loss: 0.047919126227498055 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1922 Avg_loss: 0.047589318826794624 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1923 Avg_loss: 0.047291092574596405 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1924 Avg_loss: 0.04698517210781574 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1925 Avg_loss: 0.04662082213908434 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1926 Avg_loss: 0.04628247562795877 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1927 Avg_loss: 0.04599975906312466 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1928 Avg_loss: 0.045682333409786224 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1929 Avg_loss: 0.0453379737213254 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1930 Avg_loss: 0.04502281118184328 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1931 Avg_loss: 0.04472091682255268 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1932 Avg_loss: 0.04447035323828459 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1933 Avg_loss: 0.044165163859725 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1934 Avg_loss: 0.04385573156177998 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1935 Avg_loss: 0.04355680514127016 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1936 Avg_loss: 0.043267386965453625 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1937 Avg_loss: 0.04302463978528977 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1938 Avg_loss: 0.04273413475602865 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1939 Avg_loss: 0.04240792505443096 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1940 Avg_loss: 0.04212302658706903 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1941 Avg_loss: 0.041837573796510694 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1942 Avg_loss: 0.041603980027139185 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1943 Avg_loss: 0.04136775117367506 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1944 Avg_loss: 0.04110248722136021 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1945 Avg_loss: 0.04082660265266895 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1946 Avg_loss: 0.04053197260946036 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1947 Avg_loss: 0.04025247562676668 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1948 Avg_loss: 0.040025891922414306 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1949 Avg_loss: 0.03979752343147993 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1950 Avg_loss: 0.03953517135232687 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1951 Avg_loss: 0.03929238710552454 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1952 Avg_loss: 0.03906983137130737 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1953 Avg_loss: 0.03879437930881977 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1954 Avg_loss: 0.03853022325783968 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1955 Avg_loss: 0.038307720050215724 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1956 Avg_loss: 0.03810364361852407 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1957 Avg_loss: 0.03785604760050774 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1958 Avg_loss: 0.03759834785014391 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1959 Avg_loss: 0.03741226326674223 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1960 Avg_loss: 0.03722475841641426 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1961 Avg_loss: 0.03699340187013149 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1962 Avg_loss: 0.03674298133701086 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1963 Avg_loss: 0.036567161418497564 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1964 Avg_loss: 0.036333774030208585 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1965 Avg_loss: 0.03608173690736294 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1966 Avg_loss: 0.03587605953216553 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1967 Avg_loss: 0.035687528736889365 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1968 Avg_loss: 0.03555852249264717 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1969 Avg_loss: 0.0353548401966691 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1970 Avg_loss: 0.03508519902825356 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1971 Avg_loss: 0.03484470210969448 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1972 Avg_loss: 0.03464786559343338 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1973 Avg_loss: 0.034479734115302564 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1974 Avg_loss: 0.03428605291992426 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1975 Avg_loss: 0.034093146584928034 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1976 Avg_loss: 0.03389663230627775 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1977 Avg_loss: 0.033693330734968184 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1978 Avg_loss: 0.03353182934224606 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1979 Avg_loss: 0.03335071243345737 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1980 Avg_loss: 0.033133627474308015 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1981 Avg_loss: 0.03295141663402319 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1982 Avg_loss: 0.032811582833528516 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1983 Avg_loss: 0.03266067113727331 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1984 Avg_loss: 0.032470794208347795 training accuracy: 1.0 test accuracy: 0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1985 Avg_loss: 0.03228980824351311 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1986 Avg_loss: 0.032087853737175466 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1987 Avg_loss: 0.03193140774965286 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1988 Avg_loss: 0.03178709503263235 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1989 Avg_loss: 0.03162528425455093 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1990 Avg_loss: 0.03146915957331657 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1991 Avg_loss: 0.0313377040438354 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1992 Avg_loss: 0.031238813232630492 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1993 Avg_loss: 0.031032060831785203 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1994 Avg_loss: 0.030853752978146076 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1995 Avg_loss: 0.030782975535839797 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1996 Avg_loss: 0.03059867173433304 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1997 Avg_loss: 0.03038768209517002 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1998 Avg_loss: 0.03020744500681758 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1999 Avg_loss: 0.03007496688514948 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "best accuracy: 0.3673469387755102\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "def find_best_model():\n",
    "    lrs = [0.0001, 0.0005]\n",
    "    fc_hiddens = [16, 32]\n",
    "    lambs = [0.0001, 0.001]\n",
    "    batch_sizes = [16, 32, 64]\n",
    "\n",
    "    best_states = None\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    params = []\n",
    "    losses = []\n",
    "    accs = []\n",
    "    \n",
    "    for l, fch, lm, bs in product(lrs, fc_hiddens, lambs, batch_sizes):\n",
    "        print(\"==========lr:\", l, \"lambda:\", lm, \"batch_size:\", bs, \"fc_hidden:\", fch, \"==========\")\n",
    "        params.append((l, fch, lm, bs))\n",
    "        model, best_state, best_acc, loss, acc = train_model(training_data, training_labels,\n",
    "                                                             test_data, test_labels, 2000, 128, fch,\n",
    "                                                             lr=l, lamb=lm, batch_size=bs)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        print(\"Best accuracy:\", best_acc)\n",
    "        if best_acc > best_accuracy:\n",
    "            best_accuracy = best_acc\n",
    "            best_states = best_state\n",
    "            model.load_state_dict(best_states)\n",
    "            best_model = model\n",
    "    print(\"best overall accuracy:\", best_accuracy)\n",
    "    return best_model, params, losses, accs\n",
    "\n",
    "#model, params, losses, accs = find_best_model()\n",
    "\n",
    "model, best_state, best_acc, loss, acc = train_model(training_data, training_labels,\n",
    "                                                             test_data, test_labels, 2000, 128, 16,\n",
    "                                                             lr=0.0001, lamb=0.001, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "other-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Avg_loss: 1.7942642331123353 training accuracy: 0.25625 test accuracy: 0.30612244897959184\n",
      "Epoch: 1 Avg_loss: 1.6364943265914917 training accuracy: 0.3375 test accuracy: 0.29931972789115646\n",
      "Epoch: 2 Avg_loss: 1.5354824185371398 training accuracy: 0.4125 test accuracy: 0.32653061224489793\n",
      "Epoch: 3 Avg_loss: 1.4539529979228973 training accuracy: 0.44375 test accuracy: 0.29931972789115646\n",
      "Epoch: 4 Avg_loss: 1.3886882781982421 training accuracy: 0.46875 test accuracy: 0.29931972789115646\n",
      "Epoch: 5 Avg_loss: 1.327773141860962 training accuracy: 0.4875 test accuracy: 0.2857142857142857\n",
      "Epoch: 6 Avg_loss: 1.270124888420105 training accuracy: 0.490625 test accuracy: 0.30612244897959184\n",
      "Epoch: 7 Avg_loss: 1.2129532098770142 training accuracy: 0.503125 test accuracy: 0.3197278911564626\n",
      "Epoch: 8 Avg_loss: 1.1593836545944214 training accuracy: 0.50625 test accuracy: 0.29931972789115646\n",
      "Epoch: 9 Avg_loss: 1.1085134774446488 training accuracy: 0.53125 test accuracy: 0.29931972789115646\n",
      "Epoch: 10 Avg_loss: 1.068579825758934 training accuracy: 0.55 test accuracy: 0.2857142857142857\n",
      "Epoch: 11 Avg_loss: 1.0304279536008836 training accuracy: 0.55 test accuracy: 0.2857142857142857\n",
      "Epoch: 12 Avg_loss: 0.9896383225917816 training accuracy: 0.590625 test accuracy: 0.272108843537415\n",
      "Epoch: 13 Avg_loss: 0.9398866862058639 training accuracy: 0.6375 test accuracy: 0.2925170068027211\n",
      "Epoch: 14 Avg_loss: 0.891105306148529 training accuracy: 0.6625 test accuracy: 0.29931972789115646\n",
      "Epoch: 15 Avg_loss: 0.8637593775987625 training accuracy: 0.7125 test accuracy: 0.3469387755102041\n",
      "Epoch: 16 Avg_loss: 0.8248457595705986 training accuracy: 0.71875 test accuracy: 0.3197278911564626\n",
      "Epoch: 17 Avg_loss: 0.7776826173067093 training accuracy: 0.734375 test accuracy: 0.3401360544217687\n",
      "Epoch: 18 Avg_loss: 0.7348051965236664 training accuracy: 0.74375 test accuracy: 0.3197278911564626\n",
      "Epoch: 19 Avg_loss: 0.6953404322266579 training accuracy: 0.746875 test accuracy: 0.3129251700680272\n",
      "Epoch: 20 Avg_loss: 0.6738766372203827 training accuracy: 0.74375 test accuracy: 0.30612244897959184\n",
      "Epoch: 21 Avg_loss: 0.6323499113321305 training accuracy: 0.775 test accuracy: 0.30612244897959184\n",
      "Epoch: 22 Avg_loss: 0.574649877846241 training accuracy: 0.871875 test accuracy: 0.3129251700680272\n",
      "Epoch: 23 Avg_loss: 0.5246297046542168 training accuracy: 0.940625 test accuracy: 0.2789115646258503\n",
      "Epoch: 24 Avg_loss: 0.4916784673929214 training accuracy: 0.95625 test accuracy: 0.3333333333333333\n",
      "Epoch: 25 Avg_loss: 0.44335959255695345 training accuracy: 0.975 test accuracy: 0.2925170068027211\n",
      "Epoch: 26 Avg_loss: 0.387940314412117 training accuracy: 0.9875 test accuracy: 0.2653061224489796\n",
      "Epoch: 27 Avg_loss: 0.3806345030665398 training accuracy: 0.98125 test accuracy: 0.2585034013605442\n",
      "Epoch: 28 Avg_loss: 0.36944525241851806 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 29 Avg_loss: 0.32389318719506266 training accuracy: 0.990625 test accuracy: 0.2789115646258503\n",
      "Epoch: 30 Avg_loss: 0.30816067606210706 training accuracy: 0.9875 test accuracy: 0.3129251700680272\n",
      "Epoch: 31 Avg_loss: 0.28538206219673157 training accuracy: 0.990625 test accuracy: 0.2789115646258503\n",
      "Epoch: 32 Avg_loss: 0.25087211206555365 training accuracy: 0.99375 test accuracy: 0.29931972789115646\n",
      "Epoch: 33 Avg_loss: 0.22469089254736901 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 34 Avg_loss: 0.20731423869729043 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 35 Avg_loss: 0.19403188303112984 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 36 Avg_loss: 0.18285789340734482 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 37 Avg_loss: 0.17440836280584335 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 38 Avg_loss: 0.16455066204071045 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 39 Avg_loss: 0.15722873359918593 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 40 Avg_loss: 0.1512047119438648 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 41 Avg_loss: 0.14562081620097161 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 42 Avg_loss: 0.14088544771075248 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 43 Avg_loss: 0.1365301489830017 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 44 Avg_loss: 0.13269607499241828 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 45 Avg_loss: 0.12917445562779903 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 46 Avg_loss: 0.1258546568453312 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 47 Avg_loss: 0.12282015606760979 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 48 Avg_loss: 0.1200415849685669 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 49 Avg_loss: 0.11743738502264023 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 50 Avg_loss: 0.11496081463992595 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 51 Avg_loss: 0.11265161484479905 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 52 Avg_loss: 0.11049414575099945 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 53 Avg_loss: 0.10844414755702018 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 54 Avg_loss: 0.10644532069563865 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 55 Avg_loss: 0.10458819009363651 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 56 Avg_loss: 0.10282629951834679 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 57 Avg_loss: 0.1011352151632309 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 58 Avg_loss: 0.09953822232782841 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 59 Avg_loss: 0.09801590591669082 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 60 Avg_loss: 0.0965460143983364 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 61 Avg_loss: 0.0951517827808857 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 62 Avg_loss: 0.09380500726401805 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 63 Avg_loss: 0.09250619895756244 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 64 Avg_loss: 0.09126467481255532 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 65 Avg_loss: 0.09007488675415516 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 66 Avg_loss: 0.08890987373888493 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 67 Avg_loss: 0.08779602497816086 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 68 Avg_loss: 0.08672877587378025 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 69 Avg_loss: 0.08569573014974594 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 70 Avg_loss: 0.08469699844717979 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 71 Avg_loss: 0.08373250998556614 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 72 Avg_loss: 0.08279514759778976 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 73 Avg_loss: 0.081883430108428 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 74 Avg_loss: 0.08098797611892224 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 75 Avg_loss: 0.08013450577855111 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 76 Avg_loss: 0.07931083142757415 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 77 Avg_loss: 0.0785105399787426 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 78 Avg_loss: 0.07773760370910168 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 79 Avg_loss: 0.0769726164638996 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 80 Avg_loss: 0.07624845914542674 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 81 Avg_loss: 0.07553174383938313 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 82 Avg_loss: 0.07483600601553916 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 83 Avg_loss: 0.07416123934090138 training accuracy: 1.0 test accuracy: 0.3197278911564626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 Avg_loss: 0.07351240888237953 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 85 Avg_loss: 0.07287485003471375 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 86 Avg_loss: 0.07225903421640396 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 87 Avg_loss: 0.07165525108575821 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 88 Avg_loss: 0.07106685899198055 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 89 Avg_loss: 0.07049081884324551 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 90 Avg_loss: 0.06993718519806862 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 91 Avg_loss: 0.06939276829361915 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 92 Avg_loss: 0.06885557807981968 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 93 Avg_loss: 0.06833639033138753 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 94 Avg_loss: 0.06783722452819348 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 95 Avg_loss: 0.06732932738959789 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 96 Avg_loss: 0.06683111749589443 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 97 Avg_loss: 0.06634679213166236 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 98 Avg_loss: 0.06589822955429554 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 99 Avg_loss: 0.06543636061251164 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 100 Avg_loss: 0.06502095945179462 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 101 Avg_loss: 0.06466463170945644 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 102 Avg_loss: 0.06420235671103 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 103 Avg_loss: 0.06376879084855318 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 104 Avg_loss: 0.06335388626903296 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 105 Avg_loss: 0.06294206250458956 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 106 Avg_loss: 0.06253590676933526 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 107 Avg_loss: 0.06215890869498253 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 108 Avg_loss: 0.061782019399106505 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 109 Avg_loss: 0.06140184290707111 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 110 Avg_loss: 0.061049523390829565 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 111 Avg_loss: 0.060691408812999725 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 112 Avg_loss: 0.0603282293304801 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 113 Avg_loss: 0.06000628601759672 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 114 Avg_loss: 0.05965764466673136 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 115 Avg_loss: 0.059331076592206954 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 116 Avg_loss: 0.05902163907885551 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 117 Avg_loss: 0.058710182830691335 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 118 Avg_loss: 0.05840485673397779 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 119 Avg_loss: 0.05808688923716545 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 120 Avg_loss: 0.05777435712516308 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 121 Avg_loss: 0.05748582426458597 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 122 Avg_loss: 0.05718413144350052 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 123 Avg_loss: 0.05690001342445612 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 124 Avg_loss: 0.056604545563459396 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 125 Avg_loss: 0.05634147133678198 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 126 Avg_loss: 0.05605920907109976 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 127 Avg_loss: 0.055820689722895625 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 128 Avg_loss: 0.05559644419699907 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 129 Avg_loss: 0.05528904907405376 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 130 Avg_loss: 0.05499931965023279 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 131 Avg_loss: 0.05476882755756378 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 132 Avg_loss: 0.05461880043148994 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 133 Avg_loss: 0.054352978430688384 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 134 Avg_loss: 0.054061660170555116 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 135 Avg_loss: 0.053831213526427744 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 136 Avg_loss: 0.05357203260064125 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 137 Avg_loss: 0.0533213023096323 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 138 Avg_loss: 0.05306589622050524 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 139 Avg_loss: 0.052791118063032626 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 140 Avg_loss: 0.052556862123310566 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 141 Avg_loss: 0.05244225095957518 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 142 Avg_loss: 0.052215978316962716 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 143 Avg_loss: 0.051938592828810214 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 144 Avg_loss: 0.05166264623403549 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 145 Avg_loss: 0.051541789807379244 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 146 Avg_loss: 0.05127718299627304 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 147 Avg_loss: 0.05103388167917729 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 148 Avg_loss: 0.050885115191340445 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 149 Avg_loss: 0.05069708917289972 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 150 Avg_loss: 0.05042154919356108 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 151 Avg_loss: 0.05019001122564078 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 152 Avg_loss: 0.05003611147403717 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 153 Avg_loss: 0.049799765646457675 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 154 Avg_loss: 0.049579552561044696 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 155 Avg_loss: 0.04942438472062349 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 156 Avg_loss: 0.0491875346750021 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 157 Avg_loss: 0.04899382945150137 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 158 Avg_loss: 0.04880053326487541 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 159 Avg_loss: 0.048638433776795865 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 160 Avg_loss: 0.04868196714669466 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 161 Avg_loss: 0.048383773863315584 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 162 Avg_loss: 0.6229099109768867 training accuracy: 0.80625 test accuracy: 0.2108843537414966\n",
      "Epoch: 163 Avg_loss: 1.2566041976213456 training accuracy: 0.553125 test accuracy: 0.2925170068027211\n",
      "Epoch: 164 Avg_loss: 1.0520600616931914 training accuracy: 0.6875 test accuracy: 0.24489795918367346\n",
      "Epoch: 165 Avg_loss: 1.124045842885971 training accuracy: 0.65 test accuracy: 0.2789115646258503\n",
      "Epoch: 166 Avg_loss: 0.7850857079029083 training accuracy: 0.828125 test accuracy: 0.2585034013605442\n",
      "Epoch: 167 Avg_loss: 0.570774681866169 training accuracy: 0.91875 test accuracy: 0.2653061224489796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 168 Avg_loss: 0.4237556427717209 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 169 Avg_loss: 0.4204917848110199 training accuracy: 0.965625 test accuracy: 0.30612244897959184\n",
      "Epoch: 170 Avg_loss: 0.4270595222711563 training accuracy: 0.96875 test accuracy: 0.2653061224489796\n",
      "Epoch: 171 Avg_loss: 0.3845493882894516 training accuracy: 0.978125 test accuracy: 0.30612244897959184\n",
      "Epoch: 172 Avg_loss: 0.30544166937470435 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 173 Avg_loss: 0.26240299046039584 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 174 Avg_loss: 0.24031824991106987 training accuracy: 0.996875 test accuracy: 0.30612244897959184\n",
      "Epoch: 175 Avg_loss: 0.22499456405639648 training accuracy: 0.996875 test accuracy: 0.30612244897959184\n",
      "Epoch: 176 Avg_loss: 0.21158422753214837 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 177 Avg_loss: 0.20239376202225684 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 178 Avg_loss: 0.19501682743430138 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 179 Avg_loss: 0.18866673558950425 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 180 Avg_loss: 0.1831045590341091 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 181 Avg_loss: 0.1781322292983532 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 182 Avg_loss: 0.1736537903547287 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 183 Avg_loss: 0.1694704331457615 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 184 Avg_loss: 0.16561393812298775 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 185 Avg_loss: 0.16203778460621834 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 186 Avg_loss: 0.1586064226925373 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 187 Avg_loss: 0.15550089851021767 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 188 Avg_loss: 0.15256857573986055 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 189 Avg_loss: 0.1497897505760193 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 190 Avg_loss: 0.14729295670986176 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 191 Avg_loss: 0.1461357742547989 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 192 Avg_loss: 0.14436430111527443 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 193 Avg_loss: 0.14151089116930962 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 194 Avg_loss: 0.13880130127072335 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 195 Avg_loss: 0.13631495609879493 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 196 Avg_loss: 0.13400865197181702 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 197 Avg_loss: 0.13183171674609184 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 198 Avg_loss: 0.12975782975554467 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 199 Avg_loss: 0.1277819827198982 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 200 Avg_loss: 0.125894371047616 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 201 Avg_loss: 0.1240729920566082 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 202 Avg_loss: 0.12232033647596836 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 203 Avg_loss: 0.12062624245882034 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 204 Avg_loss: 0.11897990554571151 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 205 Avg_loss: 0.11738433428108692 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 206 Avg_loss: 0.11583187580108642 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 207 Avg_loss: 0.11431725770235061 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 208 Avg_loss: 0.1128411464393139 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 209 Avg_loss: 0.11140730939805507 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 210 Avg_loss: 0.1100043248385191 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 211 Avg_loss: 0.1086379274725914 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 212 Avg_loss: 0.10730748623609543 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 213 Avg_loss: 0.10600626543164253 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 214 Avg_loss: 0.10473292917013169 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 215 Avg_loss: 0.1034875150769949 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 216 Avg_loss: 0.10227148979902267 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 217 Avg_loss: 0.1010804932564497 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 218 Avg_loss: 0.09992346316576003 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 219 Avg_loss: 0.09876402318477631 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 220 Avg_loss: 0.09765617959201336 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 221 Avg_loss: 0.09654775932431221 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 222 Avg_loss: 0.09548267498612403 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 223 Avg_loss: 0.09443668834865093 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 224 Avg_loss: 0.0934109952300787 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 225 Avg_loss: 0.09241324439644813 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 226 Avg_loss: 0.09143468216061593 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 227 Avg_loss: 0.09047777317464352 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 228 Avg_loss: 0.08953709490597248 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 229 Avg_loss: 0.08861843459308147 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 230 Avg_loss: 0.08771834746003151 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 231 Avg_loss: 0.08683483339846135 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 232 Avg_loss: 0.08596661537885666 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 233 Avg_loss: 0.0851185955107212 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 234 Avg_loss: 0.08428954780101776 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 235 Avg_loss: 0.08347657397389412 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 236 Avg_loss: 0.08267628997564316 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 237 Avg_loss: 0.08189119175076484 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 238 Avg_loss: 0.08112081736326218 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 239 Avg_loss: 0.0803703285753727 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 240 Avg_loss: 0.07963375821709633 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 241 Avg_loss: 0.07891381569206715 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 242 Avg_loss: 0.07820751294493675 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 243 Avg_loss: 0.07751484252512456 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 244 Avg_loss: 0.07683598063886166 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 245 Avg_loss: 0.07616975866258144 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 246 Avg_loss: 0.07551938518881798 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 247 Avg_loss: 0.07488015405833721 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 248 Avg_loss: 0.07425497360527515 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 249 Avg_loss: 0.07364547736942768 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 250 Avg_loss: 0.07304687052965164 training accuracy: 1.0 test accuracy: 0.3197278911564626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251 Avg_loss: 0.07245969921350479 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 252 Avg_loss: 0.07188420295715332 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 253 Avg_loss: 0.07132659927010536 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 254 Avg_loss: 0.07077444382011891 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 255 Avg_loss: 0.07023925557732583 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 256 Avg_loss: 0.06971255913376809 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 257 Avg_loss: 0.06919490061700344 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 258 Avg_loss: 0.06868972517549991 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 259 Avg_loss: 0.06819362267851829 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 260 Avg_loss: 0.06771055683493614 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 261 Avg_loss: 0.06723733134567737 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 262 Avg_loss: 0.06677222773432731 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 263 Avg_loss: 0.06631593033671379 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 264 Avg_loss: 0.06586794331669807 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 265 Avg_loss: 0.06543507911264897 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 266 Avg_loss: 0.0650105182081461 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 267 Avg_loss: 0.06459255032241344 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 268 Avg_loss: 0.06418473683297635 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 269 Avg_loss: 0.06379178911447525 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 270 Avg_loss: 0.06339812353253364 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 271 Avg_loss: 0.063017937541008 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 272 Avg_loss: 0.0626442227512598 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 273 Avg_loss: 0.06227961722761392 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 274 Avg_loss: 0.061921187490224835 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 275 Avg_loss: 0.06157407239079475 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 276 Avg_loss: 0.06122998371720314 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 277 Avg_loss: 0.06089201718568802 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 278 Avg_loss: 0.06056007072329521 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 279 Avg_loss: 0.06024320051074028 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 280 Avg_loss: 0.05991824120283127 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 281 Avg_loss: 0.059585433639585975 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 282 Avg_loss: 0.05927396845072508 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 283 Avg_loss: 0.05897480808198452 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 284 Avg_loss: 0.05868304707109928 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 285 Avg_loss: 0.05840038284659386 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 286 Avg_loss: 0.05812324080616236 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 287 Avg_loss: 0.05784341301769018 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 288 Avg_loss: 0.05757687650620937 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 289 Avg_loss: 0.057309686578810214 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 290 Avg_loss: 0.05705324988812208 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 291 Avg_loss: 0.056798739917576314 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 292 Avg_loss: 0.05655333418399096 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 293 Avg_loss: 0.05630653481930494 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 294 Avg_loss: 0.05606816150248051 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 295 Avg_loss: 0.055832472443580625 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 296 Avg_loss: 0.05560597851872444 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 297 Avg_loss: 0.055378553457558155 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 298 Avg_loss: 0.055160762183368205 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 299 Avg_loss: 0.05493550691753626 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 300 Avg_loss: 0.05470565780997276 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 301 Avg_loss: 0.054489087872207166 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 302 Avg_loss: 0.05427008830010891 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 303 Avg_loss: 0.05406339652836323 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 304 Avg_loss: 0.0538568127900362 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 305 Avg_loss: 0.05366285406053066 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 306 Avg_loss: 0.053474497981369495 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 307 Avg_loss: 0.053283534944057465 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 308 Avg_loss: 0.05308464039117098 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 309 Avg_loss: 0.05290130265057087 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 310 Avg_loss: 0.052721821889281276 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 311 Avg_loss: 0.052534577809274195 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 312 Avg_loss: 0.05236331447958946 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 313 Avg_loss: 0.05217909011989832 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 314 Avg_loss: 0.0520112656056881 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 315 Avg_loss: 0.051834816485643385 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 316 Avg_loss: 0.051678340137004855 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 317 Avg_loss: 0.05150524470955133 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 318 Avg_loss: 0.05135610457509756 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 319 Avg_loss: 0.05119256675243378 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 320 Avg_loss: 0.05104336179792881 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 321 Avg_loss: 0.05087747313082218 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 322 Avg_loss: 0.050740308687090875 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 323 Avg_loss: 0.05058705247938633 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 324 Avg_loss: 0.0504333421587944 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 325 Avg_loss: 0.05028986018151045 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 326 Avg_loss: 0.05015004202723503 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 327 Avg_loss: 0.05000081919133663 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 328 Avg_loss: 0.049870648235082624 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 329 Avg_loss: 0.04971390273422003 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 330 Avg_loss: 0.049557657726109025 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 331 Avg_loss: 0.049417887814342976 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 332 Avg_loss: 0.049279003590345385 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 333 Avg_loss: 0.04915262199938297 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 334 Avg_loss: 0.04900584109127522 training accuracy: 1.0 test accuracy: 0.3129251700680272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 335 Avg_loss: 0.04887810982763767 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 336 Avg_loss: 0.048740383423864844 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 337 Avg_loss: 0.048611432500183585 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 338 Avg_loss: 0.04848599229007959 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 339 Avg_loss: 0.04836405087262392 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 340 Avg_loss: 0.04823785647749901 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 341 Avg_loss: 0.04812504798173904 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 342 Avg_loss: 0.047992178797721864 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 343 Avg_loss: 0.04784774500876665 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 344 Avg_loss: 0.047726256959140304 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 345 Avg_loss: 0.04761065114289522 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 346 Avg_loss: 0.047496977262198925 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 347 Avg_loss: 0.04736398123204708 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 348 Avg_loss: 0.047233718633651736 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 349 Avg_loss: 0.04711921662092209 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 350 Avg_loss: 0.047010803036391734 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 351 Avg_loss: 0.046906291879713534 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 352 Avg_loss: 0.046757782064378264 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 353 Avg_loss: 0.046748092770576476 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 354 Avg_loss: 0.046636076644062996 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 355 Avg_loss: 0.046482513472437856 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 356 Avg_loss: 0.04633735213428736 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 357 Avg_loss: 0.04622030295431614 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 358 Avg_loss: 0.04610117226839065 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 359 Avg_loss: 0.04602323118597269 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 360 Avg_loss: 0.04586986023932695 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 361 Avg_loss: 0.04576641861349344 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 362 Avg_loss: 0.045641041547060016 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 363 Avg_loss: 0.045500056631863114 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 364 Avg_loss: 0.045399066247046 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 365 Avg_loss: 0.0453089902177453 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 366 Avg_loss: 0.04517692271620035 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 367 Avg_loss: 0.045054126530885696 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 368 Avg_loss: 0.0449230307713151 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 369 Avg_loss: 0.04481446947902441 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 370 Avg_loss: 0.044737199507653716 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 371 Avg_loss: 0.044599312171339986 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 372 Avg_loss: 0.04454985987395048 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 373 Avg_loss: 0.044467569701373576 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 374 Avg_loss: 0.04428458288311958 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 375 Avg_loss: 0.044154207408428195 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 376 Avg_loss: 0.044022411666810514 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 377 Avg_loss: 0.043925059773027894 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 378 Avg_loss: 0.043835723772645 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 379 Avg_loss: 0.043764919601380826 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 380 Avg_loss: 0.04373983424156904 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 381 Avg_loss: 0.04359879344701767 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 382 Avg_loss: 0.044013628736138344 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 383 Avg_loss: 0.04403661470860243 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 384 Avg_loss: 0.043380824662744996 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 385 Avg_loss: 0.043100045062601566 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 386 Avg_loss: 0.04305058754980564 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 387 Avg_loss: 0.042873670160770413 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 388 Avg_loss: 0.04272499904036522 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 389 Avg_loss: 0.04261240866035223 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 390 Avg_loss: 0.042494498379528525 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 391 Avg_loss: 0.0423707677051425 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 392 Avg_loss: 0.042269739881157876 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 393 Avg_loss: 0.04226096346974373 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 394 Avg_loss: 0.04210685733705759 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 395 Avg_loss: 0.04195769894868136 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 396 Avg_loss: 0.04186998251825571 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 397 Avg_loss: 0.041887741163372995 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 398 Avg_loss: 0.04237428307533264 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 399 Avg_loss: 0.0423117570579052 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 400 Avg_loss: 0.04211946222931147 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 401 Avg_loss: 0.041774066351354125 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 402 Avg_loss: 0.04140964113175869 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 403 Avg_loss: 0.041228700801730155 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 404 Avg_loss: 0.04108421672135591 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 405 Avg_loss: 0.04095633253455162 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 406 Avg_loss: 0.04090093523263931 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 407 Avg_loss: 0.04077905472368002 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 408 Avg_loss: 0.0406845236197114 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 409 Avg_loss: 0.040650725923478605 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 410 Avg_loss: 0.04133700225502253 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 411 Avg_loss: 0.041301550716161727 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 412 Avg_loss: 1.1756445094943047 training accuracy: 0.63125 test accuracy: 0.2789115646258503\n",
      "Epoch: 413 Avg_loss: 1.4834968775510788 training accuracy: 0.478125 test accuracy: 0.22448979591836735\n",
      "Epoch: 414 Avg_loss: 0.9331301659345627 training accuracy: 0.725 test accuracy: 0.21768707482993196\n",
      "Epoch: 415 Avg_loss: 0.6856405675411225 training accuracy: 0.86875 test accuracy: 0.23129251700680273\n",
      "Epoch: 416 Avg_loss: 0.5559649497270585 training accuracy: 0.928125 test accuracy: 0.24489795918367346\n",
      "Epoch: 417 Avg_loss: 0.41924610137939455 training accuracy: 0.965625 test accuracy: 0.24489795918367346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 418 Avg_loss: 0.3442343272268772 training accuracy: 0.96875 test accuracy: 0.24489795918367346\n",
      "Epoch: 419 Avg_loss: 0.2908896081149578 training accuracy: 0.990625 test accuracy: 0.23129251700680273\n",
      "Epoch: 420 Avg_loss: 0.2479313224554062 training accuracy: 0.99375 test accuracy: 0.2585034013605442\n",
      "Epoch: 421 Avg_loss: 0.2136991523206234 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 422 Avg_loss: 0.194097863137722 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 423 Avg_loss: 0.18124580159783363 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 424 Avg_loss: 0.1707724705338478 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 425 Avg_loss: 0.16251186430454254 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 426 Avg_loss: 0.15513676181435584 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 427 Avg_loss: 0.1491573840379715 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 428 Avg_loss: 0.14350151792168617 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 429 Avg_loss: 0.13899454325437546 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 430 Avg_loss: 0.13424052968621253 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 431 Avg_loss: 0.1301889605820179 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 432 Avg_loss: 0.1265309751033783 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 433 Avg_loss: 0.12305911593139171 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 434 Avg_loss: 0.11981263011693954 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 435 Avg_loss: 0.11683171689510345 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 436 Avg_loss: 0.11402913592755795 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 437 Avg_loss: 0.1113499566912651 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 438 Avg_loss: 0.10889741331338883 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 439 Avg_loss: 0.10656622052192688 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 440 Avg_loss: 0.10441928394138814 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 441 Avg_loss: 0.10233795829117298 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 442 Avg_loss: 0.10039056241512298 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 443 Avg_loss: 0.0985268458724022 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 444 Avg_loss: 0.0967767085880041 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 445 Avg_loss: 0.09507757239043713 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 446 Avg_loss: 0.09348928220570088 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 447 Avg_loss: 0.09192597046494484 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 448 Avg_loss: 0.09045522585511208 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 449 Avg_loss: 0.0890246495604515 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 450 Avg_loss: 0.08766979724168777 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 451 Avg_loss: 0.0863456405699253 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 452 Avg_loss: 0.08509692624211311 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 453 Avg_loss: 0.08388266563415528 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 454 Avg_loss: 0.08273836746811866 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 455 Avg_loss: 0.08161095380783082 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 456 Avg_loss: 0.08054322898387908 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 457 Avg_loss: 0.07950733378529548 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 458 Avg_loss: 0.07852008379995823 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 459 Avg_loss: 0.07754888199269772 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 460 Avg_loss: 0.07663442231714726 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 461 Avg_loss: 0.0757310751825571 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 462 Avg_loss: 0.07487673759460449 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 463 Avg_loss: 0.0740296185016632 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 464 Avg_loss: 0.0732411127537489 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 465 Avg_loss: 0.07245336845517159 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 466 Avg_loss: 0.07171524241566658 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 467 Avg_loss: 0.07097734585404396 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 468 Avg_loss: 0.07028329521417617 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 469 Avg_loss: 0.06959013938903809 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 470 Avg_loss: 0.06893965005874633 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 471 Avg_loss: 0.06827953532338142 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 472 Avg_loss: 0.06766945868730545 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 473 Avg_loss: 0.06706038229167462 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 474 Avg_loss: 0.0664905320852995 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 475 Avg_loss: 0.06590788960456848 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 476 Avg_loss: 0.06536918841302394 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 477 Avg_loss: 0.06482766680419445 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 478 Avg_loss: 0.06432517692446708 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 479 Avg_loss: 0.06381803005933762 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 480 Avg_loss: 0.06334092412143946 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 481 Avg_loss: 0.06286054961383343 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 482 Avg_loss: 0.06241122297942638 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 483 Avg_loss: 0.06195522025227547 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 484 Avg_loss: 0.061534967832267286 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 485 Avg_loss: 0.06110667306929827 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 486 Avg_loss: 0.06070848498493433 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 487 Avg_loss: 0.06030516494065523 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 488 Avg_loss: 0.05993491355329752 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 489 Avg_loss: 0.05955454632639885 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 490 Avg_loss: 0.059202670305967334 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 491 Avg_loss: 0.05884187445044518 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 492 Avg_loss: 0.05851040780544281 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 493 Avg_loss: 0.05816720128059387 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 494 Avg_loss: 0.05785269010812044 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 495 Avg_loss: 0.05752851143479347 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 496 Avg_loss: 0.057228251732885836 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 497 Avg_loss: 0.05692063644528389 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 498 Avg_loss: 0.05663943476974964 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 499 Avg_loss: 0.056346066296100616 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 500 Avg_loss: 0.05607728455215692 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 501 Avg_loss: 0.055794517323374745 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 502 Avg_loss: 0.05554245226085186 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 503 Avg_loss: 0.0552801851183176 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 504 Avg_loss: 0.055042431317269803 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 505 Avg_loss: 0.0547900777310133 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 506 Avg_loss: 0.05456514805555344 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 507 Avg_loss: 0.05432901568710804 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 508 Avg_loss: 0.054116223193705085 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 509 Avg_loss: 0.05388583578169346 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 510 Avg_loss: 0.05368625409901142 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 511 Avg_loss: 0.05346585121005774 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 512 Avg_loss: 0.05327553655952215 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 513 Avg_loss: 0.05306586176156998 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 514 Avg_loss: 0.052880875580012796 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 515 Avg_loss: 0.052690168097615245 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 516 Avg_loss: 0.05250799376517534 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 517 Avg_loss: 0.052312825061380866 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 518 Avg_loss: 0.05214404296129942 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 519 Avg_loss: 0.05195961501449346 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 520 Avg_loss: 0.05179525725543499 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 521 Avg_loss: 0.051618827506899834 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 522 Avg_loss: 0.051465791277587415 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 523 Avg_loss: 0.05129451435059309 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 524 Avg_loss: 0.05114899892359972 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 525 Avg_loss: 0.0509821642190218 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 526 Avg_loss: 0.05084258075803518 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 527 Avg_loss: 0.05068498887121677 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 528 Avg_loss: 0.05054906252771616 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 529 Avg_loss: 0.05039730910211802 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 530 Avg_loss: 0.050262270122766496 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 531 Avg_loss: 0.050135357119143006 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 532 Avg_loss: 0.04999622348695994 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 533 Avg_loss: 0.04984435979276895 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 534 Avg_loss: 0.04971876665949822 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 535 Avg_loss: 0.04959485717117786 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 536 Avg_loss: 0.04946482051163912 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 537 Avg_loss: 0.049333093129098414 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 538 Avg_loss: 0.04920988064259291 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 539 Avg_loss: 0.0490823108702898 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 540 Avg_loss: 0.048962926119565965 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 541 Avg_loss: 0.048835348710417746 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 542 Avg_loss: 0.048737280815839765 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 543 Avg_loss: 0.048621881380677225 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 544 Avg_loss: 0.0486752787604928 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 545 Avg_loss: 0.048473513685166836 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 546 Avg_loss: 0.0483004791662097 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 547 Avg_loss: 0.04816895481199026 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 548 Avg_loss: 0.048071841895580295 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 549 Avg_loss: 0.047948207706213 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 550 Avg_loss: 0.04786468558013439 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 551 Avg_loss: 0.047771119698882106 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 552 Avg_loss: 0.04783521369099617 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 553 Avg_loss: 0.04761610627174377 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 554 Avg_loss: 0.047469745948910715 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 555 Avg_loss: 0.04734522737562656 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 556 Avg_loss: 0.04725045096129179 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 557 Avg_loss: 0.04713374227285385 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 558 Avg_loss: 0.04704670999199152 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 559 Avg_loss: 0.0469300389289856 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 560 Avg_loss: 0.0468398904427886 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 561 Avg_loss: 0.04672741089016199 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 562 Avg_loss: 0.04664244279265404 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 563 Avg_loss: 0.04654540736228228 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 564 Avg_loss: 0.0465505875647068 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 565 Avg_loss: 0.046366857923567296 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 566 Avg_loss: 0.046267845295369626 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 567 Avg_loss: 0.04617313668131828 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 568 Avg_loss: 0.046103174798190594 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 569 Avg_loss: 0.04598873313516379 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 570 Avg_loss: 0.04590351637452841 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 571 Avg_loss: 0.04579936265945435 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 572 Avg_loss: 0.045718013867735864 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 573 Avg_loss: 0.0456114362925291 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 574 Avg_loss: 0.04553682766854763 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 575 Avg_loss: 0.04546744897961617 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 576 Avg_loss: 0.04536152929067612 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 577 Avg_loss: 0.045247114077210424 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 578 Avg_loss: 0.04516778122633695 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 579 Avg_loss: 0.04508218113332987 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 580 Avg_loss: 0.045013473555445674 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 581 Avg_loss: 0.044905397854745385 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 582 Avg_loss: 0.0448181364685297 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 583 Avg_loss: 0.04472321607172489 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 584 Avg_loss: 0.0446498429402709 training accuracy: 1.0 test accuracy: 0.2653061224489796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 585 Avg_loss: 0.04458125587552786 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 586 Avg_loss: 0.04447831567376852 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 587 Avg_loss: 0.04437840934842825 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 588 Avg_loss: 0.044296926073729995 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 589 Avg_loss: 0.04422138798981905 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 590 Avg_loss: 0.044127139076590535 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 591 Avg_loss: 0.04404718019068241 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 592 Avg_loss: 0.04396770242601633 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 593 Avg_loss: 0.04388036709278822 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 594 Avg_loss: 0.043790663778781894 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 595 Avg_loss: 0.04371386356651783 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 596 Avg_loss: 0.04361071363091469 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 597 Avg_loss: 0.043544824607670306 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 598 Avg_loss: 0.04343701805919409 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 599 Avg_loss: 0.04338322933763265 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 600 Avg_loss: 0.0432954078540206 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 601 Avg_loss: 0.043203876726329325 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 602 Avg_loss: 0.04311696719378233 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 603 Avg_loss: 0.0430526027455926 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 604 Avg_loss: 0.04293029196560383 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 605 Avg_loss: 0.0428661897778511 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 606 Avg_loss: 0.04273181986063719 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 607 Avg_loss: 0.04270257279276848 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 608 Avg_loss: 0.04261839985847473 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 609 Avg_loss: 0.04250415619462729 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 610 Avg_loss: 0.04243150688707829 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 611 Avg_loss: 0.04232039656490087 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 612 Avg_loss: 0.04228032547980547 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 613 Avg_loss: 0.04217209536582232 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 614 Avg_loss: 0.042064248397946355 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 615 Avg_loss: 0.041988791152834895 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 616 Avg_loss: 0.041904390417039396 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 617 Avg_loss: 0.041817130707204345 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 618 Avg_loss: 0.04176184050738811 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 619 Avg_loss: 0.04167729187756777 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 620 Avg_loss: 0.04157484527677298 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 621 Avg_loss: 0.04148088321089745 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 622 Avg_loss: 0.041418200731277464 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 623 Avg_loss: 0.041347021237015724 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 624 Avg_loss: 0.04128653854131699 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 625 Avg_loss: 0.04131380300968886 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 626 Avg_loss: 0.04123010654002428 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 627 Avg_loss: 0.04125955067574978 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 628 Avg_loss: 0.04118252210319042 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 629 Avg_loss: 0.041042966581881044 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 630 Avg_loss: 0.04096636697649956 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 631 Avg_loss: 0.04092726372182369 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 632 Avg_loss: 0.04083766583353281 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 633 Avg_loss: 0.0406176844611764 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 634 Avg_loss: 0.04046683572232723 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 635 Avg_loss: 0.04029383920133114 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 636 Avg_loss: 0.04023509658873081 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 637 Avg_loss: 0.04012989103794098 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 638 Avg_loss: 0.04015000369399786 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 639 Avg_loss: 0.03997261207550764 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 640 Avg_loss: 0.04019212797284126 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 641 Avg_loss: 0.04011670164763927 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 642 Avg_loss: 0.040570597536861895 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 643 Avg_loss: 0.46405898574739696 training accuracy: 0.9375 test accuracy: 0.29931972789115646\n",
      "Epoch: 644 Avg_loss: 0.8058133482933044 training accuracy: 0.784375 test accuracy: 0.24489795918367346\n",
      "Epoch: 645 Avg_loss: 0.7521084971725941 training accuracy: 0.74375 test accuracy: 0.2789115646258503\n",
      "Epoch: 646 Avg_loss: 0.4979530990123749 training accuracy: 0.875 test accuracy: 0.24489795918367346\n",
      "Epoch: 647 Avg_loss: 0.31274702697992324 training accuracy: 0.946875 test accuracy: 0.24489795918367346\n",
      "Epoch: 648 Avg_loss: 0.22385706827044488 training accuracy: 0.9875 test accuracy: 0.23809523809523808\n",
      "Epoch: 649 Avg_loss: 0.17764744460582732 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 650 Avg_loss: 0.14850419461727143 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 651 Avg_loss: 0.13583032563328742 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 652 Avg_loss: 0.1269863061606884 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 653 Avg_loss: 0.12032439820468425 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 654 Avg_loss: 0.11494319662451744 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 655 Avg_loss: 0.11038920916616916 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 656 Avg_loss: 0.10645121783018112 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 657 Avg_loss: 0.10298129953444005 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 658 Avg_loss: 0.09985389038920403 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 659 Avg_loss: 0.09699512720108032 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 660 Avg_loss: 0.09443654268980026 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 661 Avg_loss: 0.09212848208844662 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 662 Avg_loss: 0.09001812785863876 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 663 Avg_loss: 0.08805676437914371 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 664 Avg_loss: 0.08622555248439312 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 665 Avg_loss: 0.08451795801520348 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 666 Avg_loss: 0.08292572125792504 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 667 Avg_loss: 0.0814326662570238 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 668 Avg_loss: 0.08001816608011722 training accuracy: 1.0 test accuracy: 0.25170068027210885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 669 Avg_loss: 0.07868707701563835 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 670 Avg_loss: 0.0774296686053276 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 671 Avg_loss: 0.0762504480779171 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 672 Avg_loss: 0.07510594092309475 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 673 Avg_loss: 0.07402525655925274 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 674 Avg_loss: 0.07299969866871833 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 675 Avg_loss: 0.07202030047774315 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 676 Avg_loss: 0.0710793349891901 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 677 Avg_loss: 0.07017529010772705 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 678 Avg_loss: 0.06931576989591122 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 679 Avg_loss: 0.06849713139235973 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 680 Avg_loss: 0.06770480312407016 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 681 Avg_loss: 0.06694610007107257 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 682 Avg_loss: 0.06621801629662513 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 683 Avg_loss: 0.06552609652280808 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 684 Avg_loss: 0.06485114842653275 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 685 Avg_loss: 0.06420410759747028 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 686 Avg_loss: 0.0635667447000742 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 687 Avg_loss: 0.06296093408018351 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 688 Avg_loss: 0.06238437667489052 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 689 Avg_loss: 0.06182605940848589 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 690 Avg_loss: 0.06139253843575716 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 691 Avg_loss: 0.060844702459871766 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 692 Avg_loss: 0.060330164059996604 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 693 Avg_loss: 0.059841263294219973 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 694 Avg_loss: 0.059372730925679205 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 695 Avg_loss: 0.05892235916107893 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 696 Avg_loss: 0.05848557148128748 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 697 Avg_loss: 0.05806429386138916 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 698 Avg_loss: 0.05766264740377665 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 699 Avg_loss: 0.05727433376014233 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 700 Avg_loss: 0.056890908256173135 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 701 Avg_loss: 0.056536243110895154 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 702 Avg_loss: 0.05617623906582594 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 703 Avg_loss: 0.05581322107464075 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 704 Avg_loss: 0.055480982176959515 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 705 Avg_loss: 0.055165437422692774 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 706 Avg_loss: 0.05482850279659033 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 707 Avg_loss: 0.05451603401452303 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 708 Avg_loss: 0.05421601869165897 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 709 Avg_loss: 0.05391958560794592 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 710 Avg_loss: 0.05363428220152855 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 711 Avg_loss: 0.053356053121387956 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 712 Avg_loss: 0.05308422539383173 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 713 Avg_loss: 0.05282019414007664 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 714 Avg_loss: 0.052565235272049905 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 715 Avg_loss: 0.05231300611048937 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 716 Avg_loss: 0.05207178890705109 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 717 Avg_loss: 0.05183187704533339 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 718 Avg_loss: 0.051601582765579225 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 719 Avg_loss: 0.051371004059910776 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 720 Avg_loss: 0.05114734303206205 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 721 Avg_loss: 0.050937898457050323 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 722 Avg_loss: 0.05072932597249746 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 723 Avg_loss: 0.05052858088165522 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 724 Avg_loss: 0.05033362358808517 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 725 Avg_loss: 0.05014629028737545 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 726 Avg_loss: 0.04995244052261114 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 727 Avg_loss: 0.0497666759416461 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 728 Avg_loss: 0.04957958627492189 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 729 Avg_loss: 0.04939112141728401 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 730 Avg_loss: 0.0492229288443923 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 731 Avg_loss: 0.04904993586242199 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 732 Avg_loss: 0.04888667147606611 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 733 Avg_loss: 0.04872313141822815 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 734 Avg_loss: 0.048581736348569396 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 735 Avg_loss: 0.048414487205445764 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 736 Avg_loss: 0.04826178681105375 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 737 Avg_loss: 0.048111874423921105 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 738 Avg_loss: 0.0479672746732831 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 739 Avg_loss: 0.04782015103846789 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 740 Avg_loss: 0.04768156446516514 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 741 Avg_loss: 0.047567020542919634 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 742 Avg_loss: 0.04741443190723658 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 743 Avg_loss: 0.04727576188743114 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 744 Avg_loss: 0.04714232999831438 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 745 Avg_loss: 0.04703016746789217 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 746 Avg_loss: 0.04690019059926272 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 747 Avg_loss: 0.046788292936980724 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 748 Avg_loss: 0.04663389455527067 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 749 Avg_loss: 0.04651312176138163 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 750 Avg_loss: 0.046400427259504794 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 751 Avg_loss: 0.04627579990774393 training accuracy: 1.0 test accuracy: 0.25170068027210885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 752 Avg_loss: 0.04614206757396459 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 753 Avg_loss: 0.046016845107078555 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 754 Avg_loss: 0.045899559184908865 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 755 Avg_loss: 0.04578245412558317 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 756 Avg_loss: 0.0456695569679141 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 757 Avg_loss: 0.04555996637791395 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 758 Avg_loss: 0.04544321782886982 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 759 Avg_loss: 0.04533691667020321 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 760 Avg_loss: 0.04525562934577465 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 761 Avg_loss: 0.04511237237602472 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 762 Avg_loss: 0.04500347170978784 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 763 Avg_loss: 0.04489513151347637 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 764 Avg_loss: 0.044790488108992575 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 765 Avg_loss: 0.0446878906339407 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 766 Avg_loss: 0.04458725582808256 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 767 Avg_loss: 0.0444828886538744 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 768 Avg_loss: 0.04438286554068327 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 769 Avg_loss: 0.04427953716367483 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 770 Avg_loss: 0.04417742192745209 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 771 Avg_loss: 0.044076445326209066 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 772 Avg_loss: 0.043975415639579296 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 773 Avg_loss: 0.04387556165456772 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 774 Avg_loss: 0.04377708584070206 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 775 Avg_loss: 0.04367933738976717 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 776 Avg_loss: 0.04357993006706238 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 777 Avg_loss: 0.04348408076912165 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 778 Avg_loss: 0.043385642021894454 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 779 Avg_loss: 0.04329108353704214 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 780 Avg_loss: 0.04319000132381916 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 781 Avg_loss: 0.043096203915774824 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 782 Avg_loss: 0.04299954492598772 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 783 Avg_loss: 0.04290397483855486 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 784 Avg_loss: 0.04281020369380713 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 785 Avg_loss: 0.04271448776125908 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 786 Avg_loss: 0.04261870235204697 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 787 Avg_loss: 0.04252953808754682 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 788 Avg_loss: 0.042435863986611366 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 789 Avg_loss: 0.04234823882579804 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 790 Avg_loss: 0.042259922437369826 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 791 Avg_loss: 0.042174787260591984 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 792 Avg_loss: 0.04208232183009386 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 793 Avg_loss: 0.04199316948652267 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 794 Avg_loss: 0.04190712906420231 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 795 Avg_loss: 0.041819576360285285 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 796 Avg_loss: 0.0417307673022151 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 797 Avg_loss: 0.04164108652621508 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 798 Avg_loss: 0.04155430868268013 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 799 Avg_loss: 0.041465099155902865 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 800 Avg_loss: 0.041377457045018676 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 801 Avg_loss: 0.041295517794787885 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 802 Avg_loss: 0.04120223261415958 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 803 Avg_loss: 0.04112185854464769 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 804 Avg_loss: 0.0410375289618969 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 805 Avg_loss: 0.040942574851214886 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 806 Avg_loss: 0.04085613079369068 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 807 Avg_loss: 0.040760806761682034 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 808 Avg_loss: 0.040664452314376834 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 809 Avg_loss: 0.04057330209761858 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 810 Avg_loss: 0.040480274520814416 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 811 Avg_loss: 0.04038894735276699 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 812 Avg_loss: 0.040333697386085984 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 813 Avg_loss: 0.04024787209928036 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 814 Avg_loss: 0.04014274198561907 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 815 Avg_loss: 0.040044399164617064 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 816 Avg_loss: 0.039960756152868274 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 817 Avg_loss: 0.039877035282552244 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 818 Avg_loss: 0.03979671746492386 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 819 Avg_loss: 0.039719529822468756 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 820 Avg_loss: 0.03964088950306177 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 821 Avg_loss: 0.039555464126169684 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 822 Avg_loss: 0.03950284086167812 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 823 Avg_loss: 0.03940825704485178 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 824 Avg_loss: 0.03931085653603077 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 825 Avg_loss: 0.03921633381396532 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 826 Avg_loss: 0.03914862275123596 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 827 Avg_loss: 0.03905788157135248 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 828 Avg_loss: 0.039001844637095925 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 829 Avg_loss: 0.038921726122498515 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 830 Avg_loss: 0.03881248719990253 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 831 Avg_loss: 0.03875430542975664 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 832 Avg_loss: 0.03868284150958061 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 833 Avg_loss: 0.03863737471401692 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 834 Avg_loss: 0.03853156920522451 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 835 Avg_loss: 0.038428622856736185 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 836 Avg_loss: 0.03836913201957941 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 837 Avg_loss: 0.03829632978886366 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 838 Avg_loss: 0.03821360487490892 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 839 Avg_loss: 0.03819531723856926 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 840 Avg_loss: 0.03810282405465841 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 841 Avg_loss: 0.03799314089119434 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 842 Avg_loss: 0.03791865110397339 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 843 Avg_loss: 0.037865011394023894 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 844 Avg_loss: 0.03776453994214535 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 845 Avg_loss: 0.037804259173572066 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 846 Avg_loss: 0.03770377729088068 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 847 Avg_loss: 0.03765134736895561 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 848 Avg_loss: 0.0374904677271843 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 849 Avg_loss: 0.03741682674735784 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 850 Avg_loss: 0.03740741107612848 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 851 Avg_loss: 0.03732276670634747 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 852 Avg_loss: 0.03785723727196455 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 853 Avg_loss: 0.15396088548004627 training accuracy: 0.978125 test accuracy: 0.272108843537415\n",
      "Epoch: 854 Avg_loss: 0.3560030959546566 training accuracy: 0.909375 test accuracy: 0.25170068027210885\n",
      "Epoch: 855 Avg_loss: 0.39554530158638956 training accuracy: 0.91875 test accuracy: 0.25170068027210885\n",
      "Epoch: 856 Avg_loss: 0.43637397661805155 training accuracy: 0.896875 test accuracy: 0.2789115646258503\n",
      "Epoch: 857 Avg_loss: 0.43974422812461855 training accuracy: 0.865625 test accuracy: 0.2108843537414966\n",
      "Epoch: 858 Avg_loss: 0.27667476013302805 training accuracy: 0.94375 test accuracy: 0.24489795918367346\n",
      "Epoch: 859 Avg_loss: 0.1810356441885233 training accuracy: 0.984375 test accuracy: 0.29931972789115646\n",
      "Epoch: 860 Avg_loss: 0.1172857403755188 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 861 Avg_loss: 0.09545705579221249 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 862 Avg_loss: 0.08644195050001144 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 863 Avg_loss: 0.08102041967213154 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 864 Avg_loss: 0.07699656337499619 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 865 Avg_loss: 0.07372369170188904 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 866 Avg_loss: 0.07106224671006203 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 867 Avg_loss: 0.06883292496204377 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 868 Avg_loss: 0.06693147644400596 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 869 Avg_loss: 0.0652703158557415 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 870 Avg_loss: 0.06378346607089043 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 871 Avg_loss: 0.06248907279223204 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 872 Avg_loss: 0.061383179388940334 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 873 Avg_loss: 0.06037365775555372 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 874 Avg_loss: 0.05947278439998627 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 875 Avg_loss: 0.05865792222321033 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 876 Avg_loss: 0.05791781228035688 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 877 Avg_loss: 0.05724142696708441 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 878 Avg_loss: 0.05662586484104395 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 879 Avg_loss: 0.05606247168034315 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 880 Avg_loss: 0.055546128936111924 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 881 Avg_loss: 0.05506913363933563 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 882 Avg_loss: 0.054624458961188796 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 883 Avg_loss: 0.054212134703993796 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 884 Avg_loss: 0.053835443966090676 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 885 Avg_loss: 0.05348067712038755 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 886 Avg_loss: 0.05315190125256777 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 887 Avg_loss: 0.05284191109240055 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 888 Avg_loss: 0.05255201868712902 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 889 Avg_loss: 0.052276444248855115 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 890 Avg_loss: 0.05201622117310763 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 891 Avg_loss: 0.05176589861512184 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 892 Avg_loss: 0.05152799841016531 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 893 Avg_loss: 0.05130417011678219 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 894 Avg_loss: 0.05109613984823227 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 895 Avg_loss: 0.050897618569433686 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 896 Avg_loss: 0.05070730149745941 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 897 Avg_loss: 0.05052542388439178 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 898 Avg_loss: 0.05034733284264803 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 899 Avg_loss: 0.05017695743590593 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 900 Avg_loss: 0.05001075211912394 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 901 Avg_loss: 0.04984922222793102 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 902 Avg_loss: 0.04969246108084917 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 903 Avg_loss: 0.0495428629219532 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 904 Avg_loss: 0.04939788766205311 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 905 Avg_loss: 0.049256390519440175 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 906 Avg_loss: 0.04911845363676548 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 907 Avg_loss: 0.04898080248385668 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 908 Avg_loss: 0.048846816457808015 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 909 Avg_loss: 0.04871561769396067 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 910 Avg_loss: 0.04858567770570517 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 911 Avg_loss: 0.04845630321651697 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 912 Avg_loss: 0.04832206983119249 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 913 Avg_loss: 0.048198461346328256 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 914 Avg_loss: 0.04807910043746233 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 915 Avg_loss: 0.04795904122292995 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 916 Avg_loss: 0.0478428503498435 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 917 Avg_loss: 0.04772456251084804 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 918 Avg_loss: 0.04760974179953337 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 919 Avg_loss: 0.04749345630407333 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920 Avg_loss: 0.04738102946430445 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 921 Avg_loss: 0.0472652954980731 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 922 Avg_loss: 0.04715418945997953 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 923 Avg_loss: 0.04704281874001026 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 924 Avg_loss: 0.04693308807909489 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 925 Avg_loss: 0.04682162925601006 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 926 Avg_loss: 0.04670956637710333 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 927 Avg_loss: 0.046594743803143504 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 928 Avg_loss: 0.04647589195519686 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 929 Avg_loss: 0.04635783024132252 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 930 Avg_loss: 0.046247010491788386 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 931 Avg_loss: 0.04613681472837925 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 932 Avg_loss: 0.046033558808267115 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 933 Avg_loss: 0.04592691902071237 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 934 Avg_loss: 0.04582588616758585 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 935 Avg_loss: 0.045721630565822124 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 936 Avg_loss: 0.04562145881354809 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 937 Avg_loss: 0.04551662132143974 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 938 Avg_loss: 0.045417222380638125 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 939 Avg_loss: 0.045310893654823305 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 940 Avg_loss: 0.04521055147051811 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 941 Avg_loss: 0.04510338250547648 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 942 Avg_loss: 0.0449993846938014 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 943 Avg_loss: 0.04489066395908594 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 944 Avg_loss: 0.04479116164147854 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 945 Avg_loss: 0.04468476716428995 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 946 Avg_loss: 0.04458345249295235 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 947 Avg_loss: 0.04448977746069431 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 948 Avg_loss: 0.044386881217360494 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 949 Avg_loss: 0.04428149312734604 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 950 Avg_loss: 0.044188653118908405 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 951 Avg_loss: 0.0440852327272296 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 952 Avg_loss: 0.043984347581863405 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 953 Avg_loss: 0.043891618773341176 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 954 Avg_loss: 0.04379050377756357 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 955 Avg_loss: 0.043688167817890644 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 956 Avg_loss: 0.043598019331693647 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 957 Avg_loss: 0.04349904209375381 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 958 Avg_loss: 0.0434061111882329 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 959 Avg_loss: 0.04331979341804981 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 960 Avg_loss: 0.04321858417242765 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 961 Avg_loss: 0.04313005283474922 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 962 Avg_loss: 0.04303524438291788 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 963 Avg_loss: 0.04294632859528065 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 964 Avg_loss: 0.04284450225532055 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 965 Avg_loss: 0.04274497367441654 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 966 Avg_loss: 0.04266899861395359 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 967 Avg_loss: 0.042567371018230916 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 968 Avg_loss: 0.042467976734042165 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 969 Avg_loss: 0.042373675666749475 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 970 Avg_loss: 0.0423087228089571 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 971 Avg_loss: 0.04221034459769726 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 972 Avg_loss: 0.04210591111332178 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 973 Avg_loss: 0.042013146355748175 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 974 Avg_loss: 0.041934681683778764 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 975 Avg_loss: 0.041837763227522376 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 976 Avg_loss: 0.04174563195556402 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 977 Avg_loss: 0.04166203569620848 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 978 Avg_loss: 0.0415672916918993 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 979 Avg_loss: 0.041474828496575356 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 980 Avg_loss: 0.04141513854265213 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 981 Avg_loss: 0.04131399318575859 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 982 Avg_loss: 0.041207770071923736 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 983 Avg_loss: 0.04111609403043985 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 984 Avg_loss: 0.0410404147580266 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 985 Avg_loss: 0.04096739254891872 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 986 Avg_loss: 0.04087304249405861 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 987 Avg_loss: 0.04078985787928104 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 988 Avg_loss: 0.04068332873284817 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 989 Avg_loss: 0.040588326007127765 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 990 Avg_loss: 0.04054646957665682 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 991 Avg_loss: 0.040469263680279255 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 992 Avg_loss: 0.04034768398851156 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 993 Avg_loss: 0.04024636335670948 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 994 Avg_loss: 0.04013960603624582 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 995 Avg_loss: 0.0401006955653429 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 996 Avg_loss: 0.0399864511564374 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 997 Avg_loss: 0.03989797532558441 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 998 Avg_loss: 0.03980986513197422 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 999 Avg_loss: 0.03970183823257685 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1000 Avg_loss: 0.03966574277728796 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1001 Avg_loss: 0.03953372072428465 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1002 Avg_loss: 0.03942671623080969 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1003 Avg_loss: 0.03932649064809084 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1004 Avg_loss: 0.03924934975802898 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1005 Avg_loss: 0.03929917756468058 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1006 Avg_loss: 0.03918498568236828 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1007 Avg_loss: 0.0390442717820406 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1008 Avg_loss: 0.038966530747711656 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1009 Avg_loss: 0.03889293223619461 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1010 Avg_loss: 0.03885731883347034 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1011 Avg_loss: 0.038704519346356395 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1012 Avg_loss: 0.03860763981938362 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1013 Avg_loss: 0.038545812293887136 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1014 Avg_loss: 0.03855478428304195 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1015 Avg_loss: 0.038428528048098085 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1016 Avg_loss: 0.038322579115629196 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1017 Avg_loss: 0.038245692290365695 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1018 Avg_loss: 0.03814205173403025 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1019 Avg_loss: 0.03808093536645174 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1020 Avg_loss: 0.03799586016684771 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1021 Avg_loss: 0.03790020849555731 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1022 Avg_loss: 0.037820359133183955 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1023 Avg_loss: 0.03776721488684416 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1024 Avg_loss: 0.037723932415246964 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1025 Avg_loss: 0.03758896552026272 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1026 Avg_loss: 0.037526448257267475 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1027 Avg_loss: 0.037413735687732694 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1028 Avg_loss: 0.037323703058063984 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1029 Avg_loss: 0.037786688469350335 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1030 Avg_loss: 0.037542922981083394 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1031 Avg_loss: 0.03724468443542719 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1032 Avg_loss: 0.03709457218647003 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1033 Avg_loss: 0.03700017295777798 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1034 Avg_loss: 0.03687267880886793 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1035 Avg_loss: 0.03681061789393425 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1036 Avg_loss: 0.036713981069624424 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1037 Avg_loss: 0.03674183432012797 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1038 Avg_loss: 0.03670182954519987 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1039 Avg_loss: 0.0365515936166048 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1040 Avg_loss: 0.03646469675004482 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1041 Avg_loss: 0.03638176620006561 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1042 Avg_loss: 0.03629850577563047 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1043 Avg_loss: 0.03623120412230492 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1044 Avg_loss: 0.04536148924380541 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1045 Avg_loss: 0.05702479593455791 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1046 Avg_loss: 0.0548779359087348 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1047 Avg_loss: 0.051491484977304935 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1048 Avg_loss: 0.04887412078678608 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1049 Avg_loss: 0.046787358820438385 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1050 Avg_loss: 0.0451263140887022 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1051 Avg_loss: 0.0437510309740901 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1052 Avg_loss: 0.04257940370589495 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1053 Avg_loss: 0.041591208986938 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1054 Avg_loss: 0.04071614891290665 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1055 Avg_loss: 0.039957939833402636 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1056 Avg_loss: 0.03929583393037319 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1057 Avg_loss: 0.03870917353779078 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1058 Avg_loss: 0.03819581530988216 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1059 Avg_loss: 0.03774734679609537 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1060 Avg_loss: 0.03737550787627697 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1061 Avg_loss: 0.03711007889360189 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1062 Avg_loss: 0.036664183251559734 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1063 Avg_loss: 0.036356578767299655 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1064 Avg_loss: 0.03607463873922825 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1065 Avg_loss: 0.03583841063082218 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1066 Avg_loss: 0.03560781944543123 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1067 Avg_loss: 0.03541552945971489 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1068 Avg_loss: 0.0352325988933444 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1069 Avg_loss: 0.03510316424071789 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1070 Avg_loss: 0.035047310031950475 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1071 Avg_loss: 0.03488747607916594 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1072 Avg_loss: 0.034717945381999016 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1073 Avg_loss: 0.03454679232090711 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1074 Avg_loss: 0.03442448750138283 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1075 Avg_loss: 0.034301554411649705 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1076 Avg_loss: 0.03422095403075218 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1077 Avg_loss: 0.03414853475987911 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1078 Avg_loss: 0.03404477331787348 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1079 Avg_loss: 0.03399025499820709 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1080 Avg_loss: 0.03385023102164268 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1081 Avg_loss: 0.0337630208581686 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1082 Avg_loss: 0.033674603514373305 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1083 Avg_loss: 0.033609654381871225 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1084 Avg_loss: 0.03354560192674398 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1085 Avg_loss: 0.03346713110804558 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1086 Avg_loss: 0.03339771907776594 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1087 Avg_loss: 0.033345443196594715 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1088 Avg_loss: 0.033305348828434944 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1089 Avg_loss: 0.03327424619346857 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1090 Avg_loss: 0.03320468701422215 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1091 Avg_loss: 0.03316240794956684 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1092 Avg_loss: 0.03310731332749128 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1093 Avg_loss: 0.03306050337851048 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1094 Avg_loss: 0.03297101706266403 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1095 Avg_loss: 0.032900072261691095 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1096 Avg_loss: 0.03281920496374369 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1097 Avg_loss: 0.03279433902353048 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1098 Avg_loss: 0.03269452936947346 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1099 Avg_loss: 0.03264032807201147 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1100 Avg_loss: 0.03256959337741137 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1101 Avg_loss: 0.03258797843009233 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1102 Avg_loss: 0.03266793433576822 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1103 Avg_loss: 0.03267559837549925 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1104 Avg_loss: 0.03255533333867788 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1105 Avg_loss: 0.03242259304970503 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1106 Avg_loss: 0.032409555092453954 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1107 Avg_loss: 0.032327319122850896 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1108 Avg_loss: 0.032230698689818385 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1109 Avg_loss: 0.03214513827115297 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1110 Avg_loss: 0.032052377983927724 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1111 Avg_loss: 0.03198192324489355 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1112 Avg_loss: 0.0319287309423089 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1113 Avg_loss: 0.0318810461089015 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1114 Avg_loss: 0.03182292385026812 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1115 Avg_loss: 0.03178585758432746 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1116 Avg_loss: 0.03174297185614705 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1117 Avg_loss: 0.03176565077155828 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1118 Avg_loss: 0.03170958599075675 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1119 Avg_loss: 0.03162980703637004 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1120 Avg_loss: 0.031578177120536566 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1121 Avg_loss: 0.03151483926922083 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1122 Avg_loss: 0.031513336673378946 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1123 Avg_loss: 0.03146063955500722 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1124 Avg_loss: 0.03154688216745853 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1125 Avg_loss: 0.031539928261190654 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1126 Avg_loss: 0.03142530033364892 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1127 Avg_loss: 0.031310768239200114 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1128 Avg_loss: 0.03125885557383299 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1129 Avg_loss: 0.03126379251480103 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1130 Avg_loss: 0.0311895789578557 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1131 Avg_loss: 0.031116745714098216 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1132 Avg_loss: 0.031135552655905487 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1133 Avg_loss: 0.03113595861941576 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1134 Avg_loss: 0.03099895380437374 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1135 Avg_loss: 0.03094091797247529 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1136 Avg_loss: 0.03090672418475151 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1137 Avg_loss: 0.03086893307045102 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1138 Avg_loss: 0.03075511008501053 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1139 Avg_loss: 0.030733382049947976 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1140 Avg_loss: 0.030721558444201946 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1141 Avg_loss: 0.03063153475522995 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1142 Avg_loss: 0.030553848948329687 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1143 Avg_loss: 0.03052529413253069 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1144 Avg_loss: 0.03060259632766247 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1145 Avg_loss: 0.030498036555945872 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1146 Avg_loss: 0.030400148965418337 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1147 Avg_loss: 0.030339081678539513 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1148 Avg_loss: 0.030321628786623478 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1149 Avg_loss: 0.03031520890071988 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1150 Avg_loss: 0.030292370170354844 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1151 Avg_loss: 0.03024181444197893 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1152 Avg_loss: 0.030303596053272486 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1153 Avg_loss: 0.03037564093247056 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1154 Avg_loss: 0.030533675011247395 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1155 Avg_loss: 0.03032252974808216 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1156 Avg_loss: 0.030445491801947354 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1157 Avg_loss: 0.030782217811793088 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1158 Avg_loss: 0.03093646988272667 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1159 Avg_loss: 0.0305630000308156 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1160 Avg_loss: 0.030287508573383092 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1161 Avg_loss: 0.03020209027454257 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1162 Avg_loss: 0.030029680021107195 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1163 Avg_loss: 0.029951998498290777 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1164 Avg_loss: 0.029850131087005138 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1165 Avg_loss: 0.02982622729614377 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1166 Avg_loss: 0.029705557227134704 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1167 Avg_loss: 0.029795614536851645 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1168 Avg_loss: 0.029832514002919197 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1169 Avg_loss: 0.02996897231787443 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1170 Avg_loss: 0.030331636685878037 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1171 Avg_loss: 0.030434814281761646 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1172 Avg_loss: 0.030312997847795488 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1173 Avg_loss: 0.030188634991645813 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1174 Avg_loss: 0.029907576367259027 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1175 Avg_loss: 0.02968625333160162 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1176 Avg_loss: 0.02946579158306122 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1177 Avg_loss: 0.02932363487780094 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1178 Avg_loss: 0.02925715036690235 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1179 Avg_loss: 0.029119280632585287 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1180 Avg_loss: 0.029071972239762545 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1181 Avg_loss: 0.02896656608209014 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1182 Avg_loss: 0.02898654630407691 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1183 Avg_loss: 0.029013649560511112 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1184 Avg_loss: 0.02900789035484195 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1185 Avg_loss: 0.028926293645054103 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1186 Avg_loss: 0.02902617435902357 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1187 Avg_loss: 0.029021276347339153 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1188 Avg_loss: 0.02909108540043235 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1189 Avg_loss: 0.02913154736161232 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1190 Avg_loss: 0.02922076666727662 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1191 Avg_loss: 0.02909210920333862 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1192 Avg_loss: 0.02907973323017359 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1193 Avg_loss: 0.028938089683651923 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1194 Avg_loss: 0.028785972204059363 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1195 Avg_loss: 0.028666487988084556 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1196 Avg_loss: 0.028640819899737834 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1197 Avg_loss: 0.0287680528126657 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1198 Avg_loss: 0.02910431232303381 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1199 Avg_loss: 0.02919569341465831 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1200 Avg_loss: 0.029302802216261626 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1201 Avg_loss: 0.029267862997949125 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1202 Avg_loss: 0.02918638791888952 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1203 Avg_loss: 0.029231213871389626 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1204 Avg_loss: 0.029252449888736008 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1205 Avg_loss: 0.02922011697664857 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1206 Avg_loss: 0.029242425784468652 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1207 Avg_loss: 0.02899370137602091 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1208 Avg_loss: 0.02879302855581045 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1209 Avg_loss: 0.02889045998454094 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1210 Avg_loss: 0.028794743306934833 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1211 Avg_loss: 0.02870318777859211 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1212 Avg_loss: 0.02863572407513857 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1213 Avg_loss: 0.028687371965497734 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1214 Avg_loss: 0.02881223987787962 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1215 Avg_loss: 0.028633882757276297 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1216 Avg_loss: 0.028491995017975568 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1217 Avg_loss: 0.028536710422486067 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1218 Avg_loss: 0.028666412737220526 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1219 Avg_loss: 0.02853951249271631 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1220 Avg_loss: 0.02853684322908521 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1221 Avg_loss: 0.028542548604309558 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1222 Avg_loss: 0.028396181482821702 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1223 Avg_loss: 0.02824958646669984 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1224 Avg_loss: 0.028470788430422545 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1225 Avg_loss: 0.028393773548305034 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1226 Avg_loss: 0.028119323682039975 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1227 Avg_loss: 0.02806491171941161 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1228 Avg_loss: 0.027938973251730205 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1229 Avg_loss: 0.028066741209477185 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1230 Avg_loss: 0.028338438458740713 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1231 Avg_loss: 0.028395139519125222 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1232 Avg_loss: 0.02848045779392123 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1233 Avg_loss: 0.028711598087102174 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1234 Avg_loss: 0.029021313413977623 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1235 Avg_loss: 0.030483417492359877 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1236 Avg_loss: 0.053418613970279694 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 1237 Avg_loss: 0.5684496767818927 training accuracy: 0.8125 test accuracy: 0.20408163265306123\n",
      "Epoch: 1238 Avg_loss: 0.7589008495211601 training accuracy: 0.728125 test accuracy: 0.24489795918367346\n",
      "Epoch: 1239 Avg_loss: 0.5839109480381012 training accuracy: 0.84375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1240 Avg_loss: 0.4579309269785881 training accuracy: 0.8875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1241 Avg_loss: 0.23674652725458145 training accuracy: 0.9875 test accuracy: 0.19047619047619047\n",
      "Epoch: 1242 Avg_loss: 0.17045859396457672 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1243 Avg_loss: 0.1344107583165169 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1244 Avg_loss: 0.11698576621711254 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1245 Avg_loss: 0.10709998570382595 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1246 Avg_loss: 0.10004219114780426 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1247 Avg_loss: 0.09453368708491325 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1248 Avg_loss: 0.08987648151814938 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1249 Avg_loss: 0.08587191812694073 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1250 Avg_loss: 0.08241707682609559 training accuracy: 1.0 test accuracy: 0.19047619047619047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1251 Avg_loss: 0.07935960292816162 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1252 Avg_loss: 0.07661402486264705 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1253 Avg_loss: 0.07417477332055569 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1254 Avg_loss: 0.07199409045279026 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1255 Avg_loss: 0.07001991085708141 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1256 Avg_loss: 0.0682036355137825 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1257 Avg_loss: 0.06654444299638271 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1258 Avg_loss: 0.06502643451094628 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1259 Avg_loss: 0.06363283842802048 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1260 Avg_loss: 0.06234989892691374 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1261 Avg_loss: 0.06116726938635111 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1262 Avg_loss: 0.06006792839616537 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1263 Avg_loss: 0.059040927514433864 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1264 Avg_loss: 0.05809990745037794 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1265 Avg_loss: 0.05720939487218857 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1266 Avg_loss: 0.05636646393686533 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1267 Avg_loss: 0.05557725895196199 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1268 Avg_loss: 0.05484782829880715 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1269 Avg_loss: 0.05415996927767992 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1270 Avg_loss: 0.05350865535438061 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1271 Avg_loss: 0.0528952032327652 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1272 Avg_loss: 0.052316122129559516 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1273 Avg_loss: 0.05177162401378155 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1274 Avg_loss: 0.051257450319826606 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1275 Avg_loss: 0.05077220257371664 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1276 Avg_loss: 0.05031295008957386 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1277 Avg_loss: 0.04987530820071697 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1278 Avg_loss: 0.04946420136839151 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1279 Avg_loss: 0.04907132424414158 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1280 Avg_loss: 0.048698408715426925 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1281 Avg_loss: 0.04834343250840902 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1282 Avg_loss: 0.048007340915501115 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1283 Avg_loss: 0.04768865257501602 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1284 Avg_loss: 0.0473858680576086 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1285 Avg_loss: 0.04709639642387629 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1286 Avg_loss: 0.04681889060884714 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1287 Avg_loss: 0.046553470008075234 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1288 Avg_loss: 0.04630035441368818 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1289 Avg_loss: 0.046057792752981185 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1290 Avg_loss: 0.04582407269626856 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1291 Avg_loss: 0.04560206066817045 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1292 Avg_loss: 0.04538683723658323 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1293 Avg_loss: 0.045180424489080905 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1294 Avg_loss: 0.04498189315199852 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1295 Avg_loss: 0.044789692386984825 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1296 Avg_loss: 0.044603866152465345 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1297 Avg_loss: 0.04442330803722143 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1298 Avg_loss: 0.044248517230153085 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1299 Avg_loss: 0.044081127271056175 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1300 Avg_loss: 0.04391914121806621 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1301 Avg_loss: 0.04375900886952877 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1302 Avg_loss: 0.04360574781894684 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1303 Avg_loss: 0.04345735684037209 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1304 Avg_loss: 0.04331359453499317 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1305 Avg_loss: 0.04317345023155213 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1306 Avg_loss: 0.04303783494979143 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1307 Avg_loss: 0.042904506996273996 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1308 Avg_loss: 0.042774132825434207 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1309 Avg_loss: 0.04264738652855158 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1310 Avg_loss: 0.042524686083197594 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1311 Avg_loss: 0.042401408031582835 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1312 Avg_loss: 0.042283129692077634 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1313 Avg_loss: 0.04216807838529348 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1314 Avg_loss: 0.042053201235830784 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1315 Avg_loss: 0.04194119460880756 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1316 Avg_loss: 0.04183055777102709 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1317 Avg_loss: 0.04172253794968128 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1318 Avg_loss: 0.04161436669528484 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1319 Avg_loss: 0.041508105397224423 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1320 Avg_loss: 0.041403135843575 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1321 Avg_loss: 0.04130031317472458 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1322 Avg_loss: 0.04120008144527674 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1323 Avg_loss: 0.041101524606347084 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1324 Avg_loss: 0.04100328609347344 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1325 Avg_loss: 0.04090994317084551 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1326 Avg_loss: 0.04081623312085867 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1327 Avg_loss: 0.040723119862377644 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1328 Avg_loss: 0.040628702379763126 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1329 Avg_loss: 0.040535379014909265 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1330 Avg_loss: 0.040446536242961885 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1331 Avg_loss: 0.040358940698206426 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1332 Avg_loss: 0.040272784605622294 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1333 Avg_loss: 0.04018911104649305 training accuracy: 1.0 test accuracy: 0.19727891156462585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1334 Avg_loss: 0.04010534062981606 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1335 Avg_loss: 0.04002210721373558 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1336 Avg_loss: 0.03993947952985764 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1337 Avg_loss: 0.03985595721751452 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1338 Avg_loss: 0.039771652035415175 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1339 Avg_loss: 0.039688153006136415 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1340 Avg_loss: 0.03960629291832447 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1341 Avg_loss: 0.039526684954762456 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1342 Avg_loss: 0.039445043355226514 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1343 Avg_loss: 0.039364395290613176 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1344 Avg_loss: 0.039285875484347345 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1345 Avg_loss: 0.03920475728809834 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1346 Avg_loss: 0.03912785742431879 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1347 Avg_loss: 0.039048746414482596 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1348 Avg_loss: 0.03897132184356451 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1349 Avg_loss: 0.03889606185257435 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1350 Avg_loss: 0.03882227316498756 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1351 Avg_loss: 0.03874592650681734 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1352 Avg_loss: 0.03867492619901895 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1353 Avg_loss: 0.038603446818888186 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1354 Avg_loss: 0.03852676320821047 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1355 Avg_loss: 0.038459106162190435 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1356 Avg_loss: 0.03838651143014431 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1357 Avg_loss: 0.038331519439816476 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1358 Avg_loss: 0.03827685751020908 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1359 Avg_loss: 0.03820974286645651 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1360 Avg_loss: 0.038116654939949514 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1361 Avg_loss: 0.03803158197551966 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1362 Avg_loss: 0.03797653522342444 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1363 Avg_loss: 0.037920004688203335 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1364 Avg_loss: 0.037842276878654955 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1365 Avg_loss: 0.03775197546929121 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1366 Avg_loss: 0.037675419449806215 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1367 Avg_loss: 0.037603970430791375 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1368 Avg_loss: 0.037532010860741136 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1369 Avg_loss: 0.03746052291244269 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1370 Avg_loss: 0.037388994731009005 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1371 Avg_loss: 0.03731566816568375 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1372 Avg_loss: 0.03724812939763069 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1373 Avg_loss: 0.03718192223459482 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1374 Avg_loss: 0.03711552955210209 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1375 Avg_loss: 0.0370470080524683 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1376 Avg_loss: 0.036977227032184604 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1377 Avg_loss: 0.036906253546476364 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1378 Avg_loss: 0.036839401721954344 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1379 Avg_loss: 0.0367758858948946 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1380 Avg_loss: 0.03670550510287285 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1381 Avg_loss: 0.03663723655045033 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1382 Avg_loss: 0.03657810017466545 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1383 Avg_loss: 0.036505705676972866 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1384 Avg_loss: 0.03642717394977808 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1385 Avg_loss: 0.036356058344244956 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1386 Avg_loss: 0.03628138415515423 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1387 Avg_loss: 0.03620706778019667 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1388 Avg_loss: 0.03614988550543785 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1389 Avg_loss: 0.036064262874424456 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1390 Avg_loss: 0.03600245770066977 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1391 Avg_loss: 0.035930083505809306 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1392 Avg_loss: 0.035866457223892215 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1393 Avg_loss: 0.03579858299344778 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1394 Avg_loss: 0.035750387236475945 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1395 Avg_loss: 0.035681867972016335 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1396 Avg_loss: 0.035616304352879526 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1397 Avg_loss: 0.035553556866943836 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1398 Avg_loss: 0.03548185247927904 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1399 Avg_loss: 0.03541225921362638 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1400 Avg_loss: 0.03535337429493666 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1401 Avg_loss: 0.03528318610042334 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1402 Avg_loss: 0.03522150497883558 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1403 Avg_loss: 0.03515812251716852 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1404 Avg_loss: 0.035093954205513 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1405 Avg_loss: 0.035031691752374174 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1406 Avg_loss: 0.034972202591598035 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1407 Avg_loss: 0.034912802278995514 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1408 Avg_loss: 0.03484880793839693 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1409 Avg_loss: 0.03478923439979553 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1410 Avg_loss: 0.03473006095737219 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1411 Avg_loss: 0.03467099666595459 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1412 Avg_loss: 0.0346129409968853 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1413 Avg_loss: 0.034559059888124466 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1414 Avg_loss: 0.03449684455990791 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1415 Avg_loss: 0.0344276225194335 training accuracy: 1.0 test accuracy: 0.24489795918367346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1416 Avg_loss: 0.03436672650277615 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1417 Avg_loss: 0.03430311251431704 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1418 Avg_loss: 0.03424893878400326 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1419 Avg_loss: 0.034186907857656476 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1420 Avg_loss: 0.03411868903785944 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1421 Avg_loss: 0.03405674584209919 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1422 Avg_loss: 0.033994640596210955 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1423 Avg_loss: 0.03394057303667068 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1424 Avg_loss: 0.033875885978341104 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1425 Avg_loss: 0.033831601962447166 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1426 Avg_loss: 0.03378363288938999 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1427 Avg_loss: 0.033724296279251574 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1428 Avg_loss: 0.03367413990199566 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1429 Avg_loss: 0.033645717054605485 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1430 Avg_loss: 0.033568424731493 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1431 Avg_loss: 0.03357756566256285 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1432 Avg_loss: 0.03353540878742933 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1433 Avg_loss: 0.03345086667686701 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1434 Avg_loss: 0.03336175326257944 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1435 Avg_loss: 0.03329413756728172 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1436 Avg_loss: 0.03325265869498253 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1437 Avg_loss: 0.03322089836001396 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1438 Avg_loss: 0.03315231390297413 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1439 Avg_loss: 0.033072380162775514 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1440 Avg_loss: 0.032984061166644096 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1441 Avg_loss: 0.032958803698420525 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1442 Avg_loss: 0.03292948696762323 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1443 Avg_loss: 0.0328605392947793 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1444 Avg_loss: 0.032785327173769474 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1445 Avg_loss: 0.03272743728011847 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1446 Avg_loss: 0.03268898595124483 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1447 Avg_loss: 0.03267352432012558 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1448 Avg_loss: 0.03262258898466826 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1449 Avg_loss: 0.03254385646432638 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1450 Avg_loss: 0.03248011711984873 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1451 Avg_loss: 0.032432688772678374 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1452 Avg_loss: 0.03235238455235958 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1453 Avg_loss: 0.03230640944093466 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1454 Avg_loss: 0.032271218672394755 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1455 Avg_loss: 0.0322092579677701 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1456 Avg_loss: 0.03216582797467708 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1457 Avg_loss: 0.03211177531629801 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1458 Avg_loss: 0.03208136707544327 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1459 Avg_loss: 0.03201914504170418 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1460 Avg_loss: 0.03200101554393768 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1461 Avg_loss: 0.03191938940435648 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1462 Avg_loss: 0.031870736833661796 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1463 Avg_loss: 0.03178411349654198 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1464 Avg_loss: 0.031746387295424935 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1465 Avg_loss: 0.03168919775635004 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1466 Avg_loss: 0.03163831187412143 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1467 Avg_loss: 0.03157830284908414 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1468 Avg_loss: 0.03154020551592111 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1469 Avg_loss: 0.031518842466175555 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1470 Avg_loss: 0.031449570413678886 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1471 Avg_loss: 0.03139401273801923 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1472 Avg_loss: 0.0313776945695281 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1473 Avg_loss: 0.03137116888538003 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1474 Avg_loss: 0.031323226261883975 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1475 Avg_loss: 0.03124368321150541 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1476 Avg_loss: 0.031195269711315633 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1477 Avg_loss: 0.03117159493267536 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1478 Avg_loss: 0.031103642005473376 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1479 Avg_loss: 0.031029857229441404 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1480 Avg_loss: 0.030975062120705842 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1481 Avg_loss: 0.030926303844898938 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1482 Avg_loss: 0.03091848436743021 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1483 Avg_loss: 0.030843708477914334 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1484 Avg_loss: 0.030831518676131965 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1485 Avg_loss: 0.03077707989141345 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1486 Avg_loss: 0.03081084191799164 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1487 Avg_loss: 0.030751463677734136 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1488 Avg_loss: 0.030723239947110414 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1489 Avg_loss: 0.030614316556602718 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1490 Avg_loss: 0.030568925477564336 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1491 Avg_loss: 0.03052608510479331 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1492 Avg_loss: 0.030461661424487828 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1493 Avg_loss: 0.030416507739573717 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1494 Avg_loss: 0.03042342746630311 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1495 Avg_loss: 0.03040176760405302 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1496 Avg_loss: 0.030447526834905148 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1497 Avg_loss: 0.030399912036955357 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1498 Avg_loss: 0.0303679920732975 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1499 Avg_loss: 0.03024534126743674 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1500 Avg_loss: 0.030170999001711607 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1501 Avg_loss: 0.030061063077300786 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1502 Avg_loss: 0.030050507094711066 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1503 Avg_loss: 0.029978257976472376 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1504 Avg_loss: 0.030002091079950333 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1505 Avg_loss: 0.029921609815210103 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1506 Avg_loss: 0.029880802519619463 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1507 Avg_loss: 0.02986229406669736 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1508 Avg_loss: 0.02982587441802025 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1509 Avg_loss: 0.029772634711116554 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1510 Avg_loss: 0.02979481117799878 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1511 Avg_loss: 0.029684973880648613 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1512 Avg_loss: 0.029727709386497735 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1513 Avg_loss: 0.02968641184270382 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1514 Avg_loss: 0.029680410120636224 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1515 Avg_loss: 0.029638022184371948 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1516 Avg_loss: 0.029601343814283608 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1517 Avg_loss: 0.02954510450363159 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1518 Avg_loss: 0.029454375524073838 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1519 Avg_loss: 0.029406133200973274 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1520 Avg_loss: 0.029373922012746335 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1521 Avg_loss: 0.029345477186143398 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1522 Avg_loss: 0.029312621988356113 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1523 Avg_loss: 0.029334740713238716 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1524 Avg_loss: 0.029260076023638247 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1525 Avg_loss: 0.029208886623382568 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1526 Avg_loss: 0.029142235312610863 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1527 Avg_loss: 0.02908377191051841 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1528 Avg_loss: 0.02913620574399829 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1529 Avg_loss: 0.029059993848204613 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1530 Avg_loss: 0.029047449864447118 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1531 Avg_loss: 0.029016538243740796 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1532 Avg_loss: 0.02904890142381191 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1533 Avg_loss: 0.029008359462022782 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1534 Avg_loss: 0.029039426986128093 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1535 Avg_loss: 0.02891216715797782 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1536 Avg_loss: 0.028891722857952117 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1537 Avg_loss: 0.02883359706029296 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1538 Avg_loss: 0.028829324617981912 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1539 Avg_loss: 0.028785448521375656 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1540 Avg_loss: 0.028771864902228116 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1541 Avg_loss: 0.02872976316139102 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1542 Avg_loss: 0.02881009681150317 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1543 Avg_loss: 0.02875206936150789 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1544 Avg_loss: 0.02869486464187503 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1545 Avg_loss: 0.02860209308564663 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1546 Avg_loss: 0.028571085911244153 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1547 Avg_loss: 0.02854965552687645 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1548 Avg_loss: 0.028551065362989902 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1549 Avg_loss: 0.028495851531624795 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1550 Avg_loss: 0.028481232468038797 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1551 Avg_loss: 0.028462436515837908 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1552 Avg_loss: 0.028470528684556483 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1553 Avg_loss: 0.028407093975692986 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1554 Avg_loss: 0.028373399656265973 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1555 Avg_loss: 0.028320010751485825 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1556 Avg_loss: 0.028284935839474203 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1557 Avg_loss: 0.028250886593014002 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1558 Avg_loss: 0.028293682355433704 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1559 Avg_loss: 0.028330507315695287 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1560 Avg_loss: 0.028397367149591447 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1561 Avg_loss: 0.02828051121905446 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1562 Avg_loss: 0.028264076635241508 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1563 Avg_loss: 0.028262779768556356 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1564 Avg_loss: 0.028221669606864452 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1565 Avg_loss: 0.028170214779675008 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1566 Avg_loss: 0.028158468939363957 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1567 Avg_loss: 0.028139619529247283 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1568 Avg_loss: 0.02818606225773692 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1569 Avg_loss: 0.02827013088390231 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1570 Avg_loss: 0.028383474983274936 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1571 Avg_loss: 0.028374345507472754 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1572 Avg_loss: 0.028359822276979686 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1573 Avg_loss: 0.02812714958563447 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1574 Avg_loss: 0.02805270757526159 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1575 Avg_loss: 0.028028193302452563 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1576 Avg_loss: 0.027933187037706374 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1577 Avg_loss: 0.027992777060717344 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1578 Avg_loss: 0.027909356541931628 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1579 Avg_loss: 0.027899848110973836 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1580 Avg_loss: 0.027947941794991493 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1581 Avg_loss: 0.027897770795971156 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1582 Avg_loss: 0.027912194840610027 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1583 Avg_loss: 0.027963324170559644 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1584 Avg_loss: 0.027897445112466814 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1585 Avg_loss: 0.027936161402612923 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1586 Avg_loss: 0.02799580292776227 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1587 Avg_loss: 0.02800185848027468 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1588 Avg_loss: 0.027752846851944922 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1589 Avg_loss: 0.02761893915012479 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1590 Avg_loss: 0.02759490106254816 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1591 Avg_loss: 0.027565609384328126 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1592 Avg_loss: 0.027675522770732642 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1593 Avg_loss: 0.027575482055544852 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1594 Avg_loss: 0.027561868820339442 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1595 Avg_loss: 0.027496338728815316 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1596 Avg_loss: 0.02755393963307142 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1597 Avg_loss: 0.027442311868071556 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1598 Avg_loss: 0.027379564847797154 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1599 Avg_loss: 0.027372115291655064 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1600 Avg_loss: 0.027451438084244727 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1601 Avg_loss: 0.02742752144113183 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1602 Avg_loss: 0.027453348319977523 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1603 Avg_loss: 0.02738322103396058 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1604 Avg_loss: 0.027333888318389656 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1605 Avg_loss: 0.02725571608170867 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1606 Avg_loss: 0.02728699902072549 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1607 Avg_loss: 0.027230930887162684 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1608 Avg_loss: 0.027260998915880918 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1609 Avg_loss: 0.027315109875053166 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1610 Avg_loss: 0.027247408963739873 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1611 Avg_loss: 0.027252449467778207 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1612 Avg_loss: 0.027485491521656514 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1613 Avg_loss: 0.027435771934688092 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1614 Avg_loss: 0.027258038707077503 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1615 Avg_loss: 0.02724777553230524 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1616 Avg_loss: 0.027274839766323566 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1617 Avg_loss: 0.027307186182588337 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1618 Avg_loss: 0.02719496563076973 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1619 Avg_loss: 0.027111347671598195 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1620 Avg_loss: 0.02704968526959419 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1621 Avg_loss: 0.027172432467341422 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1622 Avg_loss: 0.027308695670217275 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1623 Avg_loss: 0.02770412927493453 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1624 Avg_loss: 0.02765894765034318 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1625 Avg_loss: 0.02739272704347968 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1626 Avg_loss: 0.027265902142971754 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1627 Avg_loss: 0.02738836444914341 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1628 Avg_loss: 0.027696823235601187 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1629 Avg_loss: 0.027757862117141485 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1630 Avg_loss: 0.028159074764698745 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1631 Avg_loss: 0.029098526667803527 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1632 Avg_loss: 0.030441963579505682 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1633 Avg_loss: 0.036360809672623874 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1634 Avg_loss: 0.2635637713596225 training accuracy: 0.9375 test accuracy: 0.25170068027210885\n",
      "Epoch: 1635 Avg_loss: 1.0544919341802597 training accuracy: 0.734375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1636 Avg_loss: 1.2852386265993119 training accuracy: 0.8625 test accuracy: 0.19727891156462585\n",
      "Epoch: 1637 Avg_loss: 0.9419758975505829 training accuracy: 0.890625 test accuracy: 0.17687074829931973\n",
      "Epoch: 1638 Avg_loss: 0.5849990144371986 training accuracy: 0.984375 test accuracy: 0.22448979591836735\n",
      "Epoch: 1639 Avg_loss: 0.4163024201989174 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1640 Avg_loss: 0.3326944798231125 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1641 Avg_loss: 0.28502578288316727 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1642 Avg_loss: 0.2514835588634014 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1643 Avg_loss: 0.22596553787589074 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1644 Avg_loss: 0.2055213399231434 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1645 Avg_loss: 0.18870265707373618 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1646 Avg_loss: 0.17456440180540084 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1647 Avg_loss: 0.16248036846518515 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1648 Avg_loss: 0.1520363688468933 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1649 Avg_loss: 0.14291306734085082 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1650 Avg_loss: 0.13488395437598227 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1651 Avg_loss: 0.1277563266456127 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1652 Avg_loss: 0.12140310741961002 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1653 Avg_loss: 0.11570340991020203 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1654 Avg_loss: 0.11055801548063755 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1655 Avg_loss: 0.10590576343238353 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1656 Avg_loss: 0.10167120359838008 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1657 Avg_loss: 0.0978103056550026 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1658 Avg_loss: 0.09427062310278415 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1659 Avg_loss: 0.0910224437713623 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1660 Avg_loss: 0.08803185559809208 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1661 Avg_loss: 0.08526705577969551 training accuracy: 1.0 test accuracy: 0.16326530612244897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1662 Avg_loss: 0.08271019384264947 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1663 Avg_loss: 0.0803349707275629 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1664 Avg_loss: 0.07812321484088898 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1665 Avg_loss: 0.07606885060667992 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1666 Avg_loss: 0.07415246181190013 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1667 Avg_loss: 0.07235762178897857 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1668 Avg_loss: 0.07067667171359063 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1669 Avg_loss: 0.06909920200705529 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1670 Avg_loss: 0.0676219467073679 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1671 Avg_loss: 0.066232605651021 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1672 Avg_loss: 0.06492468565702439 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1673 Avg_loss: 0.06369315870106221 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1674 Avg_loss: 0.06253046318888664 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1675 Avg_loss: 0.06143326908349991 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1676 Avg_loss: 0.06039576977491379 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1677 Avg_loss: 0.05941405203193426 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1678 Avg_loss: 0.05848094318062067 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1679 Avg_loss: 0.05759972222149372 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1680 Avg_loss: 0.05676312018185854 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1681 Avg_loss: 0.055965815857052806 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1682 Avg_loss: 0.05520777478814125 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1683 Avg_loss: 0.05448613520711661 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1684 Avg_loss: 0.05379782002419233 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1685 Avg_loss: 0.05314366426318884 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1686 Avg_loss: 0.0525189358741045 training accuracy: 1.0 test accuracy: 0.1564625850340136\n",
      "Epoch: 1687 Avg_loss: 0.051926222071051596 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1688 Avg_loss: 0.0513585576787591 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1689 Avg_loss: 0.05081799998879433 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1690 Avg_loss: 0.050298361107707024 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1691 Avg_loss: 0.04979710821062326 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1692 Avg_loss: 0.04931701272726059 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1693 Avg_loss: 0.048863664641976355 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1694 Avg_loss: 0.04842892307788134 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1695 Avg_loss: 0.04801314640790224 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1696 Avg_loss: 0.0476141881197691 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1697 Avg_loss: 0.04723022487014532 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1698 Avg_loss: 0.04686276875436306 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1699 Avg_loss: 0.046505404822528365 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1700 Avg_loss: 0.046166048385202885 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1701 Avg_loss: 0.04583704210817814 training accuracy: 1.0 test accuracy: 0.16326530612244897\n",
      "Epoch: 1702 Avg_loss: 0.045520514249801636 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1703 Avg_loss: 0.04521604515612125 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1704 Avg_loss: 0.04492384325712919 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1705 Avg_loss: 0.04464125838130713 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1706 Avg_loss: 0.04437103345990181 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1707 Avg_loss: 0.0441100599244237 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 1708 Avg_loss: 0.04385869447141886 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1709 Avg_loss: 0.04361602570861578 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1710 Avg_loss: 0.043384059146046636 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1711 Avg_loss: 0.043155879713594913 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1712 Avg_loss: 0.04293665997684002 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1713 Avg_loss: 0.04272345267236233 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1714 Avg_loss: 0.04251613859087229 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1715 Avg_loss: 0.04231393989175558 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1716 Avg_loss: 0.042119231447577475 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1717 Avg_loss: 0.04192888271063566 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1718 Avg_loss: 0.041745662689208984 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1719 Avg_loss: 0.041569888964295386 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1720 Avg_loss: 0.041397578455507754 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1721 Avg_loss: 0.04123104009777308 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1722 Avg_loss: 0.041070278733968735 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1723 Avg_loss: 0.04091240409761667 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1724 Avg_loss: 0.04075910411775112 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1725 Avg_loss: 0.040611073933541776 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1726 Avg_loss: 0.04046536087989807 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1727 Avg_loss: 0.04032425805926323 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1728 Avg_loss: 0.040188560262322426 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1729 Avg_loss: 0.04005442187190056 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1730 Avg_loss: 0.039922318607568744 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1731 Avg_loss: 0.03979658577591181 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1732 Avg_loss: 0.03967255409806967 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1733 Avg_loss: 0.039550923742353916 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1734 Avg_loss: 0.039432081021368505 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1735 Avg_loss: 0.03931604847311974 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1736 Avg_loss: 0.039201035909354684 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1737 Avg_loss: 0.03909015133976936 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1738 Avg_loss: 0.038979165628552435 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1739 Avg_loss: 0.03887111153453589 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1740 Avg_loss: 0.038763855770230296 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1741 Avg_loss: 0.03865982815623283 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1742 Avg_loss: 0.03855713251978159 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1743 Avg_loss: 0.03845488596707582 training accuracy: 1.0 test accuracy: 0.21768707482993196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1744 Avg_loss: 0.03835594989359379 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1745 Avg_loss: 0.03825625944882631 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1746 Avg_loss: 0.03815676122903824 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1747 Avg_loss: 0.03806433472782374 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1748 Avg_loss: 0.037966891378164294 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1749 Avg_loss: 0.037876509688794614 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1750 Avg_loss: 0.03778420574963093 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1751 Avg_loss: 0.03769659698009491 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1752 Avg_loss: 0.0376033328473568 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1753 Avg_loss: 0.037511407397687435 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1754 Avg_loss: 0.03742094170302153 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1755 Avg_loss: 0.03732790295034647 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1756 Avg_loss: 0.03723830170929432 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1757 Avg_loss: 0.03715132549405098 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1758 Avg_loss: 0.037062475457787514 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1759 Avg_loss: 0.03697455525398254 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1760 Avg_loss: 0.03689255155622959 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1761 Avg_loss: 0.03680959176272154 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1762 Avg_loss: 0.03673281762748957 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1763 Avg_loss: 0.03665072582662106 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1764 Avg_loss: 0.03657213244587183 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1765 Avg_loss: 0.03649657592177391 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1766 Avg_loss: 0.036421545408666135 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1767 Avg_loss: 0.036342245154082777 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1768 Avg_loss: 0.03626699000597 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1769 Avg_loss: 0.03619071412831545 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1770 Avg_loss: 0.036110817641019824 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1771 Avg_loss: 0.036030210368335244 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1772 Avg_loss: 0.03595686610788107 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1773 Avg_loss: 0.03588056489825249 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1774 Avg_loss: 0.03582129199057817 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1775 Avg_loss: 0.03575349934399128 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1776 Avg_loss: 0.035680060461163524 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1777 Avg_loss: 0.035608872026205066 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1778 Avg_loss: 0.03553627375513315 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1779 Avg_loss: 0.035461912676692006 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1780 Avg_loss: 0.03539349995553494 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1781 Avg_loss: 0.035321783274412155 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1782 Avg_loss: 0.03525346592068672 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1783 Avg_loss: 0.0351839704439044 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1784 Avg_loss: 0.035113634541630745 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1785 Avg_loss: 0.0350491875782609 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1786 Avg_loss: 0.034981968626379964 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1787 Avg_loss: 0.03491416107863188 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1788 Avg_loss: 0.034848511405289176 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1789 Avg_loss: 0.034784451313316825 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1790 Avg_loss: 0.03472034186124802 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1791 Avg_loss: 0.034651406668126584 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1792 Avg_loss: 0.034585170447826385 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1793 Avg_loss: 0.03452087938785553 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1794 Avg_loss: 0.03445530571043491 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1795 Avg_loss: 0.03439073171466589 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1796 Avg_loss: 0.03432415965944528 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1797 Avg_loss: 0.03426054026931524 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1798 Avg_loss: 0.034191483072936533 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1799 Avg_loss: 0.03413171302527189 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1800 Avg_loss: 0.034060926921665666 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1801 Avg_loss: 0.03399886526167393 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1802 Avg_loss: 0.03393034618347883 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1803 Avg_loss: 0.03386790677905083 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1804 Avg_loss: 0.03380071222782135 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1805 Avg_loss: 0.033736683614552024 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1806 Avg_loss: 0.033668954856693745 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1807 Avg_loss: 0.033603273704648016 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1808 Avg_loss: 0.03354331869632006 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1809 Avg_loss: 0.0334824537858367 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1810 Avg_loss: 0.03341777697205543 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1811 Avg_loss: 0.03335837777704 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1812 Avg_loss: 0.03330157659947872 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1813 Avg_loss: 0.033242628537118436 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1814 Avg_loss: 0.033185796439647676 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1815 Avg_loss: 0.033120844326913354 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1816 Avg_loss: 0.033067318797111514 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1817 Avg_loss: 0.033009908720850946 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1818 Avg_loss: 0.032957222871482374 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1819 Avg_loss: 0.03289154265075922 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1820 Avg_loss: 0.032849699072539804 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1821 Avg_loss: 0.032783858850598334 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1822 Avg_loss: 0.03274717759341002 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1823 Avg_loss: 0.03267202563583851 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1824 Avg_loss: 0.032636835053563115 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1825 Avg_loss: 0.032568408735096456 training accuracy: 1.0 test accuracy: 0.2108843537414966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1826 Avg_loss: 0.03252746947109699 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1827 Avg_loss: 0.03246357515454292 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1828 Avg_loss: 0.032427207380533216 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1829 Avg_loss: 0.03234769683331251 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1830 Avg_loss: 0.03232666403055191 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1831 Avg_loss: 0.03227154687047005 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1832 Avg_loss: 0.03222227301448584 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1833 Avg_loss: 0.03214567303657532 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1834 Avg_loss: 0.03211615215986967 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1835 Avg_loss: 0.03203937914222479 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1836 Avg_loss: 0.032008486427366735 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1837 Avg_loss: 0.03194503597915173 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1838 Avg_loss: 0.031889629922807215 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1839 Avg_loss: 0.0318166296929121 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1840 Avg_loss: 0.03180090729147196 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1841 Avg_loss: 0.03173487205058336 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1842 Avg_loss: 0.03167696250602603 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1843 Avg_loss: 0.03163338052108884 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1844 Avg_loss: 0.03161181006580591 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1845 Avg_loss: 0.031539734359830617 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1846 Avg_loss: 0.03151046466082334 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1847 Avg_loss: 0.03144269157201052 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1848 Avg_loss: 0.031407467741519215 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1849 Avg_loss: 0.03134739873930812 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1850 Avg_loss: 0.031309266947209834 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1851 Avg_loss: 0.03125752964988351 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1852 Avg_loss: 0.031233367044478655 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1853 Avg_loss: 0.0311554204672575 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1854 Avg_loss: 0.031118015199899672 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1855 Avg_loss: 0.031066082790493964 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1856 Avg_loss: 0.0310141583904624 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1857 Avg_loss: 0.030951103661209345 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1858 Avg_loss: 0.03091889899224043 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1859 Avg_loss: 0.03085825517773628 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1860 Avg_loss: 0.03085677996277809 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1861 Avg_loss: 0.03079678751528263 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1862 Avg_loss: 0.03077849466353655 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1863 Avg_loss: 0.030716091487556697 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1864 Avg_loss: 0.030682098772376775 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1865 Avg_loss: 0.03063154285773635 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1866 Avg_loss: 0.030600475519895552 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1867 Avg_loss: 0.030560636892914772 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1868 Avg_loss: 0.030506580695509912 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1869 Avg_loss: 0.03047046158462763 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1870 Avg_loss: 0.030463350377976893 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1871 Avg_loss: 0.03045280771329999 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1872 Avg_loss: 0.030381263233721256 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1873 Avg_loss: 0.030363934580236673 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1874 Avg_loss: 0.030320481210947037 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1875 Avg_loss: 0.030265457928180695 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1876 Avg_loss: 0.0302163353189826 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1877 Avg_loss: 0.030163336358964444 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1878 Avg_loss: 0.030113373510539533 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1879 Avg_loss: 0.030065391585230826 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1880 Avg_loss: 0.030022160429507495 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1881 Avg_loss: 0.02999952333047986 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1882 Avg_loss: 0.02996090827509761 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1883 Avg_loss: 0.029942266084253787 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1884 Avg_loss: 0.029877167847007512 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1885 Avg_loss: 0.029879671521484852 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1886 Avg_loss: 0.02979639545083046 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1887 Avg_loss: 0.02978014377877116 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1888 Avg_loss: 0.02973043769598007 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1889 Avg_loss: 0.029705563094466925 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1890 Avg_loss: 0.029659978486597537 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1891 Avg_loss: 0.02967692371457815 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1892 Avg_loss: 0.029647733829915524 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1893 Avg_loss: 0.029560335632413625 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1894 Avg_loss: 0.02953976234421134 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1895 Avg_loss: 0.02946353890001774 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1896 Avg_loss: 0.029421405307948588 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1897 Avg_loss: 0.02944416105747223 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1898 Avg_loss: 0.029398349300026893 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1899 Avg_loss: 0.029410770628601313 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1900 Avg_loss: 0.02936046849936247 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1901 Avg_loss: 0.02930583618581295 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1902 Avg_loss: 0.02926925616338849 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1903 Avg_loss: 0.029222124256193638 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1904 Avg_loss: 0.02918185358867049 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1905 Avg_loss: 0.02908690646290779 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1906 Avg_loss: 0.029100885894149543 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1907 Avg_loss: 0.029052723105996846 training accuracy: 1.0 test accuracy: 0.20408163265306123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1908 Avg_loss: 0.029055984038859606 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1909 Avg_loss: 0.028983157966285943 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1910 Avg_loss: 0.029006305430084468 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1911 Avg_loss: 0.028916120063513517 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1912 Avg_loss: 0.0289141315035522 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1913 Avg_loss: 0.028893814142793416 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1914 Avg_loss: 0.02892464930191636 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1915 Avg_loss: 0.028848292399197818 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1916 Avg_loss: 0.02884596083313227 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1917 Avg_loss: 0.02886961530894041 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1918 Avg_loss: 0.028781030979007482 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1919 Avg_loss: 0.028681335411965846 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1920 Avg_loss: 0.0286529709585011 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1921 Avg_loss: 0.028633030876517297 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1922 Avg_loss: 0.028682287875562908 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1923 Avg_loss: 0.028627165127545595 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1924 Avg_loss: 0.028625835571438073 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1925 Avg_loss: 0.02868823679164052 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1926 Avg_loss: 0.02877299804240465 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1927 Avg_loss: 0.02873678058385849 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1928 Avg_loss: 0.0286631484515965 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1929 Avg_loss: 0.028552255034446715 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1930 Avg_loss: 0.028477986995130777 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1931 Avg_loss: 0.028471244778484107 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1932 Avg_loss: 0.028434050641953944 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1933 Avg_loss: 0.028351654578000308 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1934 Avg_loss: 0.028362077288329603 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1935 Avg_loss: 0.028280570171773434 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1936 Avg_loss: 0.02823269832879305 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1937 Avg_loss: 0.028232766315340996 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1938 Avg_loss: 0.028147317469120026 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1939 Avg_loss: 0.028132315445691346 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1940 Avg_loss: 0.02813705112785101 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1941 Avg_loss: 0.028222729079425336 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1942 Avg_loss: 0.02818872546777129 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1943 Avg_loss: 0.028172795940190554 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1944 Avg_loss: 0.02814998887479305 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1945 Avg_loss: 0.028086563013494013 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1946 Avg_loss: 0.028073781356215476 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1947 Avg_loss: 0.02802894953638315 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1948 Avg_loss: 0.02803851179778576 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1949 Avg_loss: 0.028043970558792354 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1950 Avg_loss: 0.02800143826752901 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1951 Avg_loss: 0.02805728865787387 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1952 Avg_loss: 0.027926356717944145 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1953 Avg_loss: 0.02787344316020608 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1954 Avg_loss: 0.02777407793328166 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1955 Avg_loss: 0.02771356049925089 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1956 Avg_loss: 0.027704204618930816 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1957 Avg_loss: 0.02772445632144809 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1958 Avg_loss: 0.027695950027555226 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1959 Avg_loss: 0.027756194584071636 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1960 Avg_loss: 0.027758779004216194 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1961 Avg_loss: 0.027900713682174682 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1962 Avg_loss: 0.027926244493573903 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1963 Avg_loss: 0.027867199666798115 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1964 Avg_loss: 0.02770189633592963 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1965 Avg_loss: 0.027659183833748102 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1966 Avg_loss: 0.027559331338852643 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1967 Avg_loss: 0.027422401029616593 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1968 Avg_loss: 0.027387285232543947 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1969 Avg_loss: 0.027430789172649385 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1970 Avg_loss: 0.027432754077017306 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1971 Avg_loss: 0.027483752835541962 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1972 Avg_loss: 0.02744450243189931 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1973 Avg_loss: 0.0275095765478909 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1974 Avg_loss: 0.027476663794368507 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1975 Avg_loss: 0.027528318762779235 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1976 Avg_loss: 0.027450194023549555 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1977 Avg_loss: 0.027467283140867948 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1978 Avg_loss: 0.027485199831426145 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1979 Avg_loss: 0.02765347305685282 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1980 Avg_loss: 0.02780772466212511 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1981 Avg_loss: 0.027650101576000452 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1982 Avg_loss: 0.027519070822745562 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1983 Avg_loss: 0.027345630060881376 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1984 Avg_loss: 0.02731216512620449 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1985 Avg_loss: 0.027173445839434863 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1986 Avg_loss: 0.027140004467219113 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1987 Avg_loss: 0.027154938504099845 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1988 Avg_loss: 0.02727362448349595 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1989 Avg_loss: 0.02722703469917178 training accuracy: 1.0 test accuracy: 0.19727891156462585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1990 Avg_loss: 0.02719611907377839 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1991 Avg_loss: 0.027220007963478565 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1992 Avg_loss: 0.02723157647997141 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1993 Avg_loss: 0.027241753228008748 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 1994 Avg_loss: 0.027222456969320775 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 1995 Avg_loss: 0.02721007913351059 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1996 Avg_loss: 0.027223102375864984 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1997 Avg_loss: 0.027059775218367575 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 1998 Avg_loss: 0.026998469419777394 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 1999 Avg_loss: 0.02695232620462775 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "best accuracy: 0.3741496598639456\n"
     ]
    }
   ],
   "source": [
    "model1, best_state1, best_acc1, loss1, acc1 = train_model(training_data, training_labels,\n",
    "                                                             test_data, test_labels, 2000, 128, 16,\n",
    "                                                             lr=0.0005, lamb=0.001, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metallic-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Avg_loss: 1.8756811320781708 training accuracy: 0.25625 test accuracy: 0.21768707482993196\n",
      "Epoch: 1 Avg_loss: 1.7372596561908722 training accuracy: 0.575 test accuracy: 0.24489795918367346\n",
      "Epoch: 2 Avg_loss: 1.612297385931015 training accuracy: 0.690625 test accuracy: 0.22448979591836735\n",
      "Epoch: 3 Avg_loss: 1.5158017098903656 training accuracy: 0.709375 test accuracy: 0.23129251700680273\n",
      "Epoch: 4 Avg_loss: 1.4256671905517577 training accuracy: 0.753125 test accuracy: 0.24489795918367346\n",
      "Epoch: 5 Avg_loss: 1.3331609308719634 training accuracy: 0.809375 test accuracy: 0.23129251700680273\n",
      "Epoch: 6 Avg_loss: 1.2446162164211274 training accuracy: 0.853125 test accuracy: 0.3129251700680272\n",
      "Epoch: 7 Avg_loss: 1.1572196424007415 training accuracy: 0.8875 test accuracy: 0.29931972789115646\n",
      "Epoch: 8 Avg_loss: 1.0777524650096892 training accuracy: 0.90625 test accuracy: 0.2653061224489796\n",
      "Epoch: 9 Avg_loss: 1.000350546836853 training accuracy: 0.915625 test accuracy: 0.25170068027210885\n",
      "Epoch: 10 Avg_loss: 0.9303462207317352 training accuracy: 0.928125 test accuracy: 0.2585034013605442\n",
      "Epoch: 11 Avg_loss: 0.8599226891994476 training accuracy: 0.934375 test accuracy: 0.2925170068027211\n",
      "Epoch: 12 Avg_loss: 0.7982447177171708 training accuracy: 0.9375 test accuracy: 0.2653061224489796\n",
      "Epoch: 13 Avg_loss: 0.7358484208583832 training accuracy: 0.95625 test accuracy: 0.2925170068027211\n",
      "Epoch: 14 Avg_loss: 0.6810426086187362 training accuracy: 0.96875 test accuracy: 0.3333333333333333\n",
      "Epoch: 15 Avg_loss: 0.6289414972066879 training accuracy: 0.971875 test accuracy: 0.2789115646258503\n",
      "Epoch: 16 Avg_loss: 0.5826746627688408 training accuracy: 0.971875 test accuracy: 0.2789115646258503\n",
      "Epoch: 17 Avg_loss: 0.5315169632434845 training accuracy: 0.98125 test accuracy: 0.19727891156462585\n",
      "Epoch: 18 Avg_loss: 0.4907700940966606 training accuracy: 0.98125 test accuracy: 0.20408163265306123\n",
      "Epoch: 19 Avg_loss: 0.45508424937725067 training accuracy: 0.98125 test accuracy: 0.2108843537414966\n",
      "Epoch: 20 Avg_loss: 0.42275465577840804 training accuracy: 0.984375 test accuracy: 0.20408163265306123\n",
      "Epoch: 21 Avg_loss: 0.3942071348428726 training accuracy: 0.984375 test accuracy: 0.24489795918367346\n",
      "Epoch: 22 Avg_loss: 0.36698891818523405 training accuracy: 0.984375 test accuracy: 0.20408163265306123\n",
      "Epoch: 23 Avg_loss: 0.3433447003364563 training accuracy: 0.990625 test accuracy: 0.2857142857142857\n",
      "Epoch: 24 Avg_loss: 0.3355804830789566 training accuracy: 0.984375 test accuracy: 0.24489795918367346\n",
      "Epoch: 25 Avg_loss: 0.3281806543469429 training accuracy: 0.98125 test accuracy: 0.1836734693877551\n",
      "Epoch: 26 Avg_loss: 0.29916475862264635 training accuracy: 0.990625 test accuracy: 0.2108843537414966\n",
      "Epoch: 27 Avg_loss: 0.27761968299746514 training accuracy: 0.990625 test accuracy: 0.17687074829931973\n",
      "Epoch: 28 Avg_loss: 0.26200453788042066 training accuracy: 0.990625 test accuracy: 0.17006802721088435\n",
      "Epoch: 29 Avg_loss: 0.2478831887245178 training accuracy: 0.990625 test accuracy: 0.19047619047619047\n",
      "Epoch: 30 Avg_loss: 0.23412678092718125 training accuracy: 0.990625 test accuracy: 0.2108843537414966\n",
      "Epoch: 31 Avg_loss: 0.22170939594507216 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 32 Avg_loss: 0.2102369524538517 training accuracy: 0.99375 test accuracy: 0.17006802721088435\n",
      "Epoch: 33 Avg_loss: 0.1998324416577816 training accuracy: 0.99375 test accuracy: 0.17687074829931973\n",
      "Epoch: 34 Avg_loss: 0.1903424568474293 training accuracy: 0.99375 test accuracy: 0.16326530612244897\n",
      "Epoch: 35 Avg_loss: 0.1814715139567852 training accuracy: 0.99375 test accuracy: 0.16326530612244897\n",
      "Epoch: 36 Avg_loss: 0.17352059483528137 training accuracy: 0.99375 test accuracy: 0.16326530612244897\n",
      "Epoch: 37 Avg_loss: 0.1661077320575714 training accuracy: 0.99375 test accuracy: 0.17006802721088435\n",
      "Epoch: 38 Avg_loss: 0.15898632481694222 training accuracy: 0.99375 test accuracy: 0.17006802721088435\n",
      "Epoch: 39 Avg_loss: 0.15307841263711452 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 40 Avg_loss: 0.14741454236209392 training accuracy: 0.996875 test accuracy: 0.1836734693877551\n",
      "Epoch: 41 Avg_loss: 0.14190089739859105 training accuracy: 0.996875 test accuracy: 0.1836734693877551\n",
      "Epoch: 42 Avg_loss: 0.1419184386730194 training accuracy: 0.996875 test accuracy: 0.17006802721088435\n",
      "Epoch: 43 Avg_loss: 0.13678424656391144 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 44 Avg_loss: 0.16465660072863103 training accuracy: 0.9875 test accuracy: 0.19727891156462585\n",
      "Epoch: 45 Avg_loss: 0.2006054028868675 training accuracy: 0.96875 test accuracy: 0.272108843537415\n",
      "Epoch: 46 Avg_loss: 0.26859631910920145 training accuracy: 0.953125 test accuracy: 0.24489795918367346\n",
      "Epoch: 47 Avg_loss: 0.30061659663915635 training accuracy: 0.946875 test accuracy: 0.2108843537414966\n",
      "Epoch: 48 Avg_loss: 0.2327184073626995 training accuracy: 0.971875 test accuracy: 0.2653061224489796\n",
      "Epoch: 49 Avg_loss: 0.21087684109807014 training accuracy: 0.98125 test accuracy: 0.23129251700680273\n",
      "Epoch: 50 Avg_loss: 0.19924957677721977 training accuracy: 0.984375 test accuracy: 0.2108843537414966\n",
      "Epoch: 51 Avg_loss: 0.18694585487246512 training accuracy: 0.9875 test accuracy: 0.20408163265306123\n",
      "Epoch: 52 Avg_loss: 0.17858705371618272 training accuracy: 0.9875 test accuracy: 0.2108843537414966\n",
      "Epoch: 53 Avg_loss: 0.1722150631248951 training accuracy: 0.990625 test accuracy: 0.2108843537414966\n",
      "Epoch: 54 Avg_loss: 0.16647615060210227 training accuracy: 0.990625 test accuracy: 0.2108843537414966\n",
      "Epoch: 55 Avg_loss: 0.16159564703702928 training accuracy: 0.990625 test accuracy: 0.20408163265306123\n",
      "Epoch: 56 Avg_loss: 0.1565326914191246 training accuracy: 0.990625 test accuracy: 0.20408163265306123\n",
      "Epoch: 57 Avg_loss: 0.15300884582102298 training accuracy: 0.990625 test accuracy: 0.19727891156462585\n",
      "Epoch: 58 Avg_loss: 0.1498758140951395 training accuracy: 0.990625 test accuracy: 0.19727891156462585\n",
      "Epoch: 59 Avg_loss: 0.14694504849612713 training accuracy: 0.99375 test accuracy: 0.19727891156462585\n",
      "Epoch: 60 Avg_loss: 0.14366264194250106 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 61 Avg_loss: 0.14108418114483356 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 62 Avg_loss: 0.1386658065021038 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 63 Avg_loss: 0.1363733820617199 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 64 Avg_loss: 0.13415825702250003 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 65 Avg_loss: 0.13213767483830452 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 66 Avg_loss: 0.13020700328052043 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 67 Avg_loss: 0.1283716607838869 training accuracy: 0.99375 test accuracy: 0.19047619047619047\n",
      "Epoch: 68 Avg_loss: 0.1266501747071743 training accuracy: 0.99375 test accuracy: 0.19727891156462585\n",
      "Epoch: 69 Avg_loss: 0.1250059973448515 training accuracy: 0.99375 test accuracy: 0.19727891156462585\n",
      "Epoch: 70 Avg_loss: 0.12345611974596978 training accuracy: 0.99375 test accuracy: 0.20408163265306123\n",
      "Epoch: 71 Avg_loss: 0.12196101024746894 training accuracy: 0.99375 test accuracy: 0.20408163265306123\n",
      "Epoch: 72 Avg_loss: 0.12048999108374119 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 73 Avg_loss: 0.11907385587692261 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 74 Avg_loss: 0.11772288084030151 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 75 Avg_loss: 0.11634260825812817 training accuracy: 0.99375 test accuracy: 0.20408163265306123\n",
      "Epoch: 76 Avg_loss: 0.1146834947168827 training accuracy: 0.99375 test accuracy: 0.20408163265306123\n",
      "Epoch: 77 Avg_loss: 0.11312853172421455 training accuracy: 0.99375 test accuracy: 0.20408163265306123\n",
      "Epoch: 78 Avg_loss: 0.1116552397608757 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 79 Avg_loss: 0.11022638417780399 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n",
      "Epoch: 80 Avg_loss: 0.10875222273170948 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 Avg_loss: 0.10737916082143784 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n",
      "Epoch: 82 Avg_loss: 0.10600860975682735 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n",
      "Epoch: 83 Avg_loss: 0.10478695444762706 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 84 Avg_loss: 0.10366972871124744 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 85 Avg_loss: 0.10256454683840274 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 86 Avg_loss: 0.10146630965173245 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 87 Avg_loss: 0.10042942985892296 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 88 Avg_loss: 0.0994350142776966 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 89 Avg_loss: 0.09848556742072105 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 90 Avg_loss: 0.0975714385509491 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 91 Avg_loss: 0.09665966294705867 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 92 Avg_loss: 0.09580805636942387 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 93 Avg_loss: 0.09497160464525223 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 94 Avg_loss: 0.09413784928619862 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 95 Avg_loss: 0.09334925450384617 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 96 Avg_loss: 0.09260713048279286 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 97 Avg_loss: 0.09188236854970455 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 98 Avg_loss: 0.09115335457026959 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 99 Avg_loss: 0.09044499918818474 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 100 Avg_loss: 0.08973816707730294 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 101 Avg_loss: 0.08905952274799347 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 102 Avg_loss: 0.08842176496982575 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 103 Avg_loss: 0.0877791740000248 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 104 Avg_loss: 0.08713265545666218 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 105 Avg_loss: 0.08649879544973374 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 106 Avg_loss: 0.08589036166667938 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 107 Avg_loss: 0.08429162725806236 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 108 Avg_loss: 0.08374464139342308 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 109 Avg_loss: 0.08323968760669231 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 110 Avg_loss: 0.08266662359237671 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 111 Avg_loss: 0.08211436308920383 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 112 Avg_loss: 0.08157667852938175 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 113 Avg_loss: 0.08105969987809658 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 114 Avg_loss: 0.08052359111607074 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 115 Avg_loss: 0.08002524599432945 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 116 Avg_loss: 0.07954288013279438 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 117 Avg_loss: 0.07904850654304027 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 118 Avg_loss: 0.07857245206832886 training accuracy: 0.996875 test accuracy: 0.19047619047619047\n",
      "Epoch: 119 Avg_loss: 0.07807511128485203 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 120 Avg_loss: 0.07762084528803825 training accuracy: 0.996875 test accuracy: 0.19047619047619047\n",
      "Epoch: 121 Avg_loss: 0.07717538513243198 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 122 Avg_loss: 0.0767519760876894 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 123 Avg_loss: 0.07627008557319641 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 124 Avg_loss: 0.07585215047001839 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 125 Avg_loss: 0.07541087418794631 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 126 Avg_loss: 0.07501512691378594 training accuracy: 0.996875 test accuracy: 0.19047619047619047\n",
      "Epoch: 127 Avg_loss: 0.07460352666676044 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 128 Avg_loss: 0.07417906858026982 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 129 Avg_loss: 0.07377257198095322 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 130 Avg_loss: 0.07335129901766776 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 131 Avg_loss: 0.07295700795948505 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 132 Avg_loss: 0.07257185317575932 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 133 Avg_loss: 0.0721254911273718 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 134 Avg_loss: 0.07141962200403214 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 135 Avg_loss: 0.07072558142244816 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 136 Avg_loss: 0.07006103955209256 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 137 Avg_loss: 0.0693870209157467 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 138 Avg_loss: 0.06867459416389465 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 139 Avg_loss: 0.06820519864559174 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 140 Avg_loss: 0.0677021637558937 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 141 Avg_loss: 0.06710878163576126 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 142 Avg_loss: 0.06657099854201079 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 143 Avg_loss: 0.06612434182316065 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 144 Avg_loss: 0.06564495600759983 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 145 Avg_loss: 0.06520302109420299 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 146 Avg_loss: 0.06479913238435983 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 147 Avg_loss: 0.06435346752405166 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 148 Avg_loss: 0.06393169909715653 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 149 Avg_loss: 0.06354882102459669 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 150 Avg_loss: 0.06318968422710895 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 151 Avg_loss: 0.06283127404749393 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 152 Avg_loss: 0.06264237202703953 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 153 Avg_loss: 0.0623298903927207 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 154 Avg_loss: 0.0618242509663105 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 155 Avg_loss: 0.06140270996838808 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 156 Avg_loss: 0.06103380173444748 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 157 Avg_loss: 0.06068465374410152 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 158 Avg_loss: 0.0604406701400876 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 159 Avg_loss: 0.060106422007083896 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 160 Avg_loss: 0.05972615573555231 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 161 Avg_loss: 0.05939436014741659 training accuracy: 1.0 test accuracy: 0.1836734693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162 Avg_loss: 0.059104386158287524 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 163 Avg_loss: 0.058815358020365235 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 164 Avg_loss: 0.05860473122447729 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 165 Avg_loss: 0.058307772129774095 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 166 Avg_loss: 0.05796826537698507 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 167 Avg_loss: 0.05764123108237982 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 168 Avg_loss: 0.05741295684129 training accuracy: 1.0 test accuracy: 0.1836734693877551\n",
      "Epoch: 169 Avg_loss: 0.05710618048906326 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 170 Avg_loss: 0.05682930033653975 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 171 Avg_loss: 0.05653491150587797 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 172 Avg_loss: 0.05612548999488354 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 173 Avg_loss: 0.055858440697193146 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 174 Avg_loss: 0.05558370556682348 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 175 Avg_loss: 0.05532055255025625 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 176 Avg_loss: 0.055049123056232926 training accuracy: 1.0 test accuracy: 0.17006802721088435\n",
      "Epoch: 177 Avg_loss: 0.054682009667158124 training accuracy: 1.0 test accuracy: 0.17687074829931973\n",
      "Epoch: 178 Avg_loss: 0.05451783016324043 training accuracy: 1.0 test accuracy: 0.19047619047619047\n",
      "Epoch: 179 Avg_loss: 0.07014289870858192 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 180 Avg_loss: 0.48025051280856135 training accuracy: 0.865625 test accuracy: 0.272108843537415\n",
      "Epoch: 181 Avg_loss: 0.5170632570981979 training accuracy: 0.865625 test accuracy: 0.22448979591836735\n",
      "Epoch: 182 Avg_loss: 0.36241370961070063 training accuracy: 0.940625 test accuracy: 0.22448979591836735\n",
      "Epoch: 183 Avg_loss: 0.2708666197955608 training accuracy: 0.978125 test accuracy: 0.22448979591836735\n",
      "Epoch: 184 Avg_loss: 0.23718151003122329 training accuracy: 0.984375 test accuracy: 0.23129251700680273\n",
      "Epoch: 185 Avg_loss: 0.21028074771165847 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 186 Avg_loss: 0.19681282415986062 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 187 Avg_loss: 0.18721478804945946 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 188 Avg_loss: 0.18009463101625442 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 189 Avg_loss: 0.17431126311421394 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 190 Avg_loss: 0.16937331929802896 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 191 Avg_loss: 0.1651077799499035 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 192 Avg_loss: 0.16130975186824797 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 193 Avg_loss: 0.15788500085473062 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 194 Avg_loss: 0.15476987808942794 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 195 Avg_loss: 0.15192951038479804 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 196 Avg_loss: 0.14929648935794831 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 197 Avg_loss: 0.1468695007264614 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 198 Avg_loss: 0.14465537592768668 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 199 Avg_loss: 0.14258964285254477 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 200 Avg_loss: 0.1406327247619629 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 201 Avg_loss: 0.13879844322800636 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 202 Avg_loss: 0.1370681032538414 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 203 Avg_loss: 0.13541446030139923 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 204 Avg_loss: 0.13384595066308974 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 205 Avg_loss: 0.13235860355198384 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 206 Avg_loss: 0.13093952015042304 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 207 Avg_loss: 0.1295856311917305 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 208 Avg_loss: 0.12827569022774696 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 209 Avg_loss: 0.12700509056448936 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 210 Avg_loss: 0.12577381022274495 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 211 Avg_loss: 0.12458754740655423 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 212 Avg_loss: 0.12246009223163128 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 213 Avg_loss: 0.1199546504765749 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 214 Avg_loss: 0.11800483800470829 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 215 Avg_loss: 0.11649326644837857 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 216 Avg_loss: 0.11520905047655106 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 217 Avg_loss: 0.11407368890941143 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 218 Avg_loss: 0.112987919151783 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 219 Avg_loss: 0.11193933747708798 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 220 Avg_loss: 0.11093233227729797 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 221 Avg_loss: 0.10995711721479892 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 222 Avg_loss: 0.10900273062288761 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 223 Avg_loss: 0.10807668566703796 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 224 Avg_loss: 0.10715390034019948 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 225 Avg_loss: 0.10626976564526558 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 226 Avg_loss: 0.10539417639374733 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 227 Avg_loss: 0.10453172586858273 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 228 Avg_loss: 0.10369386710226536 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 229 Avg_loss: 0.10286760963499546 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 230 Avg_loss: 0.10205717198550701 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 231 Avg_loss: 0.10125830881297589 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 232 Avg_loss: 0.10046938396990299 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 233 Avg_loss: 0.09969167076051236 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 234 Avg_loss: 0.09892443604767323 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 235 Avg_loss: 0.09816531948745251 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 236 Avg_loss: 0.09741934463381767 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 237 Avg_loss: 0.09668082110583782 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 238 Avg_loss: 0.09594639204442501 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 239 Avg_loss: 0.09523626193404197 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 240 Avg_loss: 0.09452875405550003 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 241 Avg_loss: 0.09381496012210847 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 242 Avg_loss: 0.09310817196965218 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 243 Avg_loss: 0.09242604337632657 training accuracy: 1.0 test accuracy: 0.2653061224489796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 244 Avg_loss: 0.09174788929522038 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 245 Avg_loss: 0.091060084477067 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 246 Avg_loss: 0.09039693623781205 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 247 Avg_loss: 0.08972865790128708 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 248 Avg_loss: 0.08908019624650479 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 249 Avg_loss: 0.08843643181025981 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 250 Avg_loss: 0.08779551684856415 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 251 Avg_loss: 0.08716648556292057 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 252 Avg_loss: 0.08653887249529361 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 253 Avg_loss: 0.08591564744710922 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 254 Avg_loss: 0.08529430963099002 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 255 Avg_loss: 0.0846804253757 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 256 Avg_loss: 0.08407326452434064 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 257 Avg_loss: 0.08347515352070331 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 258 Avg_loss: 0.08287932015955449 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 259 Avg_loss: 0.08227540142834186 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 260 Avg_loss: 0.0816692490130663 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 261 Avg_loss: 0.08108890354633332 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 262 Avg_loss: 0.08051159009337425 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 263 Avg_loss: 0.0799507662653923 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 264 Avg_loss: 0.07938986271619797 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 265 Avg_loss: 0.07882366925477982 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 266 Avg_loss: 0.07827138230204582 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 267 Avg_loss: 0.0777217660099268 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 268 Avg_loss: 0.07717840187251568 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 269 Avg_loss: 0.07663364820182324 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 270 Avg_loss: 0.07610432915389538 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 271 Avg_loss: 0.07556743882596492 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 272 Avg_loss: 0.0750461172312498 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 273 Avg_loss: 0.07451870441436767 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 274 Avg_loss: 0.07400620616972446 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 275 Avg_loss: 0.07348717711865901 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 276 Avg_loss: 0.07297925502061844 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 277 Avg_loss: 0.07247014045715332 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 278 Avg_loss: 0.07197165489196777 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 279 Avg_loss: 0.07146661765873433 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 280 Avg_loss: 0.07097143344581128 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 281 Avg_loss: 0.07047842815518379 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 282 Avg_loss: 0.0699937254190445 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 283 Avg_loss: 0.06951511949300766 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 284 Avg_loss: 0.0690410539507866 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 285 Avg_loss: 0.0685532983392477 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 286 Avg_loss: 0.0681033756583929 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 287 Avg_loss: 0.06764377392828465 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 288 Avg_loss: 0.06716771833598614 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 289 Avg_loss: 0.06669565252959728 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 290 Avg_loss: 0.06624467372894287 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 291 Avg_loss: 0.06578883714973927 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 292 Avg_loss: 0.06533779874444008 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 293 Avg_loss: 0.06489776931703091 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 294 Avg_loss: 0.06445889286696911 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 295 Avg_loss: 0.06400826517492533 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 296 Avg_loss: 0.06356760822236537 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 297 Avg_loss: 0.06312091276049614 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 298 Avg_loss: 0.06262117084115744 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 299 Avg_loss: 0.06216965317726135 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 300 Avg_loss: 0.061748521588742736 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 301 Avg_loss: 0.061325194872915746 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 302 Avg_loss: 0.060899545438587666 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 303 Avg_loss: 0.06048081237822771 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 304 Avg_loss: 0.06007743794471025 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 305 Avg_loss: 0.05965876206755638 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 306 Avg_loss: 0.059249062836170194 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 307 Avg_loss: 0.05884077362716198 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 308 Avg_loss: 0.05843723453581333 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 309 Avg_loss: 0.05803971868008375 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 310 Avg_loss: 0.057656065188348295 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 311 Avg_loss: 0.05725441463291645 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 312 Avg_loss: 0.056865069456398486 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 313 Avg_loss: 0.05648128259927034 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 314 Avg_loss: 0.05610217172652483 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 315 Avg_loss: 0.055714957788586615 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 316 Avg_loss: 0.055332735553383826 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 317 Avg_loss: 0.05495436806231737 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 318 Avg_loss: 0.05460599884390831 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 319 Avg_loss: 0.054261835478246215 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 320 Avg_loss: 0.053881076350808146 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 321 Avg_loss: 0.053504226915538314 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 322 Avg_loss: 0.05315420757979154 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 323 Avg_loss: 0.052821031957864764 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 324 Avg_loss: 0.052485625818371774 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 325 Avg_loss: 0.05212116837501526 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 326 Avg_loss: 0.05177811682224274 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 327 Avg_loss: 0.051439251750707626 training accuracy: 1.0 test accuracy: 0.2925170068027211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 328 Avg_loss: 0.051096192188560964 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 329 Avg_loss: 0.050761725194752215 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 330 Avg_loss: 0.05042886901646852 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 331 Avg_loss: 0.05011011976748705 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 332 Avg_loss: 0.04979390166699886 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 333 Avg_loss: 0.049473806843161584 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 334 Avg_loss: 0.04915944244712591 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 335 Avg_loss: 0.048861789889633654 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 336 Avg_loss: 0.0485792625695467 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 337 Avg_loss: 0.04825112074613571 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 338 Avg_loss: 0.04791886024177074 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 339 Avg_loss: 0.047599646262824535 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 340 Avg_loss: 0.04730332680046558 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 341 Avg_loss: 0.047004866600036624 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 342 Avg_loss: 0.04670768827199936 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 343 Avg_loss: 0.04639403261244297 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 344 Avg_loss: 0.04607114903628826 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 345 Avg_loss: 0.04578103553503752 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 346 Avg_loss: 0.045494621805846694 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 347 Avg_loss: 0.04520297292619944 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 348 Avg_loss: 0.04493887759745121 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 349 Avg_loss: 0.04466598369181156 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 350 Avg_loss: 0.044370707124471664 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 351 Avg_loss: 0.044111930206418036 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 352 Avg_loss: 0.043894744105637075 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 353 Avg_loss: 0.04361263196915388 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 354 Avg_loss: 0.04331437349319458 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 355 Avg_loss: 0.04304518382996321 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 356 Avg_loss: 0.042789953760802746 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 357 Avg_loss: 0.04253619909286499 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 358 Avg_loss: 0.04228511415421963 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 359 Avg_loss: 0.04203042946755886 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 360 Avg_loss: 0.041780087538063525 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 361 Avg_loss: 0.04157231729477644 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 362 Avg_loss: 0.04141527060419321 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 363 Avg_loss: 0.041136421635746954 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 364 Avg_loss: 0.040854659490287305 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 365 Avg_loss: 0.04059027265757322 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 366 Avg_loss: 0.040335208736360074 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 367 Avg_loss: 0.04013422187417746 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 368 Avg_loss: 0.0399142112582922 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 369 Avg_loss: 0.03966629803180695 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 370 Avg_loss: 0.03946280498057604 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 371 Avg_loss: 0.03926498778164387 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 372 Avg_loss: 0.039036575518548486 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 373 Avg_loss: 0.03879059236496687 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 374 Avg_loss: 0.038575530610978605 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 375 Avg_loss: 0.03837063573300838 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 376 Avg_loss: 0.03815628662705421 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 377 Avg_loss: 0.03796921744942665 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 378 Avg_loss: 0.03778008054941893 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 379 Avg_loss: 0.037571424059569834 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 380 Avg_loss: 0.03740458786487579 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 381 Avg_loss: 0.03719089739024639 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 382 Avg_loss: 0.037001958675682546 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 383 Avg_loss: 0.03683261685073376 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 384 Avg_loss: 0.03665423337370157 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 385 Avg_loss: 0.036477582156658174 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 386 Avg_loss: 0.03626998048275709 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 387 Avg_loss: 0.03605283498764038 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 388 Avg_loss: 0.035827478766441344 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 389 Avg_loss: 0.03565381076186895 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 390 Avg_loss: 0.03553542140871287 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 391 Avg_loss: 0.035357392951846124 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 392 Avg_loss: 0.03513230513781309 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 393 Avg_loss: 0.03496055398136377 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 394 Avg_loss: 0.03481966760009527 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 395 Avg_loss: 0.03468575663864613 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 396 Avg_loss: 0.03449007291346788 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 397 Avg_loss: 0.03428502678871155 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 398 Avg_loss: 0.034104864485561846 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 399 Avg_loss: 0.03397735171020031 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 400 Avg_loss: 0.033836491778492926 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 401 Avg_loss: 0.03369542732834816 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 402 Avg_loss: 0.03356023672968149 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 403 Avg_loss: 0.03340340685099363 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 404 Avg_loss: 0.033245334029197694 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 405 Avg_loss: 0.03307474907487631 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 406 Avg_loss: 0.032996431551873685 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 407 Avg_loss: 0.032966777123510836 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 408 Avg_loss: 0.032713285833597186 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 409 Avg_loss: 0.03263591062277556 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 410 Avg_loss: 0.2359026663005352 training accuracy: 0.946875 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411 Avg_loss: 0.6694903418421745 training accuracy: 0.79375 test accuracy: 0.21768707482993196\n",
      "Epoch: 412 Avg_loss: 0.5114307090640068 training accuracy: 0.878125 test accuracy: 0.23129251700680273\n",
      "Epoch: 413 Avg_loss: 0.3407717987895012 training accuracy: 0.95625 test accuracy: 0.20408163265306123\n",
      "Epoch: 414 Avg_loss: 0.26556103527545927 training accuracy: 0.96875 test accuracy: 0.20408163265306123\n",
      "Epoch: 415 Avg_loss: 0.2221465863287449 training accuracy: 0.978125 test accuracy: 0.20408163265306123\n",
      "Epoch: 416 Avg_loss: 0.2059507891535759 training accuracy: 0.978125 test accuracy: 0.21768707482993196\n",
      "Epoch: 417 Avg_loss: 0.19348386004567147 training accuracy: 0.984375 test accuracy: 0.20408163265306123\n",
      "Epoch: 418 Avg_loss: 0.18351106867194175 training accuracy: 0.9875 test accuracy: 0.19727891156462585\n",
      "Epoch: 419 Avg_loss: 0.1747596189379692 training accuracy: 0.9875 test accuracy: 0.19727891156462585\n",
      "Epoch: 420 Avg_loss: 0.16762312278151512 training accuracy: 0.9875 test accuracy: 0.20408163265306123\n",
      "Epoch: 421 Avg_loss: 0.16108571514487266 training accuracy: 0.9875 test accuracy: 0.21768707482993196\n",
      "Epoch: 422 Avg_loss: 0.15582982674241067 training accuracy: 0.990625 test accuracy: 0.22448979591836735\n",
      "Epoch: 423 Avg_loss: 0.15125995352864266 training accuracy: 0.990625 test accuracy: 0.22448979591836735\n",
      "Epoch: 424 Avg_loss: 0.14725872613489627 training accuracy: 0.990625 test accuracy: 0.23809523809523808\n",
      "Epoch: 425 Avg_loss: 0.14372169598937035 training accuracy: 0.990625 test accuracy: 0.23809523809523808\n",
      "Epoch: 426 Avg_loss: 0.14057777673006058 training accuracy: 0.990625 test accuracy: 0.25170068027210885\n",
      "Epoch: 427 Avg_loss: 0.13774643652141094 training accuracy: 0.99375 test accuracy: 0.2585034013605442\n",
      "Epoch: 428 Avg_loss: 0.1351032078266144 training accuracy: 0.99375 test accuracy: 0.25170068027210885\n",
      "Epoch: 429 Avg_loss: 0.13261584900319576 training accuracy: 0.99375 test accuracy: 0.25170068027210885\n",
      "Epoch: 430 Avg_loss: 0.13020911887288095 training accuracy: 0.99375 test accuracy: 0.23809523809523808\n",
      "Epoch: 431 Avg_loss: 0.12710174173116684 training accuracy: 0.99375 test accuracy: 0.23809523809523808\n",
      "Epoch: 432 Avg_loss: 0.12382877469062806 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 433 Avg_loss: 0.12065708562731743 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 434 Avg_loss: 0.11771199963986874 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 435 Avg_loss: 0.11514309793710709 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 436 Avg_loss: 0.11275754347443581 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 437 Avg_loss: 0.11072195246815682 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 438 Avg_loss: 0.10894727185368538 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 439 Avg_loss: 0.10734541714191437 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 440 Avg_loss: 0.1058999489992857 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 441 Avg_loss: 0.10458511188626289 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 442 Avg_loss: 0.10342897698283196 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 443 Avg_loss: 0.10221513770520688 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 444 Avg_loss: 0.1010122399777174 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 445 Avg_loss: 0.09990787357091904 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 446 Avg_loss: 0.09883048199117184 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 447 Avg_loss: 0.09781727343797683 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 448 Avg_loss: 0.09685910679399967 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 449 Avg_loss: 0.09592222310602665 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 450 Avg_loss: 0.09503678418695927 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 451 Avg_loss: 0.09409911558032036 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 452 Avg_loss: 0.09322584979236126 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 453 Avg_loss: 0.09240548089146614 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 454 Avg_loss: 0.0915807243436575 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 455 Avg_loss: 0.09076401963829994 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 456 Avg_loss: 0.08995008617639541 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 457 Avg_loss: 0.08915033340454101 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 458 Avg_loss: 0.0884074840694666 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 459 Avg_loss: 0.08754250183701515 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 460 Avg_loss: 0.08673883564770221 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 461 Avg_loss: 0.08603846542537212 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 462 Avg_loss: 0.08537906408309937 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 463 Avg_loss: 0.08481879271566868 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 464 Avg_loss: 0.08414649404585361 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 465 Avg_loss: 0.08342529535293579 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 466 Avg_loss: 0.08274790942668915 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 467 Avg_loss: 0.0820676077157259 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 468 Avg_loss: 0.08143585585057736 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 469 Avg_loss: 0.08080050013959408 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 470 Avg_loss: 0.08015811741352082 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 471 Avg_loss: 0.07952739410102368 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 472 Avg_loss: 0.07892595864832401 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 473 Avg_loss: 0.07832627035677434 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 474 Avg_loss: 0.07775915935635566 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 475 Avg_loss: 0.07716373205184937 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 476 Avg_loss: 0.07659574560821056 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 477 Avg_loss: 0.07605241909623146 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 478 Avg_loss: 0.07549697831273079 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 479 Avg_loss: 0.07492451407015324 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 480 Avg_loss: 0.07440026849508286 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 481 Avg_loss: 0.07386497780680656 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 482 Avg_loss: 0.0733364075422287 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 483 Avg_loss: 0.07280061915516853 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 484 Avg_loss: 0.07227769754827022 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 485 Avg_loss: 0.07175098657608033 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 486 Avg_loss: 0.07126336991786957 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 487 Avg_loss: 0.07076876163482666 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 488 Avg_loss: 0.07027442939579487 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 489 Avg_loss: 0.06977026015520096 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 490 Avg_loss: 0.06926919668912887 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 491 Avg_loss: 0.06877516135573387 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 492 Avg_loss: 0.06831420846283436 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 493 Avg_loss: 0.06783329509198666 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 494 Avg_loss: 0.06735511757433414 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 495 Avg_loss: 0.06688462495803833 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 496 Avg_loss: 0.06643644385039807 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 497 Avg_loss: 0.06597646288573741 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 498 Avg_loss: 0.06551396325230599 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 499 Avg_loss: 0.06504967957735061 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 500 Avg_loss: 0.06460769586265087 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 501 Avg_loss: 0.0641568049788475 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 502 Avg_loss: 0.06371819116175174 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 503 Avg_loss: 0.06328348573297263 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 504 Avg_loss: 0.06287592817097902 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 505 Avg_loss: 0.06246231608092785 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 506 Avg_loss: 0.062022164836525916 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 507 Avg_loss: 0.06160157173871994 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 508 Avg_loss: 0.061199600249528883 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 509 Avg_loss: 0.06079111266881228 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 510 Avg_loss: 0.06038485933095217 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 511 Avg_loss: 0.059971997328102586 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 512 Avg_loss: 0.05957464575767517 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 513 Avg_loss: 0.05919083338230848 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 514 Avg_loss: 0.05879436153918505 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 515 Avg_loss: 0.058397524803876874 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 516 Avg_loss: 0.05800427384674549 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 517 Avg_loss: 0.05762700717896223 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 518 Avg_loss: 0.057258670963346955 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 519 Avg_loss: 0.056890403293073176 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 520 Avg_loss: 0.056507691740989685 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 521 Avg_loss: 0.05613418947905302 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 522 Avg_loss: 0.05578273199498653 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 523 Avg_loss: 0.055419522896409036 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 524 Avg_loss: 0.05505421962589026 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 525 Avg_loss: 0.05468763243407011 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 526 Avg_loss: 0.054332714341580865 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 527 Avg_loss: 0.053989377617835996 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 528 Avg_loss: 0.0536469828337431 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 529 Avg_loss: 0.05329448282718659 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 530 Avg_loss: 0.05295464359223843 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 531 Avg_loss: 0.0526064982637763 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 532 Avg_loss: 0.05225308984518051 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 533 Avg_loss: 0.0519141523167491 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 534 Avg_loss: 0.05158692225813866 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 535 Avg_loss: 0.05125609375536442 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 536 Avg_loss: 0.05093264654278755 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 537 Avg_loss: 0.050611422024667264 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 538 Avg_loss: 0.050295685231685636 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 539 Avg_loss: 0.04997666589915752 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 540 Avg_loss: 0.04964269753545523 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 541 Avg_loss: 0.049310169741511346 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 542 Avg_loss: 0.04901318047195673 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 543 Avg_loss: 0.04871364291757345 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 544 Avg_loss: 0.04838879425078631 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 545 Avg_loss: 0.04808400571346283 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 546 Avg_loss: 0.04781179688870907 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 547 Avg_loss: 0.04751651268452406 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 548 Avg_loss: 0.04721147902309895 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 549 Avg_loss: 0.046898148581385614 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 550 Avg_loss: 0.04660011474043131 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 551 Avg_loss: 0.04630854837596417 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 552 Avg_loss: 0.04601463247090578 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 553 Avg_loss: 0.04574213642627001 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 554 Avg_loss: 0.045465003699064255 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 555 Avg_loss: 0.045170305855572225 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 556 Avg_loss: 0.044898480921983716 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 557 Avg_loss: 0.044653959758579734 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 558 Avg_loss: 0.04440778903663158 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 559 Avg_loss: 0.04411085844039917 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 560 Avg_loss: 0.04381757210940122 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 561 Avg_loss: 0.04354899432510138 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 562 Avg_loss: 0.043307339027524 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 563 Avg_loss: 0.043045019172132014 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 564 Avg_loss: 0.04277368374168873 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 565 Avg_loss: 0.04252547696232796 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 566 Avg_loss: 0.04227139912545681 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 567 Avg_loss: 0.04201848264783621 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 568 Avg_loss: 0.041757160983979705 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 569 Avg_loss: 0.04154020287096501 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 570 Avg_loss: 0.04132311176508665 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 571 Avg_loss: 0.04106040298938751 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 572 Avg_loss: 0.0408183490857482 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 573 Avg_loss: 0.04064753595739603 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 574 Avg_loss: 0.040439979173243046 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 575 Avg_loss: 0.04012679271399975 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 576 Avg_loss: 0.03985418081283569 training accuracy: 1.0 test accuracy: 0.272108843537415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 577 Avg_loss: 0.03964185491204262 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 578 Avg_loss: 0.039426664263010024 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 579 Avg_loss: 0.03922725953161717 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 580 Avg_loss: 0.03901378363370896 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 581 Avg_loss: 0.03876401986926794 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 582 Avg_loss: 0.03852503877133131 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 583 Avg_loss: 0.03827614951878786 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 584 Avg_loss: 0.038062379136681555 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 585 Avg_loss: 0.037876497767865655 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 586 Avg_loss: 0.037649604678153994 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 587 Avg_loss: 0.03744748681783676 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 588 Avg_loss: 0.03727006129920483 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 589 Avg_loss: 0.037064811773598196 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 590 Avg_loss: 0.03686929773539305 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 591 Avg_loss: 0.03667855374515057 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 592 Avg_loss: 0.036525598354637624 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 593 Avg_loss: 0.03632778190076351 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 594 Avg_loss: 0.036102467030286786 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 595 Avg_loss: 0.03591688238084316 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 596 Avg_loss: 0.035759486630558966 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 597 Avg_loss: 0.03563789539039135 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 598 Avg_loss: 0.035438494943082335 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 599 Avg_loss: 0.03526254016906023 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 600 Avg_loss: 0.035046094283461574 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 601 Avg_loss: 0.03496358282864094 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 602 Avg_loss: 0.034855576045811174 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 603 Avg_loss: 0.034631766751408576 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 604 Avg_loss: 0.03440207131206989 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 605 Avg_loss: 0.034233544021844864 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 606 Avg_loss: 0.03410365469753742 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 607 Avg_loss: 0.033911111764609814 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 608 Avg_loss: 0.033759628981351854 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 609 Avg_loss: 0.033595524914562705 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 610 Avg_loss: 0.03354962393641472 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 611 Avg_loss: 0.033384616300463674 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 612 Avg_loss: 0.03317366074770689 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 613 Avg_loss: 0.032993920333683494 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 614 Avg_loss: 0.032825323194265364 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 615 Avg_loss: 0.03265040293335915 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 616 Avg_loss: 0.03253261707723141 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 617 Avg_loss: 0.03238488081842661 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 618 Avg_loss: 0.03228495456278324 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 619 Avg_loss: 0.03211491880938411 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 620 Avg_loss: 0.031990683916956184 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 621 Avg_loss: 0.03186306282877922 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 622 Avg_loss: 0.031743505503982306 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 623 Avg_loss: 0.03157389899715781 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 624 Avg_loss: 0.03143751798197627 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 625 Avg_loss: 0.03131339754909277 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 626 Avg_loss: 0.03117173919454217 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 627 Avg_loss: 0.031090144906193017 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 628 Avg_loss: 0.030979371257126333 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 629 Avg_loss: 0.030963437259197236 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 630 Avg_loss: 0.030754774902015926 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 631 Avg_loss: 0.03059727353975177 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 632 Avg_loss: 0.030473011173307897 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 633 Avg_loss: 0.030339218955487014 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 634 Avg_loss: 0.03022389579564333 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 635 Avg_loss: 0.03008579732850194 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 636 Avg_loss: 0.030025093257427214 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 637 Avg_loss: 0.029883295111358166 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 638 Avg_loss: 0.029828140418976544 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 639 Avg_loss: 0.029728646483272315 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 640 Avg_loss: 0.029598178621381522 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 641 Avg_loss: 0.02944272356107831 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 642 Avg_loss: 0.029355316516011955 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 643 Avg_loss: 0.029262478929013014 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 644 Avg_loss: 0.029301955178380013 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 645 Avg_loss: 0.030322795268148184 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 646 Avg_loss: 0.20565737169235945 training accuracy: 0.95 test accuracy: 0.25170068027210885\n",
      "Epoch: 647 Avg_loss: 0.49263362810015676 training accuracy: 0.88125 test accuracy: 0.2653061224489796\n",
      "Epoch: 648 Avg_loss: 0.3827252507209778 training accuracy: 0.95625 test accuracy: 0.29931972789115646\n",
      "Epoch: 649 Avg_loss: 0.28448721542954447 training accuracy: 0.978125 test accuracy: 0.29931972789115646\n",
      "Epoch: 650 Avg_loss: 0.22759727463126184 training accuracy: 0.9875 test accuracy: 0.2789115646258503\n",
      "Epoch: 651 Avg_loss: 0.19482070505619048 training accuracy: 0.990625 test accuracy: 0.2653061224489796\n",
      "Epoch: 652 Avg_loss: 0.18131539821624756 training accuracy: 0.990625 test accuracy: 0.2857142857142857\n",
      "Epoch: 653 Avg_loss: 0.1702771283686161 training accuracy: 0.990625 test accuracy: 0.29931972789115646\n",
      "Epoch: 654 Avg_loss: 0.1597837194800377 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 655 Avg_loss: 0.151224597543478 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 656 Avg_loss: 0.14482176676392555 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 657 Avg_loss: 0.1394688904285431 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 658 Avg_loss: 0.13491266705095767 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 659 Avg_loss: 0.13088689595460892 training accuracy: 0.99375 test accuracy: 0.2789115646258503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 660 Avg_loss: 0.12724217846989633 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 661 Avg_loss: 0.12387393973767757 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 662 Avg_loss: 0.12084032669663429 training accuracy: 0.99375 test accuracy: 0.2789115646258503\n",
      "Epoch: 663 Avg_loss: 0.11808348670601845 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 664 Avg_loss: 0.11537674143910408 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 665 Avg_loss: 0.1125780999660492 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 666 Avg_loss: 0.10980500802397727 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 667 Avg_loss: 0.10719909816980362 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 668 Avg_loss: 0.10485181398689747 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 669 Avg_loss: 0.10261952206492424 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 670 Avg_loss: 0.10064436905086041 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 671 Avg_loss: 0.09876879900693894 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 672 Avg_loss: 0.0960890918970108 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 673 Avg_loss: 0.09330882020294666 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 674 Avg_loss: 0.09127365611493587 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 675 Avg_loss: 0.08950118087232113 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 676 Avg_loss: 0.08802087120711803 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 677 Avg_loss: 0.08672604486346244 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 678 Avg_loss: 0.08540655933320522 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 679 Avg_loss: 0.08413467407226563 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 680 Avg_loss: 0.08291939869523049 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 681 Avg_loss: 0.08180151954293251 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 682 Avg_loss: 0.0806653518229723 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 683 Avg_loss: 0.07958616390824318 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 684 Avg_loss: 0.07856320403516293 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 685 Avg_loss: 0.07754510268568993 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 686 Avg_loss: 0.07655292339622974 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 687 Avg_loss: 0.07560874819755554 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 688 Avg_loss: 0.07473195977509021 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 689 Avg_loss: 0.07384411208331584 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 690 Avg_loss: 0.07293285541236401 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 691 Avg_loss: 0.07206231243908405 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 692 Avg_loss: 0.07123203165829181 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 693 Avg_loss: 0.07043654359877109 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 694 Avg_loss: 0.0696417074650526 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 695 Avg_loss: 0.06888392977416516 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 696 Avg_loss: 0.06814180389046669 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 697 Avg_loss: 0.06739671006798745 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 698 Avg_loss: 0.06668484620749951 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 699 Avg_loss: 0.06596175581216812 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 700 Avg_loss: 0.06526487357914448 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 701 Avg_loss: 0.06460914984345437 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 702 Avg_loss: 0.06395734660327435 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 703 Avg_loss: 0.06327732373028994 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 704 Avg_loss: 0.06263211444020271 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 705 Avg_loss: 0.06202921085059643 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 706 Avg_loss: 0.06148636490106583 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 707 Avg_loss: 0.06086933612823486 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 708 Avg_loss: 0.06024805177003145 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 709 Avg_loss: 0.05965572632849216 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 710 Avg_loss: 0.05908836387097836 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 711 Avg_loss: 0.05852337647229433 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 712 Avg_loss: 0.05800896305590868 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 713 Avg_loss: 0.05748630929738283 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 714 Avg_loss: 0.05695216730237007 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 715 Avg_loss: 0.056426753848791124 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 716 Avg_loss: 0.05591876618564129 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 717 Avg_loss: 0.05541926883161068 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 718 Avg_loss: 0.05493513215333223 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 719 Avg_loss: 0.05446907542645931 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 720 Avg_loss: 0.05400110315531492 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 721 Avg_loss: 0.053540324233472346 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 722 Avg_loss: 0.053096437267959117 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 723 Avg_loss: 0.0526477986946702 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 724 Avg_loss: 0.05219332221895456 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 725 Avg_loss: 0.051753266155719756 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 726 Avg_loss: 0.05130531806498766 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 727 Avg_loss: 0.05089155826717615 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 728 Avg_loss: 0.050492226332426074 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 729 Avg_loss: 0.050101020745933054 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 730 Avg_loss: 0.049691736698150635 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 731 Avg_loss: 0.04929221849888563 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 732 Avg_loss: 0.04889860209077597 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 733 Avg_loss: 0.04854342769831419 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 734 Avg_loss: 0.04816137403249741 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 735 Avg_loss: 0.04777069874107838 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 736 Avg_loss: 0.047393716685473916 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 737 Avg_loss: 0.04703075662255287 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 738 Avg_loss: 0.04665709584951401 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 739 Avg_loss: 0.046291493251919745 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 740 Avg_loss: 0.04596955180168152 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 741 Avg_loss: 0.045616060681641105 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 742 Avg_loss: 0.04527135547250509 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 743 Avg_loss: 0.04493606090545654 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 744 Avg_loss: 0.04460532702505589 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 745 Avg_loss: 0.04433269556611776 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 746 Avg_loss: 0.044019362330436705 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 747 Avg_loss: 0.043699791096150874 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 748 Avg_loss: 0.04336877539753914 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 749 Avg_loss: 0.043054589070379734 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 750 Avg_loss: 0.04275002833455801 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 751 Avg_loss: 0.04247229676693678 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 752 Avg_loss: 0.04220065139234066 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 753 Avg_loss: 0.04191957339644432 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 754 Avg_loss: 0.04162855744361878 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 755 Avg_loss: 0.04130144771188497 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 756 Avg_loss: 0.04102776180952787 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 757 Avg_loss: 0.040822535380721094 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 758 Avg_loss: 0.04059798251837492 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 759 Avg_loss: 0.04034451115876436 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 760 Avg_loss: 0.04001635480672121 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 761 Avg_loss: 0.03971044272184372 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 762 Avg_loss: 0.03941622003912926 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 763 Avg_loss: 0.03917847741395235 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 764 Avg_loss: 0.03898179028183222 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 765 Avg_loss: 0.0387492610141635 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 766 Avg_loss: 0.03846484050154686 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 767 Avg_loss: 0.0382174389436841 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 768 Avg_loss: 0.03796712066978216 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 769 Avg_loss: 0.037758694402873515 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 770 Avg_loss: 0.03756745308637619 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 771 Avg_loss: 0.03732511214911938 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 772 Avg_loss: 0.03707403875887394 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 773 Avg_loss: 0.03684621192514896 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 774 Avg_loss: 0.03660878948867321 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 775 Avg_loss: 0.03646258693188429 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 776 Avg_loss: 0.03623418267816305 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 777 Avg_loss: 0.03597526736557484 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 778 Avg_loss: 0.03575192615389824 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 779 Avg_loss: 0.03559345211833716 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 780 Avg_loss: 0.035391142778098586 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 781 Avg_loss: 0.03517481088638306 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 782 Avg_loss: 0.03501712027937174 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 783 Avg_loss: 0.03484863005578518 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 784 Avg_loss: 0.034625828452408317 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 785 Avg_loss: 0.0344664741307497 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 786 Avg_loss: 0.034261864796280864 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 787 Avg_loss: 0.03406069558113813 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 788 Avg_loss: 0.03386093955487013 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 789 Avg_loss: 0.033683955855667594 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 790 Avg_loss: 0.03348715081810951 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 791 Avg_loss: 0.03335366826504469 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 792 Avg_loss: 0.033238006941974166 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 793 Avg_loss: 0.03304241430014372 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 794 Avg_loss: 0.032887918129563334 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 795 Avg_loss: 0.03275671247392893 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 796 Avg_loss: 0.03259653598070145 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 797 Avg_loss: 0.032396060228347776 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 798 Avg_loss: 0.03234303183853626 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 799 Avg_loss: 0.03213871587067842 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 800 Avg_loss: 0.03192840870469808 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 801 Avg_loss: 0.03180195624008775 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 802 Avg_loss: 0.03164809364825487 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 803 Avg_loss: 0.03149544456973672 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 804 Avg_loss: 0.031272731721401215 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 805 Avg_loss: 0.03109294958412647 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 806 Avg_loss: 0.0309486641548574 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 807 Avg_loss: 0.030819050408899783 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 808 Avg_loss: 0.030676754470914603 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 809 Avg_loss: 0.03056175885722041 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 810 Avg_loss: 0.03045826470479369 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 811 Avg_loss: 0.030318868812173605 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 812 Avg_loss: 0.030156283359974622 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 813 Avg_loss: 0.02999743865802884 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 814 Avg_loss: 0.029842385463416575 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 815 Avg_loss: 0.029723469540476798 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 816 Avg_loss: 0.029599595721811055 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 817 Avg_loss: 0.029528440535068513 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 818 Avg_loss: 0.029459245223551988 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 819 Avg_loss: 0.029261886794120073 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 820 Avg_loss: 0.029190566297620534 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 821 Avg_loss: 0.029085769318044186 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 822 Avg_loss: 0.02888866513967514 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 823 Avg_loss: 0.028719221893697976 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 824 Avg_loss: 0.028661558497697116 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 825 Avg_loss: 0.02874114252626896 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 826 Avg_loss: 0.028594246413558722 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 827 Avg_loss: 0.028410022612661123 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 828 Avg_loss: 0.028216918744146825 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 829 Avg_loss: 0.02804044969379902 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 830 Avg_loss: 0.027953352592885495 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 831 Avg_loss: 0.02801630226895213 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 832 Avg_loss: 0.07270045531913638 training accuracy: 0.990625 test accuracy: 0.2789115646258503\n",
      "Epoch: 833 Avg_loss: 0.1463947666808963 training accuracy: 0.96875 test accuracy: 0.2585034013605442\n",
      "Epoch: 834 Avg_loss: 0.2604487925767899 training accuracy: 0.959375 test accuracy: 0.2857142857142857\n",
      "Epoch: 835 Avg_loss: 0.22848448902368546 training accuracy: 0.978125 test accuracy: 0.29931972789115646\n",
      "Epoch: 836 Avg_loss: 0.16928310915827752 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 837 Avg_loss: 0.14727660939097403 training accuracy: 0.996875 test accuracy: 0.38095238095238093\n",
      "Epoch: 838 Avg_loss: 0.13104239627718925 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 839 Avg_loss: 0.12100669108331204 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 840 Avg_loss: 0.11396544836461545 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 841 Avg_loss: 0.10888575166463851 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 842 Avg_loss: 0.10464609786868095 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 843 Avg_loss: 0.10103104785084724 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 844 Avg_loss: 0.09793482944369317 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 845 Avg_loss: 0.09518694691359997 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 846 Avg_loss: 0.09280352294445038 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 847 Avg_loss: 0.09057887233793735 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 848 Avg_loss: 0.08851755298674106 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 849 Avg_loss: 0.08665695264935494 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 850 Avg_loss: 0.08490126729011535 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 851 Avg_loss: 0.08344423770904541 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 852 Avg_loss: 0.08215207420289516 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 853 Avg_loss: 0.08073982372879981 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 854 Avg_loss: 0.07932943291962147 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 855 Avg_loss: 0.07801329083740711 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 856 Avg_loss: 0.07681535407900811 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 857 Avg_loss: 0.0756463747471571 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 858 Avg_loss: 0.07458457164466381 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 859 Avg_loss: 0.07354987151920796 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 860 Avg_loss: 0.07254359945654869 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 861 Avg_loss: 0.0715748555958271 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 862 Avg_loss: 0.07068940475583077 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 863 Avg_loss: 0.06982223950326442 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 864 Avg_loss: 0.06897693164646626 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 865 Avg_loss: 0.06817731000483036 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 866 Avg_loss: 0.0674155205488205 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 867 Avg_loss: 0.06668156571686268 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 868 Avg_loss: 0.06595519855618477 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 869 Avg_loss: 0.06522336192429065 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 870 Avg_loss: 0.06456751935184002 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 871 Avg_loss: 0.0640153732150793 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 872 Avg_loss: 0.0634255489334464 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 873 Avg_loss: 0.06270004510879516 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 874 Avg_loss: 0.06205632258206606 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 875 Avg_loss: 0.06143908835947513 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 876 Avg_loss: 0.06083673276007175 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 877 Avg_loss: 0.06024192404001951 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 878 Avg_loss: 0.059711753763258456 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 879 Avg_loss: 0.05918371919542551 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 880 Avg_loss: 0.05864102095365524 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 881 Avg_loss: 0.0580989096313715 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 882 Avg_loss: 0.05761905387043953 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 883 Avg_loss: 0.057161465473473075 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 884 Avg_loss: 0.05666535031050444 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 885 Avg_loss: 0.056167366169393065 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 886 Avg_loss: 0.05569067262113094 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 887 Avg_loss: 0.055252081528306005 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 888 Avg_loss: 0.0548359191045165 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 889 Avg_loss: 0.054395355843007566 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 890 Avg_loss: 0.05398252718150616 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 891 Avg_loss: 0.05355402231216431 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 892 Avg_loss: 0.053102832660079 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 893 Avg_loss: 0.05268057137727737 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 894 Avg_loss: 0.0522751497104764 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 895 Avg_loss: 0.05187062453478575 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 896 Avg_loss: 0.05150055624544621 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 897 Avg_loss: 0.051132604107260705 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 898 Avg_loss: 0.05074486751109362 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 899 Avg_loss: 0.050356546975672246 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 900 Avg_loss: 0.04999972376972437 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 901 Avg_loss: 0.04964458271861076 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 902 Avg_loss: 0.049276139959692954 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 903 Avg_loss: 0.048927959986031055 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 904 Avg_loss: 0.04862823039293289 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 905 Avg_loss: 0.04829056840389967 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 906 Avg_loss: 0.04792263768613338 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 907 Avg_loss: 0.04755752943456173 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 908 Avg_loss: 0.04724468216300011 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 909 Avg_loss: 0.046935462206602094 training accuracy: 1.0 test accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 910 Avg_loss: 0.04663005154579878 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 911 Avg_loss: 0.04630006067454815 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 912 Avg_loss: 0.04601045493036508 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 913 Avg_loss: 0.045693857595324516 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 914 Avg_loss: 0.04536188710480928 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 915 Avg_loss: 0.04505652859807015 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 916 Avg_loss: 0.04476503860205412 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 917 Avg_loss: 0.044488773494958875 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 918 Avg_loss: 0.04421219564974308 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 919 Avg_loss: 0.0439071774482727 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 920 Avg_loss: 0.04368397817015648 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 921 Avg_loss: 0.043426050804555416 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 922 Avg_loss: 0.04312679208815098 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 923 Avg_loss: 0.04281243719160557 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 924 Avg_loss: 0.0425198707729578 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 925 Avg_loss: 0.04227913934737444 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 926 Avg_loss: 0.042042996361851694 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 927 Avg_loss: 0.04176498111337423 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 928 Avg_loss: 0.041483170725405215 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 929 Avg_loss: 0.04119718261063099 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 930 Avg_loss: 0.04093984868377447 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 931 Avg_loss: 0.04069797024130821 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 932 Avg_loss: 0.040436998941004276 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 933 Avg_loss: 0.040210592374205587 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 934 Avg_loss: 0.040086294338107106 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 935 Avg_loss: 0.03984740786254406 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 936 Avg_loss: 0.039573514461517335 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 937 Avg_loss: 0.03928551133722067 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 938 Avg_loss: 0.039084273390471935 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 939 Avg_loss: 0.0388672037050128 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 940 Avg_loss: 0.038610118255019185 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 941 Avg_loss: 0.03843706585466862 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 942 Avg_loss: 0.038319156505167484 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 943 Avg_loss: 0.03801879808306694 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 944 Avg_loss: 0.037734675034880635 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 945 Avg_loss: 0.03749169632792473 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 946 Avg_loss: 0.03734494503587484 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 947 Avg_loss: 0.0370936332270503 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 948 Avg_loss: 0.03680400010198355 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 949 Avg_loss: 0.036565523408353326 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 950 Avg_loss: 0.03641353994607925 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 951 Avg_loss: 0.03622076790779829 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 952 Avg_loss: 0.03597638159990311 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 953 Avg_loss: 0.03575717285275459 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 954 Avg_loss: 0.03556535467505455 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 955 Avg_loss: 0.035388778708875177 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 956 Avg_loss: 0.03519547116011381 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 957 Avg_loss: 0.03498576898127794 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 958 Avg_loss: 0.03479299861937761 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 959 Avg_loss: 0.03463373463600874 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 960 Avg_loss: 0.03444996606558561 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 961 Avg_loss: 0.03423497788608074 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 962 Avg_loss: 0.03412792664021254 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 963 Avg_loss: 0.03416850510984659 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 964 Avg_loss: 0.03391808792948723 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 965 Avg_loss: 0.03362459056079388 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 966 Avg_loss: 0.03339026756584644 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 967 Avg_loss: 0.03332714978605509 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 968 Avg_loss: 0.03321184515953064 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 969 Avg_loss: 0.03291663564741611 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 970 Avg_loss: 0.032730279676616195 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 971 Avg_loss: 0.032512369006872176 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 972 Avg_loss: 0.03230174668133259 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 973 Avg_loss: 0.03216756638139486 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 974 Avg_loss: 0.03208702784031629 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 975 Avg_loss: 0.031939137261360884 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 976 Avg_loss: 0.03169847559183836 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 977 Avg_loss: 0.0315061810426414 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 978 Avg_loss: 0.031492711324244735 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 979 Avg_loss: 0.0333976655267179 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 980 Avg_loss: 0.19996610544621946 training accuracy: 0.95 test accuracy: 0.23809523809523808\n",
      "Epoch: 981 Avg_loss: 0.47115141078829764 training accuracy: 0.89375 test accuracy: 0.21768707482993196\n",
      "Epoch: 982 Avg_loss: 0.396218466758728 training accuracy: 0.9375 test accuracy: 0.25170068027210885\n",
      "Epoch: 983 Avg_loss: 0.34129818379878996 training accuracy: 0.95625 test accuracy: 0.2585034013605442\n",
      "Epoch: 984 Avg_loss: 0.2921077623963356 training accuracy: 0.965625 test accuracy: 0.24489795918367346\n",
      "Epoch: 985 Avg_loss: 0.25111439898610116 training accuracy: 0.978125 test accuracy: 0.24489795918367346\n",
      "Epoch: 986 Avg_loss: 0.23255375474691392 training accuracy: 0.978125 test accuracy: 0.2653061224489796\n",
      "Epoch: 987 Avg_loss: 0.21607948914170266 training accuracy: 0.978125 test accuracy: 0.2653061224489796\n",
      "Epoch: 988 Avg_loss: 0.20176517367362976 training accuracy: 0.98125 test accuracy: 0.2789115646258503\n",
      "Epoch: 989 Avg_loss: 0.19088939651846887 training accuracy: 0.98125 test accuracy: 0.272108843537415\n",
      "Epoch: 990 Avg_loss: 0.18309930264949797 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 991 Avg_loss: 0.176666784286499 training accuracy: 0.98125 test accuracy: 0.272108843537415\n",
      "Epoch: 992 Avg_loss: 0.1708642192184925 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 993 Avg_loss: 0.1651193916797638 training accuracy: 0.984375 test accuracy: 0.2585034013605442\n",
      "Epoch: 994 Avg_loss: 0.1607222132384777 training accuracy: 0.9875 test accuracy: 0.24489795918367346\n",
      "Epoch: 995 Avg_loss: 0.15688116177916528 training accuracy: 0.984375 test accuracy: 0.23809523809523808\n",
      "Epoch: 996 Avg_loss: 0.1531256765127182 training accuracy: 0.9875 test accuracy: 0.23809523809523808\n",
      "Epoch: 997 Avg_loss: 0.14979799836874008 training accuracy: 0.9875 test accuracy: 0.23809523809523808\n",
      "Epoch: 998 Avg_loss: 0.14676696248352528 training accuracy: 0.9875 test accuracy: 0.23129251700680273\n",
      "Epoch: 999 Avg_loss: 0.14380003288388252 training accuracy: 0.9875 test accuracy: 0.23809523809523808\n",
      "Epoch: 1000 Avg_loss: 0.1405407026410103 training accuracy: 0.9875 test accuracy: 0.23809523809523808\n",
      "Epoch: 1001 Avg_loss: 0.13725275546312332 training accuracy: 0.9875 test accuracy: 0.23809523809523808\n",
      "Epoch: 1002 Avg_loss: 0.13444742001593113 training accuracy: 0.9875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1003 Avg_loss: 0.13131852261722088 training accuracy: 0.990625 test accuracy: 0.23129251700680273\n",
      "Epoch: 1004 Avg_loss: 0.12876767180860044 training accuracy: 0.990625 test accuracy: 0.23129251700680273\n",
      "Epoch: 1005 Avg_loss: 0.12580917552113532 training accuracy: 0.99375 test accuracy: 0.24489795918367346\n",
      "Epoch: 1006 Avg_loss: 0.12250992953777314 training accuracy: 0.99375 test accuracy: 0.23809523809523808\n",
      "Epoch: 1007 Avg_loss: 0.11941507533192634 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 1008 Avg_loss: 0.11666833199560642 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1009 Avg_loss: 0.11428702846169472 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 1010 Avg_loss: 0.11187864542007446 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1011 Avg_loss: 0.10854940861463547 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1012 Avg_loss: 0.10514270886778831 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1013 Avg_loss: 0.10253433622419834 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1014 Avg_loss: 0.10057334788143635 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1015 Avg_loss: 0.09893323034048081 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1016 Avg_loss: 0.09727631583809852 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1017 Avg_loss: 0.09564750716090202 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1018 Avg_loss: 0.09396390654146672 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1019 Avg_loss: 0.09227276593446732 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1020 Avg_loss: 0.09062509797513485 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1021 Avg_loss: 0.0889437559992075 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1022 Avg_loss: 0.08732744865119457 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1023 Avg_loss: 0.08581250309944152 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1024 Avg_loss: 0.08452955670654774 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1025 Avg_loss: 0.08329354003071784 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1026 Avg_loss: 0.08211332559585571 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1027 Avg_loss: 0.08102021366357803 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1028 Avg_loss: 0.07994157858192921 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1029 Avg_loss: 0.07895858436822892 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1030 Avg_loss: 0.07803825289011002 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1031 Avg_loss: 0.0770426269620657 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1032 Avg_loss: 0.07605754546821117 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1033 Avg_loss: 0.07520461082458496 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1034 Avg_loss: 0.07437456138432026 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1035 Avg_loss: 0.0734585240483284 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1036 Avg_loss: 0.07248202450573445 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1037 Avg_loss: 0.07137884311378002 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1038 Avg_loss: 0.07037375867366791 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1039 Avg_loss: 0.06923768855631351 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1040 Avg_loss: 0.06823703944683075 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1041 Avg_loss: 0.06703293807804585 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1042 Avg_loss: 0.06584424301981925 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1043 Avg_loss: 0.06494461186230183 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1044 Avg_loss: 0.06412332952022552 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1045 Avg_loss: 0.06338921189308167 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1046 Avg_loss: 0.06271502785384656 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1047 Avg_loss: 0.062016751244664194 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1048 Avg_loss: 0.061345319636166094 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1049 Avg_loss: 0.060672627389431 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1050 Avg_loss: 0.06000180784612894 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1051 Avg_loss: 0.05934829004108906 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1052 Avg_loss: 0.05875583104789257 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1053 Avg_loss: 0.058136787824332715 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1054 Avg_loss: 0.05752373058348894 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1055 Avg_loss: 0.056930975057184696 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1056 Avg_loss: 0.056380444392561915 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1057 Avg_loss: 0.05581973269581795 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1058 Avg_loss: 0.05524102859199047 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1059 Avg_loss: 0.05468869861215353 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1060 Avg_loss: 0.054186896048486234 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1061 Avg_loss: 0.05365714766085148 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1062 Avg_loss: 0.0531496187672019 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1063 Avg_loss: 0.052626500464975835 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1064 Avg_loss: 0.05213826708495617 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1065 Avg_loss: 0.05165589638054371 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1066 Avg_loss: 0.05119378063827753 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1067 Avg_loss: 0.05077537652105093 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1068 Avg_loss: 0.05034805368632078 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1069 Avg_loss: 0.04984365571290254 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1070 Avg_loss: 0.04936542194336653 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1071 Avg_loss: 0.048852821066975596 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1072 Avg_loss: 0.04844088666141033 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1073 Avg_loss: 0.048041402362287045 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1074 Avg_loss: 0.047591719590127465 training accuracy: 1.0 test accuracy: 0.2789115646258503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1075 Avg_loss: 0.04708593636751175 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1076 Avg_loss: 0.04662132244557142 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1077 Avg_loss: 0.046267475560307504 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1078 Avg_loss: 0.04585399590432644 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1079 Avg_loss: 0.0453968757763505 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1080 Avg_loss: 0.04499347470700741 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1081 Avg_loss: 0.04461238197982311 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1082 Avg_loss: 0.044239983148872855 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1083 Avg_loss: 0.0438535550609231 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1084 Avg_loss: 0.04348036721348762 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1085 Avg_loss: 0.043107352964580056 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1086 Avg_loss: 0.04279659613966942 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1087 Avg_loss: 0.042488057911396024 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1088 Avg_loss: 0.04214191995561123 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1089 Avg_loss: 0.04175840951502323 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1090 Avg_loss: 0.0414104413241148 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1091 Avg_loss: 0.04107322674244642 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1092 Avg_loss: 0.04073992874473333 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1093 Avg_loss: 0.040445145778357984 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1094 Avg_loss: 0.04013494476675987 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1095 Avg_loss: 0.03977880533784628 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1096 Avg_loss: 0.039436433278024194 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1097 Avg_loss: 0.039119419269263746 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1098 Avg_loss: 0.03886780776083469 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1099 Avg_loss: 0.03859802670776844 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1100 Avg_loss: 0.03826189246028662 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1101 Avg_loss: 0.03801249973475933 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1102 Avg_loss: 0.03776595760136843 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1103 Avg_loss: 0.037476458214223386 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1104 Avg_loss: 0.037152154743671416 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1105 Avg_loss: 0.03679031059145928 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1106 Avg_loss: 0.03650933261960745 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1107 Avg_loss: 0.03630442302674055 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1108 Avg_loss: 0.03605413641780615 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1109 Avg_loss: 0.035698276571929456 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1110 Avg_loss: 0.035426417179405686 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1111 Avg_loss: 0.03518617954105139 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1112 Avg_loss: 0.03493398725986481 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1113 Avg_loss: 0.034608766064047815 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1114 Avg_loss: 0.034353772178292274 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1115 Avg_loss: 0.03411626704037189 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1116 Avg_loss: 0.033838437683880326 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1117 Avg_loss: 0.03365448527038097 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1118 Avg_loss: 0.03345971964299679 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1119 Avg_loss: 0.033165699988603595 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1120 Avg_loss: 0.032904197834432124 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1121 Avg_loss: 0.032818127609789374 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1122 Avg_loss: 0.03286962006241083 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1123 Avg_loss: 0.03259922657161951 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1124 Avg_loss: 0.03223219402134418 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1125 Avg_loss: 0.03192809242755175 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1126 Avg_loss: 0.031641967967152594 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1127 Avg_loss: 0.03141887215897441 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1128 Avg_loss: 0.031235269270837307 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1129 Avg_loss: 0.031117073353379966 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1130 Avg_loss: 0.03097744267433882 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1131 Avg_loss: 0.0308289410546422 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1132 Avg_loss: 0.030731382966041564 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1133 Avg_loss: 0.030425970908254385 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1134 Avg_loss: 0.030189992021769287 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1135 Avg_loss: 0.029953415133059026 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1136 Avg_loss: 0.02976421806961298 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1137 Avg_loss: 0.029555912595242262 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1138 Avg_loss: 0.02936780694872141 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1139 Avg_loss: 0.029228357970714568 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1140 Avg_loss: 0.029107108991593123 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1141 Avg_loss: 0.02893337272107601 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1142 Avg_loss: 0.02883024113252759 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1143 Avg_loss: 0.028762456867843865 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1144 Avg_loss: 0.028660546522587538 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1145 Avg_loss: 0.028467306215316058 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1146 Avg_loss: 0.02821833025664091 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1147 Avg_loss: 0.028015718143433333 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1148 Avg_loss: 0.02780795134603977 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1149 Avg_loss: 0.027661203499883415 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1150 Avg_loss: 0.027560783550143242 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1151 Avg_loss: 0.027383192721754313 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1152 Avg_loss: 0.027252210211008786 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1153 Avg_loss: 0.027156380470842123 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1154 Avg_loss: 0.027028460055589676 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1155 Avg_loss: 0.026913131400942803 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1156 Avg_loss: 0.026716886181384326 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1157 Avg_loss: 0.026529004145413638 training accuracy: 1.0 test accuracy: 0.21768707482993196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1158 Avg_loss: 0.02635267311707139 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1159 Avg_loss: 0.02620911356061697 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1160 Avg_loss: 0.02620211523026228 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1161 Avg_loss: 0.02630166234448552 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1162 Avg_loss: 0.026140379067510367 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1163 Avg_loss: 0.025968512799590827 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1164 Avg_loss: 0.025861374754458665 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1165 Avg_loss: 0.02575072702020407 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1166 Avg_loss: 0.02583622233942151 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1167 Avg_loss: 0.02579653887078166 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1168 Avg_loss: 0.02563584130257368 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1169 Avg_loss: 0.025341980997473 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1170 Avg_loss: 0.025038476381450892 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1171 Avg_loss: 0.024844191130250694 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1172 Avg_loss: 0.02767801135778427 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1173 Avg_loss: 0.2831987550482154 training accuracy: 0.928125 test accuracy: 0.23809523809523808\n",
      "Epoch: 1174 Avg_loss: 0.4207450680434704 training accuracy: 0.91875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1175 Avg_loss: 0.3191420085728168 training accuracy: 0.9625 test accuracy: 0.2585034013605442\n",
      "Epoch: 1176 Avg_loss: 0.23014830723404883 training accuracy: 0.978125 test accuracy: 0.24489795918367346\n",
      "Epoch: 1177 Avg_loss: 0.1963932491838932 training accuracy: 0.9875 test accuracy: 0.24489795918367346\n",
      "Epoch: 1178 Avg_loss: 0.17473821491003036 training accuracy: 0.9875 test accuracy: 0.23809523809523808\n",
      "Epoch: 1179 Avg_loss: 0.15624236539006234 training accuracy: 0.990625 test accuracy: 0.23809523809523808\n",
      "Epoch: 1180 Avg_loss: 0.16642411202192306 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 1181 Avg_loss: 0.13387538008391858 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1182 Avg_loss: 0.12707785405218602 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1183 Avg_loss: 0.12162717804312706 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1184 Avg_loss: 0.11726425252854825 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1185 Avg_loss: 0.11348414979875088 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1186 Avg_loss: 0.110152717679739 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1187 Avg_loss: 0.10716102160513401 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1188 Avg_loss: 0.10447589196264744 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1189 Avg_loss: 0.10199137739837169 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1190 Avg_loss: 0.09968297444283962 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1191 Avg_loss: 0.09752061776816845 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1192 Avg_loss: 0.09554421864449977 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1193 Avg_loss: 0.093694281950593 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1194 Avg_loss: 0.09191867895424366 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1195 Avg_loss: 0.09023537300527096 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1196 Avg_loss: 0.08864031620323658 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1197 Avg_loss: 0.0871390238404274 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1198 Avg_loss: 0.08571625053882599 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1199 Avg_loss: 0.08440793752670288 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1200 Avg_loss: 0.08309006914496422 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1201 Avg_loss: 0.08179968036711216 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1202 Avg_loss: 0.08056637346744537 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1203 Avg_loss: 0.07941833436489106 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1204 Avg_loss: 0.07831195332109928 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1205 Avg_loss: 0.07727243639528751 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1206 Avg_loss: 0.07622573897242546 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1207 Avg_loss: 0.07516150549054146 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1208 Avg_loss: 0.074187171459198 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1209 Avg_loss: 0.07326504737138748 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1210 Avg_loss: 0.07232659794390202 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1211 Avg_loss: 0.07139885984361172 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1212 Avg_loss: 0.0705174945294857 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1213 Avg_loss: 0.0697035014629364 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1214 Avg_loss: 0.06888567358255386 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1215 Avg_loss: 0.06804915219545364 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1216 Avg_loss: 0.06723581627011299 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1217 Avg_loss: 0.06645699925720691 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1218 Avg_loss: 0.06576953865587712 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1219 Avg_loss: 0.06504249200224876 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1220 Avg_loss: 0.06429137028753758 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1221 Avg_loss: 0.06357544232159854 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1222 Avg_loss: 0.06294501312077046 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1223 Avg_loss: 0.06230286378413439 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1224 Avg_loss: 0.06162401922047138 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1225 Avg_loss: 0.06097016129642725 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1226 Avg_loss: 0.06037128325551748 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1227 Avg_loss: 0.0597654452547431 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1228 Avg_loss: 0.05914318952709437 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1229 Avg_loss: 0.058521962724626064 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1230 Avg_loss: 0.05793876890093088 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1231 Avg_loss: 0.05741109680384397 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1232 Avg_loss: 0.05685731954872608 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1233 Avg_loss: 0.05627765171229839 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1234 Avg_loss: 0.05573133658617735 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1235 Avg_loss: 0.05519710425287485 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1236 Avg_loss: 0.05465417206287384 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1237 Avg_loss: 0.05412967000156641 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1238 Avg_loss: 0.053660809993743896 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1239 Avg_loss: 0.053167151659727095 training accuracy: 1.0 test accuracy: 0.24489795918367346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1240 Avg_loss: 0.05267098732292652 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1241 Avg_loss: 0.05215446278452873 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1242 Avg_loss: 0.05169176533818245 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1243 Avg_loss: 0.05123048331588507 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1244 Avg_loss: 0.050753000937402246 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1245 Avg_loss: 0.05030406806617975 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1246 Avg_loss: 0.04988818224519491 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1247 Avg_loss: 0.04945435132831335 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1248 Avg_loss: 0.049002187512815 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1249 Avg_loss: 0.0485855046659708 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1250 Avg_loss: 0.04820091109722853 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1251 Avg_loss: 0.047786079719662665 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1252 Avg_loss: 0.04748386647552252 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1253 Avg_loss: 0.047077659890055655 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1254 Avg_loss: 0.04659444838762283 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1255 Avg_loss: 0.04617337230592966 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1256 Avg_loss: 0.045739478804171084 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1257 Avg_loss: 0.045289505273103714 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1258 Avg_loss: 0.04491311423480511 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1259 Avg_loss: 0.04458634033799171 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1260 Avg_loss: 0.04419651329517364 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1261 Avg_loss: 0.04383980873972178 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1262 Avg_loss: 0.043535450100898744 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1263 Avg_loss: 0.04317126870155334 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1264 Avg_loss: 0.042808705009520054 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1265 Avg_loss: 0.04242610242217779 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1266 Avg_loss: 0.04211964253336191 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1267 Avg_loss: 0.04182399827986956 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1268 Avg_loss: 0.04148917831480503 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1269 Avg_loss: 0.0411444129422307 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1270 Avg_loss: 0.04081659372895956 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1271 Avg_loss: 0.04047510679811239 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1272 Avg_loss: 0.04014922231435776 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1273 Avg_loss: 0.03987696785479784 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1274 Avg_loss: 0.039620823226869106 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1275 Avg_loss: 0.03927095681428909 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1276 Avg_loss: 0.03891635145992041 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1277 Avg_loss: 0.0386080227792263 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1278 Avg_loss: 0.03837005887180567 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1279 Avg_loss: 0.038114081509411334 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1280 Avg_loss: 0.03784497994929552 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1281 Avg_loss: 0.0375308820977807 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1282 Avg_loss: 0.03721784651279449 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1283 Avg_loss: 0.03696419484913349 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1284 Avg_loss: 0.03669995944947004 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1285 Avg_loss: 0.03641581237316131 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1286 Avg_loss: 0.03615809939801693 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1287 Avg_loss: 0.035908933728933334 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1288 Avg_loss: 0.03566079027950764 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1289 Avg_loss: 0.03543435502797365 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1290 Avg_loss: 0.035168086364865306 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1291 Avg_loss: 0.03494202885776758 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1292 Avg_loss: 0.034782718680799005 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1293 Avg_loss: 0.03449334688484669 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1294 Avg_loss: 0.034196476079523565 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1295 Avg_loss: 0.033922001533210275 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1296 Avg_loss: 0.033699823170900346 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1297 Avg_loss: 0.033554564230144024 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1298 Avg_loss: 0.03332270011305809 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1299 Avg_loss: 0.03309151157736778 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1300 Avg_loss: 0.03300964832305908 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1301 Avg_loss: 0.03281160369515419 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1302 Avg_loss: 0.0325184665620327 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1303 Avg_loss: 0.03226223085075617 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1304 Avg_loss: 0.03212580624967813 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1305 Avg_loss: 0.031879111379385 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1306 Avg_loss: 0.031670776475220916 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1307 Avg_loss: 0.03142241826280952 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1308 Avg_loss: 0.031161329429596662 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1309 Avg_loss: 0.030988985020667315 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1310 Avg_loss: 0.030828439351171254 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1311 Avg_loss: 0.03065347149968147 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1312 Avg_loss: 0.030494227074086666 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1313 Avg_loss: 0.030303220450878143 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1314 Avg_loss: 0.030167365074157716 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1315 Avg_loss: 0.030005807243287563 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1316 Avg_loss: 0.02974725803360343 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1317 Avg_loss: 0.029541257303208113 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1318 Avg_loss: 0.029390222299844025 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1319 Avg_loss: 0.02917312113568187 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1320 Avg_loss: 0.028987656254321335 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1321 Avg_loss: 0.02883077124133706 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1322 Avg_loss: 0.028714478947222233 training accuracy: 1.0 test accuracy: 0.2789115646258503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1323 Avg_loss: 0.028668306488543748 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1324 Avg_loss: 0.02848448362201452 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1325 Avg_loss: 0.028287997469305992 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1326 Avg_loss: 0.028120178915560245 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1327 Avg_loss: 0.02791950749233365 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1328 Avg_loss: 0.027728764433413745 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1329 Avg_loss: 0.027667811047285794 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1330 Avg_loss: 0.027542592957615852 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1331 Avg_loss: 0.027382179256528617 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1332 Avg_loss: 0.027153671346604825 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1333 Avg_loss: 0.02701187552884221 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1334 Avg_loss: 0.026920944824814795 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1335 Avg_loss: 0.02671139258891344 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1336 Avg_loss: 0.026583599112927913 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1337 Avg_loss: 0.026479611080139874 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1338 Avg_loss: 0.026391717605292797 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1339 Avg_loss: 0.026236563827842473 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1340 Avg_loss: 0.02601493615657091 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1341 Avg_loss: 0.025948782823979853 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1342 Avg_loss: 0.025982788670808075 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1343 Avg_loss: 0.02587603498250246 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1344 Avg_loss: 0.02563966978341341 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1345 Avg_loss: 0.025416839774698018 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1346 Avg_loss: 0.025295037124305964 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1347 Avg_loss: 0.025259927567094564 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1348 Avg_loss: 0.025124908704310656 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1349 Avg_loss: 0.024985289387404918 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1350 Avg_loss: 0.024893285520374776 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1351 Avg_loss: 0.024716830905526878 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1352 Avg_loss: 0.024613801203668118 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1353 Avg_loss: 0.02459452347829938 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1354 Avg_loss: 0.02434184867888689 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1355 Avg_loss: 0.02419264204800129 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1356 Avg_loss: 0.024105600081384182 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1357 Avg_loss: 0.02407163120806217 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1358 Avg_loss: 0.023930883686989545 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1359 Avg_loss: 0.023753728345036508 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1360 Avg_loss: 0.023630796279758216 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1361 Avg_loss: 0.023563784826546908 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1362 Avg_loss: 0.023532735370099544 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1363 Avg_loss: 0.023476974945515393 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1364 Avg_loss: 0.023423812352120876 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1365 Avg_loss: 0.02334430059418082 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1366 Avg_loss: 0.02324893241748214 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1367 Avg_loss: 0.026258057449012995 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1368 Avg_loss: 0.17261990401893854 training accuracy: 0.959375 test accuracy: 0.272108843537415\n",
      "Epoch: 1369 Avg_loss: 0.4131086215376854 training accuracy: 0.9125 test accuracy: 0.2789115646258503\n",
      "Epoch: 1370 Avg_loss: 0.3567082703113556 training accuracy: 0.95625 test accuracy: 0.19727891156462585\n",
      "Epoch: 1371 Avg_loss: 0.2807000294327736 training accuracy: 0.98125 test accuracy: 0.22448979591836735\n",
      "Epoch: 1372 Avg_loss: 0.22863350361585616 training accuracy: 0.9875 test accuracy: 0.24489795918367346\n",
      "Epoch: 1373 Avg_loss: 0.1995488442480564 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 1374 Avg_loss: 0.18380453288555146 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 1375 Avg_loss: 0.17227385491132735 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 1376 Avg_loss: 0.16390833258628845 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 1377 Avg_loss: 0.15154031664133072 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1378 Avg_loss: 0.14561150819063187 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1379 Avg_loss: 0.14036981761455536 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1380 Avg_loss: 0.13576480597257615 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1381 Avg_loss: 0.1316550202667713 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1382 Avg_loss: 0.1279529083520174 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1383 Avg_loss: 0.12458029389381409 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1384 Avg_loss: 0.12150400653481483 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1385 Avg_loss: 0.11872363165020942 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1386 Avg_loss: 0.11608379408717155 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1387 Avg_loss: 0.11357980035245419 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1388 Avg_loss: 0.11123360358178616 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1389 Avg_loss: 0.10903364829719067 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1390 Avg_loss: 0.10698622651398182 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1391 Avg_loss: 0.10505205653607845 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1392 Avg_loss: 0.10320825576782226 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1393 Avg_loss: 0.10145233832299709 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1394 Avg_loss: 0.09976818896830082 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1395 Avg_loss: 0.09818973205983639 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1396 Avg_loss: 0.09665625244379043 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1397 Avg_loss: 0.09519571289420128 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1398 Avg_loss: 0.09376285374164581 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1399 Avg_loss: 0.09236828498542309 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1400 Avg_loss: 0.09106612727046012 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1401 Avg_loss: 0.08980445340275764 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1402 Avg_loss: 0.08857433646917343 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1403 Avg_loss: 0.08739246018230915 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1404 Avg_loss: 0.0862532552331686 training accuracy: 1.0 test accuracy: 0.21768707482993196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1405 Avg_loss: 0.08516052067279815 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1406 Avg_loss: 0.08408971056342125 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1407 Avg_loss: 0.08301557339727879 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1408 Avg_loss: 0.08198999613523483 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1409 Avg_loss: 0.08098618909716607 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1410 Avg_loss: 0.0800225704908371 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1411 Avg_loss: 0.07908236421644688 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1412 Avg_loss: 0.07817833609879017 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1413 Avg_loss: 0.07726911753416062 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1414 Avg_loss: 0.07638293690979481 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1415 Avg_loss: 0.0755812294781208 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1416 Avg_loss: 0.07474973089993 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1417 Avg_loss: 0.07388289272785187 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1418 Avg_loss: 0.07307244800031185 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1419 Avg_loss: 0.07230236642062664 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1420 Avg_loss: 0.07153410613536834 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1421 Avg_loss: 0.07079092562198638 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1422 Avg_loss: 0.07003663815557956 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1423 Avg_loss: 0.0692840363830328 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1424 Avg_loss: 0.0685919601470232 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1425 Avg_loss: 0.06791351623833179 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1426 Avg_loss: 0.06726084537804126 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1427 Avg_loss: 0.06660251133143902 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1428 Avg_loss: 0.06590612567961215 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1429 Avg_loss: 0.06523274295032025 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1430 Avg_loss: 0.06461212448775769 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1431 Avg_loss: 0.06397226825356483 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1432 Avg_loss: 0.06332761626690626 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1433 Avg_loss: 0.06271291878074407 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1434 Avg_loss: 0.0621311005204916 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1435 Avg_loss: 0.061509201675653456 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1436 Avg_loss: 0.060934128053486344 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1437 Avg_loss: 0.060378335416316986 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1438 Avg_loss: 0.05979960225522518 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1439 Avg_loss: 0.05924271568655968 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1440 Avg_loss: 0.058716336451470855 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1441 Avg_loss: 0.0581835875287652 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1442 Avg_loss: 0.057634007185697556 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1443 Avg_loss: 0.05708454325795174 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1444 Avg_loss: 0.05654879231005907 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1445 Avg_loss: 0.0560475317761302 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1446 Avg_loss: 0.0555533142760396 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1447 Avg_loss: 0.05504322070628405 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1448 Avg_loss: 0.05456628948450089 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1449 Avg_loss: 0.05407822579145431 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1450 Avg_loss: 0.05362549759447575 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1451 Avg_loss: 0.05318023283034563 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1452 Avg_loss: 0.05267930645495653 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1453 Avg_loss: 0.05221382081508637 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1454 Avg_loss: 0.05178576409816742 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1455 Avg_loss: 0.051336704008281234 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1456 Avg_loss: 0.050864886678755286 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1457 Avg_loss: 0.05041166674345732 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1458 Avg_loss: 0.049995265528559686 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1459 Avg_loss: 0.049594915471971035 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1460 Avg_loss: 0.04916528817266226 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1461 Avg_loss: 0.04878042694181204 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1462 Avg_loss: 0.048399601504206656 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1463 Avg_loss: 0.048002070561051366 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1464 Avg_loss: 0.047533421963453296 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1465 Avg_loss: 0.047105878591537476 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1466 Avg_loss: 0.046714618988335135 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1467 Avg_loss: 0.046374662406742574 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1468 Avg_loss: 0.04597441144287586 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1469 Avg_loss: 0.0455884674564004 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1470 Avg_loss: 0.04519411288201809 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1471 Avg_loss: 0.04483076557517052 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1472 Avg_loss: 0.044490618631243706 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1473 Avg_loss: 0.044158761575818065 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1474 Avg_loss: 0.04376797173172235 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1475 Avg_loss: 0.043393203802406785 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1476 Avg_loss: 0.04305640310049057 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1477 Avg_loss: 0.04277602396905422 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1478 Avg_loss: 0.0424693938344717 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1479 Avg_loss: 0.042076779156923295 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1480 Avg_loss: 0.041708012111485004 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1481 Avg_loss: 0.04134600106626749 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1482 Avg_loss: 0.04103931244462729 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1483 Avg_loss: 0.04073646459728479 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1484 Avg_loss: 0.040461445972323415 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1485 Avg_loss: 0.04011985305696726 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1486 Avg_loss: 0.03975528944283724 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1487 Avg_loss: 0.039448465965688226 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1488 Avg_loss: 0.03915275651961565 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1489 Avg_loss: 0.03889137394726276 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1490 Avg_loss: 0.03860410545021296 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1491 Avg_loss: 0.0382773794233799 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1492 Avg_loss: 0.03797666989266872 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1493 Avg_loss: 0.03770143762230873 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1494 Avg_loss: 0.03747165612876415 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1495 Avg_loss: 0.03722587432712317 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1496 Avg_loss: 0.0369157500565052 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1497 Avg_loss: 0.03658586628735065 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1498 Avg_loss: 0.036289791017770766 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1499 Avg_loss: 0.03600903172045946 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1500 Avg_loss: 0.03573535457253456 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1501 Avg_loss: 0.03547878935933113 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1502 Avg_loss: 0.03529133126139641 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1503 Avg_loss: 0.03515997231006622 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1504 Avg_loss: 0.03483884911984205 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1505 Avg_loss: 0.03452602531760931 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1506 Avg_loss: 0.03422924820333719 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1507 Avg_loss: 0.03393602967262268 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1508 Avg_loss: 0.033690277673304084 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1509 Avg_loss: 0.03346004746854305 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1510 Avg_loss: 0.03323842473328113 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1511 Avg_loss: 0.03302994929254055 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1512 Avg_loss: 0.03281751461327076 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1513 Avg_loss: 0.03251822758466005 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1514 Avg_loss: 0.03226780202239752 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1515 Avg_loss: 0.03205774370580912 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1516 Avg_loss: 0.03192377220839262 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1517 Avg_loss: 0.03165871789678931 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1518 Avg_loss: 0.031391345988959075 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1519 Avg_loss: 0.0311983548104763 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1520 Avg_loss: 0.03098732531070709 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1521 Avg_loss: 0.030826336331665517 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1522 Avg_loss: 0.030600431095808744 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1523 Avg_loss: 0.030383902229368688 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1524 Avg_loss: 0.0303315544500947 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1525 Avg_loss: 0.03014213154092431 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1526 Avg_loss: 0.029918731562793253 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1527 Avg_loss: 0.029778771009296177 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1528 Avg_loss: 0.029510991740971805 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1529 Avg_loss: 0.029229672532528637 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1530 Avg_loss: 0.029173651058226825 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1531 Avg_loss: 0.028966501262038945 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1532 Avg_loss: 0.028739456832408906 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1533 Avg_loss: 0.028459230810403822 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1534 Avg_loss: 0.028216668777167796 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1535 Avg_loss: 0.028131734114140272 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1536 Avg_loss: 0.028061087243258953 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1537 Avg_loss: 0.027810838259756564 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1538 Avg_loss: 0.027568319346755743 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1539 Avg_loss: 0.027362421061843632 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1540 Avg_loss: 0.027185804955661298 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1541 Avg_loss: 0.027069785445928574 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1542 Avg_loss: 0.027039122115820647 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1543 Avg_loss: 0.026816503144800663 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1544 Avg_loss: 0.04099444048479199 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1545 Avg_loss: 0.22913444545120001 training accuracy: 0.953125 test accuracy: 0.19727891156462585\n",
      "Epoch: 1546 Avg_loss: 0.21413376778364182 training accuracy: 0.9625 test accuracy: 0.23809523809523808\n",
      "Epoch: 1547 Avg_loss: 0.21848575323820113 training accuracy: 0.975 test accuracy: 0.25170068027210885\n",
      "Epoch: 1548 Avg_loss: 0.15653792768716812 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1549 Avg_loss: 0.13429819345474242 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1550 Avg_loss: 0.12120107412338257 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1551 Avg_loss: 0.11315889731049537 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1552 Avg_loss: 0.10713631138205529 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1553 Avg_loss: 0.10264199562370777 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1554 Avg_loss: 0.09890609569847583 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1555 Avg_loss: 0.09565261863172055 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1556 Avg_loss: 0.09275285862386226 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1557 Avg_loss: 0.09022329412400723 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1558 Avg_loss: 0.08796871788799762 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1559 Avg_loss: 0.08602572605013847 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1560 Avg_loss: 0.08415640033781528 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1561 Avg_loss: 0.0823692612349987 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1562 Avg_loss: 0.08067919351160527 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1563 Avg_loss: 0.07905554324388504 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1564 Avg_loss: 0.07757564187049866 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1565 Avg_loss: 0.07615398205816745 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1566 Avg_loss: 0.07466189377009869 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1567 Avg_loss: 0.07144327312707902 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1568 Avg_loss: 0.0697569664567709 training accuracy: 1.0 test accuracy: 0.22448979591836735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1569 Avg_loss: 0.06845946349203587 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1570 Avg_loss: 0.06734945029020309 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1571 Avg_loss: 0.0662487331777811 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1572 Avg_loss: 0.06525264345109463 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1573 Avg_loss: 0.06430279724299907 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1574 Avg_loss: 0.06343409679830074 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1575 Avg_loss: 0.0625915702432394 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1576 Avg_loss: 0.06177222412079573 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1577 Avg_loss: 0.06097488794475794 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1578 Avg_loss: 0.06023351643234491 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1579 Avg_loss: 0.05951423235237598 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1580 Avg_loss: 0.058843945525586604 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1581 Avg_loss: 0.05820404887199402 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1582 Avg_loss: 0.05751033499836922 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1583 Avg_loss: 0.05685172323137522 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1584 Avg_loss: 0.05618940256536007 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1585 Avg_loss: 0.05556336734443903 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1586 Avg_loss: 0.054962470196187496 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1587 Avg_loss: 0.05438729468733072 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1588 Avg_loss: 0.05380649417638779 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1589 Avg_loss: 0.05325460471212864 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1590 Avg_loss: 0.05274545792490244 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1591 Avg_loss: 0.05222126170992851 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1592 Avg_loss: 0.05169522743672132 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1593 Avg_loss: 0.0511749379336834 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1594 Avg_loss: 0.05068456418812275 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1595 Avg_loss: 0.05019753128290176 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1596 Avg_loss: 0.04969106875360012 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1597 Avg_loss: 0.04921259563416243 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1598 Avg_loss: 0.04878554418683052 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1599 Avg_loss: 0.04836567565798759 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1600 Avg_loss: 0.04787234589457512 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1601 Avg_loss: 0.04741198252886534 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1602 Avg_loss: 0.04698511566966772 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1603 Avg_loss: 0.046580101177096364 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1604 Avg_loss: 0.046150834299623966 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1605 Avg_loss: 0.04573142118752003 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1606 Avg_loss: 0.045306190848350525 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1607 Avg_loss: 0.04487360659986735 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1608 Avg_loss: 0.04449634440243244 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1609 Avg_loss: 0.04411736428737641 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1610 Avg_loss: 0.043763441406190394 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1611 Avg_loss: 0.04339956901967525 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1612 Avg_loss: 0.04302358273416758 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1613 Avg_loss: 0.04264199696481228 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1614 Avg_loss: 0.04228194523602724 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1615 Avg_loss: 0.041943390481173994 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1616 Avg_loss: 0.041588515788316724 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1617 Avg_loss: 0.041210221499204634 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1618 Avg_loss: 0.04088212344795465 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1619 Avg_loss: 0.04056296534836292 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1620 Avg_loss: 0.04019114505499601 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1621 Avg_loss: 0.03986444715410471 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1622 Avg_loss: 0.039555481635034084 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1623 Avg_loss: 0.039230077713727954 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1624 Avg_loss: 0.03894782550632954 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1625 Avg_loss: 0.03876363597810269 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1626 Avg_loss: 0.03845884557813406 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1627 Avg_loss: 0.03819719646126032 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1628 Avg_loss: 0.03785591684281826 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1629 Avg_loss: 0.03745659496635199 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1630 Avg_loss: 0.03711861595511436 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1631 Avg_loss: 0.036825920827686785 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1632 Avg_loss: 0.036575816385447976 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1633 Avg_loss: 0.03631034269928932 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1634 Avg_loss: 0.03601098656654358 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1635 Avg_loss: 0.03572279401123524 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1636 Avg_loss: 0.03550605867058039 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1637 Avg_loss: 0.03531298581510782 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1638 Avg_loss: 0.03505912683904171 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1639 Avg_loss: 0.034745500050485136 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1640 Avg_loss: 0.03448457419872284 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1641 Avg_loss: 0.03422856461256742 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1642 Avg_loss: 0.03396766595542431 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1643 Avg_loss: 0.03371226396411657 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1644 Avg_loss: 0.033450332656502726 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1645 Avg_loss: 0.033224552124738696 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1646 Avg_loss: 0.03300665691494942 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1647 Avg_loss: 0.032767200097441676 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1648 Avg_loss: 0.03262777477502823 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1649 Avg_loss: 0.03252120092511177 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1650 Avg_loss: 0.032229228876531124 training accuracy: 1.0 test accuracy: 0.23809523809523808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1651 Avg_loss: 0.031939410511404275 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1652 Avg_loss: 0.03167398180812597 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1653 Avg_loss: 0.031479418836534025 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1654 Avg_loss: 0.03134275432676077 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1655 Avg_loss: 0.031116601079702377 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1656 Avg_loss: 0.0308811504393816 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1657 Avg_loss: 0.030685665551573038 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1658 Avg_loss: 0.030503298062831162 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1659 Avg_loss: 0.030317553877830507 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1660 Avg_loss: 0.030123440362513066 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1661 Avg_loss: 0.02989980736747384 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1662 Avg_loss: 0.029803586751222612 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1663 Avg_loss: 0.02965400880202651 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1664 Avg_loss: 0.02939528049901128 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1665 Avg_loss: 0.029192210733890535 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1666 Avg_loss: 0.029120118357241154 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1667 Avg_loss: 0.02893809527158737 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1668 Avg_loss: 0.02878150064498186 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1669 Avg_loss: 0.028573141433298588 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1670 Avg_loss: 0.028340268321335314 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1671 Avg_loss: 0.02809447906911373 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1672 Avg_loss: 0.027952057681977747 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1673 Avg_loss: 0.027817255165427924 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1674 Avg_loss: 0.027693568728864193 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1675 Avg_loss: 0.027558783162385227 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1676 Avg_loss: 0.02737615667283535 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1677 Avg_loss: 0.027222442720085383 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1678 Avg_loss: 0.02701454423367977 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1679 Avg_loss: 0.02682520905509591 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1680 Avg_loss: 0.026682474371045827 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1681 Avg_loss: 0.026572954654693604 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1682 Avg_loss: 0.026389822456985713 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1683 Avg_loss: 0.026300921384245158 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1684 Avg_loss: 0.026188231725245713 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1685 Avg_loss: 0.026020421739667655 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1686 Avg_loss: 0.02579845190048218 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1687 Avg_loss: 0.025646012090146542 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1688 Avg_loss: 0.02552842106670141 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1689 Avg_loss: 0.025411320570856332 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1690 Avg_loss: 0.02530112424865365 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1691 Avg_loss: 0.025237480364739894 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1692 Avg_loss: 0.02504793107509613 training accuracy: 1.0 test accuracy: 0.20408163265306123\n",
      "Epoch: 1693 Avg_loss: 0.024925314448773862 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1694 Avg_loss: 0.02476091580465436 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1695 Avg_loss: 0.024601151514798403 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 1696 Avg_loss: 0.024471012502908708 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 1697 Avg_loss: 0.024491979740560055 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1698 Avg_loss: 0.04611260313540697 training accuracy: 0.99375 test accuracy: 0.21768707482993196\n",
      "Epoch: 1699 Avg_loss: 0.23656107243150473 training accuracy: 0.95 test accuracy: 0.22448979591836735\n",
      "Epoch: 1700 Avg_loss: 0.26689426973462105 training accuracy: 0.965625 test accuracy: 0.2653061224489796\n",
      "Epoch: 1701 Avg_loss: 0.28623690977692606 training accuracy: 0.965625 test accuracy: 0.2108843537414966\n",
      "Epoch: 1702 Avg_loss: 0.2083258517086506 training accuracy: 0.984375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1703 Avg_loss: 0.17279894575476645 training accuracy: 0.990625 test accuracy: 0.21768707482993196\n",
      "Epoch: 1704 Avg_loss: 0.15305280759930612 training accuracy: 0.99375 test accuracy: 0.19727891156462585\n",
      "Epoch: 1705 Avg_loss: 0.14090245142579078 training accuracy: 0.99375 test accuracy: 0.2108843537414966\n",
      "Epoch: 1706 Avg_loss: 0.13207778111100196 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1707 Avg_loss: 0.12497793212532997 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1708 Avg_loss: 0.11879219189286232 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1709 Avg_loss: 0.11384174898266793 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1710 Avg_loss: 0.10972127094864845 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1711 Avg_loss: 0.1061204805970192 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1712 Avg_loss: 0.10288625322282315 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1713 Avg_loss: 0.09997277893126011 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1714 Avg_loss: 0.09731302224099636 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1715 Avg_loss: 0.0948966708034277 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 1716 Avg_loss: 0.09266019724309445 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 1717 Avg_loss: 0.09059034176170826 training accuracy: 0.996875 test accuracy: 0.19727891156462585\n",
      "Epoch: 1718 Avg_loss: 0.0886438399553299 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1719 Avg_loss: 0.08680940456688405 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1720 Avg_loss: 0.08510041572153568 training accuracy: 0.996875 test accuracy: 0.20408163265306123\n",
      "Epoch: 1721 Avg_loss: 0.08348680846393108 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1722 Avg_loss: 0.08194566071033478 training accuracy: 0.996875 test accuracy: 0.2108843537414966\n",
      "Epoch: 1723 Avg_loss: 0.08047752156853676 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1724 Avg_loss: 0.07909881733357907 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1725 Avg_loss: 0.0778001058846712 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1726 Avg_loss: 0.07653536796569824 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1727 Avg_loss: 0.07531359642744065 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1728 Avg_loss: 0.07414749525487423 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1729 Avg_loss: 0.0730448130518198 training accuracy: 0.996875 test accuracy: 0.21768707482993196\n",
      "Epoch: 1730 Avg_loss: 0.07200314514338971 training accuracy: 0.996875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1731 Avg_loss: 0.07099278159439563 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1732 Avg_loss: 0.06997505202889442 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 1733 Avg_loss: 0.06902136243879795 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1734 Avg_loss: 0.06810387782752514 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1735 Avg_loss: 0.06722925696521997 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1736 Avg_loss: 0.0663486609235406 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1737 Avg_loss: 0.06548385210335254 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1738 Avg_loss: 0.06465674806386232 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1739 Avg_loss: 0.06387150343507528 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1740 Avg_loss: 0.06309702899307013 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1741 Avg_loss: 0.062358960136771203 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1742 Avg_loss: 0.06162467747926712 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1743 Avg_loss: 0.060927783884108064 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1744 Avg_loss: 0.06026145536452532 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1745 Avg_loss: 0.059588283859193326 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1746 Avg_loss: 0.05893384926021099 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1747 Avg_loss: 0.058308961987495425 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1748 Avg_loss: 0.05771061163395643 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1749 Avg_loss: 0.05713444333523512 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1750 Avg_loss: 0.056513101793825626 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1751 Avg_loss: 0.05591162648051977 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1752 Avg_loss: 0.055327771604061125 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1753 Avg_loss: 0.05477490704506636 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1754 Avg_loss: 0.05425742212682962 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1755 Avg_loss: 0.053744138590991496 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1756 Avg_loss: 0.05323216207325458 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1757 Avg_loss: 0.052697078324854374 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1758 Avg_loss: 0.05218758024275303 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1759 Avg_loss: 0.051716025732457635 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1760 Avg_loss: 0.05126249101012945 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1761 Avg_loss: 0.050784554332494736 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1762 Avg_loss: 0.05034108404070139 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1763 Avg_loss: 0.04992542639374733 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1764 Avg_loss: 0.049501482769846915 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1765 Avg_loss: 0.049055942334234715 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1766 Avg_loss: 0.048609620332717894 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1767 Avg_loss: 0.048176958970725534 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1768 Avg_loss: 0.047769513167440894 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1769 Avg_loss: 0.04737728741019964 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1770 Avg_loss: 0.046967812441289426 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1771 Avg_loss: 0.04654919523745775 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1772 Avg_loss: 0.0461528230458498 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1773 Avg_loss: 0.045806092023849485 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1774 Avg_loss: 0.045476756431162356 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1775 Avg_loss: 0.045088683068752286 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1776 Avg_loss: 0.0447271216660738 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1777 Avg_loss: 0.04438368212431669 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1778 Avg_loss: 0.04405472241342068 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1779 Avg_loss: 0.043688366934657094 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1780 Avg_loss: 0.04332521930336952 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1781 Avg_loss: 0.043028813786804676 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1782 Avg_loss: 0.04281188808381557 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1783 Avg_loss: 0.042540833726525305 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1784 Avg_loss: 0.04213776532560587 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1785 Avg_loss: 0.03761339616030455 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1786 Avg_loss: 0.03733017742633819 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1787 Avg_loss: 0.03704210165888071 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1788 Avg_loss: 0.03669613897800446 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1789 Avg_loss: 0.03639630433171988 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1790 Avg_loss: 0.03616056442260742 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1791 Avg_loss: 0.035857255943119525 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1792 Avg_loss: 0.035550587065517905 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1793 Avg_loss: 0.035262957029044625 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1794 Avg_loss: 0.03497842215001583 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1795 Avg_loss: 0.03470694273710251 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1796 Avg_loss: 0.03444124851375818 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1797 Avg_loss: 0.034179710783064365 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1798 Avg_loss: 0.0339383402839303 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1799 Avg_loss: 0.03365748468786478 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1800 Avg_loss: 0.03343050088733435 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1801 Avg_loss: 0.033306218683719635 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1802 Avg_loss: 0.0331106485798955 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1803 Avg_loss: 0.03276718482375145 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1804 Avg_loss: 0.03245527613908052 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1805 Avg_loss: 0.03221444059163332 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1806 Avg_loss: 0.032032084092497824 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1807 Avg_loss: 0.031796081177890304 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1808 Avg_loss: 0.03153713243082166 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1809 Avg_loss: 0.03130487557500601 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1810 Avg_loss: 0.03115204516798258 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1811 Avg_loss: 0.03108738539740443 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1812 Avg_loss: 0.030836821440607308 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1813 Avg_loss: 0.0305200582370162 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1814 Avg_loss: 0.030255982279777528 training accuracy: 1.0 test accuracy: 0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1815 Avg_loss: 0.03014680165797472 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1816 Avg_loss: 0.030040144082158805 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1817 Avg_loss: 0.029736494272947313 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1818 Avg_loss: 0.029484369978308677 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1819 Avg_loss: 0.029327946621924637 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1820 Avg_loss: 0.029154849890619516 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1821 Avg_loss: 0.028974893130362035 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1822 Avg_loss: 0.02877056086435914 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1823 Avg_loss: 0.028640538174659013 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1824 Avg_loss: 0.028477213252335785 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1825 Avg_loss: 0.02824432300403714 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1826 Avg_loss: 0.028022150322794915 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1827 Avg_loss: 0.027810882404446603 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1828 Avg_loss: 0.02768494114279747 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1829 Avg_loss: 0.02756537115201354 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1830 Avg_loss: 0.02734931306913495 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1831 Avg_loss: 0.02712608203291893 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1832 Avg_loss: 0.026968298945575953 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1833 Avg_loss: 0.02682308303192258 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1834 Avg_loss: 0.02667615944519639 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1835 Avg_loss: 0.026521164923906326 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1836 Avg_loss: 0.026415092404931784 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1837 Avg_loss: 0.026396297197788954 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1838 Avg_loss: 0.026222599577158688 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1839 Avg_loss: 0.025964114628732205 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1840 Avg_loss: 0.025758067704737188 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1841 Avg_loss: 0.025574602745473386 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1842 Avg_loss: 0.025419382471591236 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1843 Avg_loss: 0.025343985110521317 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1844 Avg_loss: 0.025244366098195314 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1845 Avg_loss: 0.025054784957319498 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1846 Avg_loss: 0.0249552421271801 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1847 Avg_loss: 0.02511690091341734 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1848 Avg_loss: 0.08327346174046397 training accuracy: 0.98125 test accuracy: 0.30612244897959184\n",
      "Epoch: 1849 Avg_loss: 0.33640767224133017 training accuracy: 0.940625 test accuracy: 0.2653061224489796\n",
      "Epoch: 1850 Avg_loss: 0.3029865600168705 training accuracy: 0.96875 test accuracy: 0.272108843537415\n",
      "Epoch: 1851 Avg_loss: 0.2272143118083477 training accuracy: 0.9875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1852 Avg_loss: 0.18443156480789186 training accuracy: 0.99375 test accuracy: 0.23809523809523808\n",
      "Epoch: 1853 Avg_loss: 0.16479869037866593 training accuracy: 0.99375 test accuracy: 0.25170068027210885\n",
      "Epoch: 1854 Avg_loss: 0.15196293592453003 training accuracy: 0.99375 test accuracy: 0.24489795918367346\n",
      "Epoch: 1855 Avg_loss: 0.14294945299625397 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 1856 Avg_loss: 0.1358346100896597 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 1857 Avg_loss: 0.13138468340039253 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 1858 Avg_loss: 0.12686061039566993 training accuracy: 0.996875 test accuracy: 0.23809523809523808\n",
      "Epoch: 1859 Avg_loss: 0.12307304702699184 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1860 Avg_loss: 0.11907182522118091 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1861 Avg_loss: 0.11401537247002125 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1862 Avg_loss: 0.1103044655174017 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1863 Avg_loss: 0.10732253566384316 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1864 Avg_loss: 0.10469342544674873 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1865 Avg_loss: 0.10232979953289031 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1866 Avg_loss: 0.10015630982816219 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1867 Avg_loss: 0.09814238585531712 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1868 Avg_loss: 0.09625627808272838 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1869 Avg_loss: 0.09451833218336106 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1870 Avg_loss: 0.09285307303071022 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1871 Avg_loss: 0.09126241430640221 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1872 Avg_loss: 0.0897387344390154 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1873 Avg_loss: 0.0883030854165554 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1874 Avg_loss: 0.08693489171564579 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1875 Avg_loss: 0.08562888279557228 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1876 Avg_loss: 0.08435682468116283 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1877 Avg_loss: 0.08314406052231789 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1878 Avg_loss: 0.08197250925004482 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1879 Avg_loss: 0.08088205866515637 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1880 Avg_loss: 0.07979443110525608 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1881 Avg_loss: 0.07875952199101448 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1882 Avg_loss: 0.07769042998552322 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1883 Avg_loss: 0.07666628248989582 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1884 Avg_loss: 0.0756725486367941 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1885 Avg_loss: 0.07471136040985585 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1886 Avg_loss: 0.07378327026963234 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1887 Avg_loss: 0.07289409451186657 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1888 Avg_loss: 0.0720050260424614 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1889 Avg_loss: 0.07115260660648345 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1890 Avg_loss: 0.070325568318367 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1891 Avg_loss: 0.06951175890862941 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1892 Avg_loss: 0.06869987063109875 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1893 Avg_loss: 0.06792961955070495 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1894 Avg_loss: 0.06719416044652463 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1895 Avg_loss: 0.066448063403368 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1896 Avg_loss: 0.0656947249546647 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1897 Avg_loss: 0.06500956527888775 training accuracy: 1.0 test accuracy: 0.2789115646258503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1898 Avg_loss: 0.06432375386357307 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1899 Avg_loss: 0.06364089492708444 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1900 Avg_loss: 0.06295102182775736 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1901 Avg_loss: 0.06227812506258488 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1902 Avg_loss: 0.061609435081481936 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1903 Avg_loss: 0.06096287909895182 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1904 Avg_loss: 0.06032835654914379 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1905 Avg_loss: 0.0597213925793767 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1906 Avg_loss: 0.059139946661889556 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1907 Avg_loss: 0.05856198742985726 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1908 Avg_loss: 0.057952951081097125 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1909 Avg_loss: 0.05734079331159592 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1910 Avg_loss: 0.05671906210482121 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1911 Avg_loss: 0.05610196627676487 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1912 Avg_loss: 0.055518518574535845 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1913 Avg_loss: 0.05495117586106062 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1914 Avg_loss: 0.05437847729772329 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 1915 Avg_loss: 0.05380359664559364 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 1916 Avg_loss: 0.05326452367007732 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 1917 Avg_loss: 0.05281425192952156 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 1918 Avg_loss: 0.052221563272178174 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1919 Avg_loss: 0.051481501385569575 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1920 Avg_loss: 0.05000323820859194 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1921 Avg_loss: 0.05171925742179155 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 1922 Avg_loss: 0.050486940704286096 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1923 Avg_loss: 0.06092119291424751 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 1924 Avg_loss: 0.051429678499698636 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1925 Avg_loss: 0.05118247289210558 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1926 Avg_loss: 0.05045122485607863 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1927 Avg_loss: 0.04969586953520775 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1928 Avg_loss: 0.048993343859910964 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1929 Avg_loss: 0.04833765234798193 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1930 Avg_loss: 0.04775849524885416 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1931 Avg_loss: 0.04722440391778946 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1932 Avg_loss: 0.04669534284621477 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1933 Avg_loss: 0.04614461027085781 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1934 Avg_loss: 0.04565642643719912 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 1935 Avg_loss: 0.04523841422051191 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1936 Avg_loss: 0.044793203473091125 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1937 Avg_loss: 0.044270686060190204 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1938 Avg_loss: 0.043780396319925786 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1939 Avg_loss: 0.04332778807729483 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1940 Avg_loss: 0.04287870693951845 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1941 Avg_loss: 0.042463572882115844 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1942 Avg_loss: 0.04207514580339193 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1943 Avg_loss: 0.04167863819748163 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1944 Avg_loss: 0.04126433357596397 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1945 Avg_loss: 0.040857129357755186 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1946 Avg_loss: 0.04047383982688189 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1947 Avg_loss: 0.04008136391639709 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1948 Avg_loss: 0.039750796370208265 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1949 Avg_loss: 0.039435320533812046 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1950 Avg_loss: 0.03903769962489605 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1951 Avg_loss: 0.038632005266845224 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1952 Avg_loss: 0.03827775493264198 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1953 Avg_loss: 0.03797168917953968 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1954 Avg_loss: 0.03764063287526369 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1955 Avg_loss: 0.03728289287537336 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1956 Avg_loss: 0.0369521651417017 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1957 Avg_loss: 0.03664233330637216 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1958 Avg_loss: 0.03632401879876852 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1959 Avg_loss: 0.035994640178978445 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1960 Avg_loss: 0.03574663642793894 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1961 Avg_loss: 0.0354750519618392 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1962 Avg_loss: 0.035116839595139025 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1963 Avg_loss: 0.034817245416343214 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1964 Avg_loss: 0.034554718248546126 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1965 Avg_loss: 0.03427381366491318 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1966 Avg_loss: 0.03398033585399389 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1967 Avg_loss: 0.03369705136865377 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1968 Avg_loss: 0.03352238442748785 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1969 Avg_loss: 0.0332383194938302 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1970 Avg_loss: 0.0328788498416543 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1971 Avg_loss: 0.03256253413856029 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1972 Avg_loss: 0.032442038506269456 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1973 Avg_loss: 0.03227983713150025 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1974 Avg_loss: 0.03195125963538885 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1975 Avg_loss: 0.03162378193810582 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1976 Avg_loss: 0.03133447915315628 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1977 Avg_loss: 0.031055789068341257 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1978 Avg_loss: 0.030807269364595415 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1979 Avg_loss: 0.03057195795699954 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1980 Avg_loss: 0.030324657447636127 training accuracy: 1.0 test accuracy: 0.23129251700680273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1981 Avg_loss: 0.030093161202967168 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1982 Avg_loss: 0.029973371420055628 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 1983 Avg_loss: 0.02980037936940789 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1984 Avg_loss: 0.029505628906190396 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1985 Avg_loss: 0.029251137096434832 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1986 Avg_loss: 0.02902843290939927 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1987 Avg_loss: 0.028786864038556813 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1988 Avg_loss: 0.028637092281132936 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1989 Avg_loss: 0.028448155149817467 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1990 Avg_loss: 0.028212430700659753 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1991 Avg_loss: 0.028029804956167935 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 1992 Avg_loss: 0.027815870195627212 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1993 Avg_loss: 0.02756986767053604 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1994 Avg_loss: 0.02741208653897047 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1995 Avg_loss: 0.027275598142296076 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1996 Avg_loss: 0.027124029770493507 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 1997 Avg_loss: 0.026931368093937636 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1998 Avg_loss: 0.02679224722087383 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 1999 Avg_loss: 0.02655140133574605 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "best accuracy: 0.3945578231292517\n"
     ]
    }
   ],
   "source": [
    "model1, best_state1, best_acc1, loss1, acc1 = train_model(training_data, training_labels,\n",
    "                                                             test_data, test_labels, 2000, 128, 32,\n",
    "                                                             lr=0.0001, lamb=0.001, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "level-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Avg_loss: 3.7881065130233766 training accuracy: 0.246875 test accuracy: 0.2925170068027211\n",
      "Epoch: 1 Avg_loss: 3.2346574306488036 training accuracy: 0.39375 test accuracy: 0.3129251700680272\n",
      "Epoch: 2 Avg_loss: 2.938950443267822 training accuracy: 0.45625 test accuracy: 0.2789115646258503\n",
      "Epoch: 3 Avg_loss: 2.726707363128662 training accuracy: 0.4875 test accuracy: 0.30612244897959184\n",
      "Epoch: 4 Avg_loss: 2.530256462097168 training accuracy: 0.525 test accuracy: 0.3333333333333333\n",
      "Epoch: 5 Avg_loss: 2.3521998167037963 training accuracy: 0.546875 test accuracy: 0.2653061224489796\n",
      "Epoch: 6 Avg_loss: 2.1843955755233764 training accuracy: 0.603125 test accuracy: 0.3129251700680272\n",
      "Epoch: 7 Avg_loss: 2.022719645500183 training accuracy: 0.65 test accuracy: 0.2925170068027211\n",
      "Epoch: 8 Avg_loss: 1.8797616243362427 training accuracy: 0.684375 test accuracy: 0.29931972789115646\n",
      "Epoch: 9 Avg_loss: 1.7510489225387573 training accuracy: 0.709375 test accuracy: 0.3129251700680272\n",
      "Epoch: 10 Avg_loss: 1.641551923751831 training accuracy: 0.734375 test accuracy: 0.2857142857142857\n",
      "Epoch: 11 Avg_loss: 1.530046284198761 training accuracy: 0.7625 test accuracy: 0.3333333333333333\n",
      "Epoch: 12 Avg_loss: 1.4276939630508423 training accuracy: 0.7875 test accuracy: 0.3401360544217687\n",
      "Epoch: 13 Avg_loss: 1.3351819276809693 training accuracy: 0.834375 test accuracy: 0.2585034013605442\n",
      "Epoch: 14 Avg_loss: 1.2768452286720275 training accuracy: 0.84375 test accuracy: 0.3333333333333333\n",
      "Epoch: 15 Avg_loss: 1.228121316432953 training accuracy: 0.821875 test accuracy: 0.36054421768707484\n",
      "Epoch: 16 Avg_loss: 1.1541563987731933 training accuracy: 0.8625 test accuracy: 0.2789115646258503\n",
      "Epoch: 17 Avg_loss: 1.1040977835655212 training accuracy: 0.884375 test accuracy: 0.3401360544217687\n",
      "Epoch: 18 Avg_loss: 1.0920824885368348 training accuracy: 0.878125 test accuracy: 0.3333333333333333\n",
      "Epoch: 19 Avg_loss: 1.046104657649994 training accuracy: 0.890625 test accuracy: 0.3469387755102041\n",
      "Epoch: 20 Avg_loss: 1.0077380776405334 training accuracy: 0.9125 test accuracy: 0.36054421768707484\n",
      "Epoch: 21 Avg_loss: 0.9889785587787628 training accuracy: 0.903125 test accuracy: 0.36054421768707484\n",
      "Epoch: 22 Avg_loss: 0.935138714313507 training accuracy: 0.940625 test accuracy: 0.36054421768707484\n",
      "Epoch: 23 Avg_loss: 0.8929870784282684 training accuracy: 0.946875 test accuracy: 0.2789115646258503\n",
      "Epoch: 24 Avg_loss: 0.8506286859512329 training accuracy: 0.959375 test accuracy: 0.30612244897959184\n",
      "Epoch: 25 Avg_loss: 0.8148409366607666 training accuracy: 0.965625 test accuracy: 0.30612244897959184\n",
      "Epoch: 26 Avg_loss: 0.7956475555896759 training accuracy: 0.9625 test accuracy: 0.2789115646258503\n",
      "Epoch: 27 Avg_loss: 0.8320840239524842 training accuracy: 0.94375 test accuracy: 0.3129251700680272\n",
      "Epoch: 28 Avg_loss: 0.7912454605102539 training accuracy: 0.96875 test accuracy: 0.2789115646258503\n",
      "Epoch: 29 Avg_loss: 0.7715480625629425 training accuracy: 0.978125 test accuracy: 0.25170068027210885\n",
      "Epoch: 30 Avg_loss: 0.7343902111053466 training accuracy: 0.990625 test accuracy: 0.25170068027210885\n",
      "Epoch: 31 Avg_loss: 0.6996442973613739 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 32 Avg_loss: 0.6678184151649476 training accuracy: 0.990625 test accuracy: 0.24489795918367346\n",
      "Epoch: 33 Avg_loss: 0.634806889295578 training accuracy: 0.99375 test accuracy: 0.24489795918367346\n",
      "Epoch: 34 Avg_loss: 0.6055171549320221 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 35 Avg_loss: 0.5789780735969543 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 36 Avg_loss: 0.5556276977062226 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 37 Avg_loss: 0.5350355386734009 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 38 Avg_loss: 0.5163431763648987 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 39 Avg_loss: 0.4995295912027359 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 40 Avg_loss: 0.48447610437870026 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 41 Avg_loss: 0.47074691355228426 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 42 Avg_loss: 0.4581535220146179 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 43 Avg_loss: 0.44658973813056946 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 44 Avg_loss: 0.4360034793615341 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 45 Avg_loss: 0.4261568278074265 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 46 Avg_loss: 0.41737366318702696 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 47 Avg_loss: 0.4089606463909149 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 48 Avg_loss: 0.4007396101951599 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 49 Avg_loss: 0.39340769350528715 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 50 Avg_loss: 0.38896682262420657 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 51 Avg_loss: 0.38195917308330535 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 52 Avg_loss: 0.3752791047096252 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 53 Avg_loss: 0.36928908824920653 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 54 Avg_loss: 0.3638435661792755 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 55 Avg_loss: 0.35885668694972994 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 56 Avg_loss: 0.35407334864139556 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 57 Avg_loss: 0.34968939125537873 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 58 Avg_loss: 0.3455768287181854 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 59 Avg_loss: 0.3417325526475906 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 60 Avg_loss: 0.33812645375728606 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 61 Avg_loss: 0.33462961614131925 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 62 Avg_loss: 0.33131458461284635 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 63 Avg_loss: 0.3280944496393204 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 64 Avg_loss: 0.3251037895679474 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 65 Avg_loss: 0.3222463846206665 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 66 Avg_loss: 0.3195340782403946 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 67 Avg_loss: 0.3169387936592102 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 68 Avg_loss: 0.3143798321485519 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 69 Avg_loss: 0.3119650363922119 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 70 Avg_loss: 0.3096728414297104 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 71 Avg_loss: 0.30741238296031953 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 72 Avg_loss: 0.30520846247673034 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 73 Avg_loss: 0.3031094253063202 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 74 Avg_loss: 0.3010601609945297 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 75 Avg_loss: 0.29904119968414306 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 76 Avg_loss: 0.2971484810113907 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 77 Avg_loss: 0.29530586302280426 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 78 Avg_loss: 0.2933756232261658 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 79 Avg_loss: 0.2915007084608078 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 80 Avg_loss: 0.2896618634462357 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 81 Avg_loss: 0.2879456430673599 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 82 Avg_loss: 0.28628860116004945 training accuracy: 1.0 test accuracy: 0.29931972789115646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83 Avg_loss: 0.2846130609512329 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 84 Avg_loss: 0.28290984630584715 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 85 Avg_loss: 0.28128315806388854 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 86 Avg_loss: 0.2797111958265305 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 87 Avg_loss: 0.2782013535499573 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 88 Avg_loss: 0.27666805386543275 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 89 Avg_loss: 0.2752715229988098 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 90 Avg_loss: 0.2738748282194138 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 91 Avg_loss: 0.27253676652908326 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 92 Avg_loss: 0.27115297615528106 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 93 Avg_loss: 0.2698055595159531 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 94 Avg_loss: 0.2684536337852478 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 95 Avg_loss: 0.2671557903289795 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 96 Avg_loss: 0.2658820301294327 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 97 Avg_loss: 0.2646534353494644 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 98 Avg_loss: 0.26345347464084623 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 99 Avg_loss: 0.2623245120048523 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 100 Avg_loss: 0.2611312627792358 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 101 Avg_loss: 0.2600670844316483 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 102 Avg_loss: 0.2588375985622406 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 103 Avg_loss: 0.2578922897577286 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 104 Avg_loss: 0.25785233080387115 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 105 Avg_loss: 0.25817216038703916 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 106 Avg_loss: 0.2567684009671211 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 107 Avg_loss: 0.25563993901014326 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 108 Avg_loss: 0.25420688688755033 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 109 Avg_loss: 0.2530414417386055 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 110 Avg_loss: 0.25442778766155244 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 111 Avg_loss: 0.3620487838983536 training accuracy: 0.965625 test accuracy: 0.2789115646258503\n",
      "Epoch: 112 Avg_loss: 0.9153838992118836 training accuracy: 0.825 test accuracy: 0.29931972789115646\n",
      "Epoch: 113 Avg_loss: 1.1546208381652832 training accuracy: 0.853125 test accuracy: 0.2585034013605442\n",
      "Epoch: 114 Avg_loss: 1.1633142709732056 training accuracy: 0.909375 test accuracy: 0.29931972789115646\n",
      "Epoch: 115 Avg_loss: 1.155187690258026 training accuracy: 0.9125 test accuracy: 0.30612244897959184\n",
      "Epoch: 116 Avg_loss: 1.068536216020584 training accuracy: 0.959375 test accuracy: 0.2789115646258503\n",
      "Epoch: 117 Avg_loss: 1.0295863151550293 training accuracy: 0.94375 test accuracy: 0.2653061224489796\n",
      "Epoch: 118 Avg_loss: 1.017889964580536 training accuracy: 0.946875 test accuracy: 0.2925170068027211\n",
      "Epoch: 119 Avg_loss: 0.9342256128787995 training accuracy: 0.975 test accuracy: 0.2857142857142857\n",
      "Epoch: 120 Avg_loss: 0.905489307641983 training accuracy: 0.975 test accuracy: 0.2857142857142857\n",
      "Epoch: 121 Avg_loss: 0.847844809293747 training accuracy: 0.984375 test accuracy: 0.25170068027210885\n",
      "Epoch: 122 Avg_loss: 0.8047968566417694 training accuracy: 0.9875 test accuracy: 0.272108843537415\n",
      "Epoch: 123 Avg_loss: 0.7638669371604919 training accuracy: 0.984375 test accuracy: 0.29931972789115646\n",
      "Epoch: 124 Avg_loss: 0.7273329854011535 training accuracy: 0.990625 test accuracy: 0.2789115646258503\n",
      "Epoch: 125 Avg_loss: 0.6939276218414306 training accuracy: 0.990625 test accuracy: 0.272108843537415\n",
      "Epoch: 126 Avg_loss: 0.6880296289920806 training accuracy: 0.98125 test accuracy: 0.2585034013605442\n",
      "Epoch: 127 Avg_loss: 0.7398389458656311 training accuracy: 0.965625 test accuracy: 0.2585034013605442\n",
      "Epoch: 128 Avg_loss: 0.6769923448562623 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 129 Avg_loss: 0.6514912366867065 training accuracy: 0.990625 test accuracy: 0.272108843537415\n",
      "Epoch: 130 Avg_loss: 0.6228209972381592 training accuracy: 0.99375 test accuracy: 0.25170068027210885\n",
      "Epoch: 131 Avg_loss: 0.5932743430137635 training accuracy: 0.99375 test accuracy: 0.24489795918367346\n",
      "Epoch: 132 Avg_loss: 0.5643387377262116 training accuracy: 0.99375 test accuracy: 0.25170068027210885\n",
      "Epoch: 133 Avg_loss: 0.5300145417451858 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 134 Avg_loss: 0.5049564510583877 training accuracy: 0.996875 test accuracy: 0.24489795918367346\n",
      "Epoch: 135 Avg_loss: 0.4826341778039932 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 136 Avg_loss: 0.4627185255289078 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 137 Avg_loss: 0.444706118106842 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 138 Avg_loss: 0.4282652050256729 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 139 Avg_loss: 0.41358213424682616 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 140 Avg_loss: 0.4002119183540344 training accuracy: 0.996875 test accuracy: 0.25170068027210885\n",
      "Epoch: 141 Avg_loss: 0.38805694580078126 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 142 Avg_loss: 0.3769623965024948 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 143 Avg_loss: 0.366876545548439 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 144 Avg_loss: 0.35759426951408385 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 145 Avg_loss: 0.34906392693519595 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 146 Avg_loss: 0.34124945998191836 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 147 Avg_loss: 0.33409594297409057 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 148 Avg_loss: 0.32750600576400757 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 149 Avg_loss: 0.3214753657579422 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 150 Avg_loss: 0.31582061350345614 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 151 Avg_loss: 0.3101680248975754 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 152 Avg_loss: 0.3051364988088608 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 153 Avg_loss: 0.30031591951847075 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 154 Avg_loss: 0.29618636071681975 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 155 Avg_loss: 0.2887555301189423 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 156 Avg_loss: 0.2849331021308899 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 157 Avg_loss: 0.2815690815448761 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 158 Avg_loss: 0.27872005105018616 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 159 Avg_loss: 0.2752822995185852 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 160 Avg_loss: 0.27233017683029176 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 161 Avg_loss: 0.2697480142116547 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 162 Avg_loss: 0.26722181141376494 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 163 Avg_loss: 0.2650328516960144 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 164 Avg_loss: 0.26293812692165375 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 165 Avg_loss: 0.2609180748462677 training accuracy: 1.0 test accuracy: 0.29931972789115646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 166 Avg_loss: 0.25911361873149874 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 167 Avg_loss: 0.25734166204929354 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 168 Avg_loss: 0.2557821929454803 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 169 Avg_loss: 0.2542300522327423 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 170 Avg_loss: 0.2528239116072655 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 171 Avg_loss: 0.2514162346720695 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 172 Avg_loss: 0.25015381872653963 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 173 Avg_loss: 0.24889223873615265 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 174 Avg_loss: 0.24774073511362077 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 175 Avg_loss: 0.24717580229043962 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 176 Avg_loss: 0.24650365561246873 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 177 Avg_loss: 0.24519745707511903 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 178 Avg_loss: 0.24368511736392975 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 179 Avg_loss: 0.24296429604291916 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 180 Avg_loss: 0.2418561965227127 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 181 Avg_loss: 0.24082692265510558 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 182 Avg_loss: 0.24004211723804475 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 183 Avg_loss: 0.23911778181791304 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 184 Avg_loss: 0.23831778764724731 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 185 Avg_loss: 0.23748439848423003 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 186 Avg_loss: 0.23672446012496948 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 187 Avg_loss: 0.2360636845231056 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 188 Avg_loss: 0.2353482112288475 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 189 Avg_loss: 0.23466954678297042 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 190 Avg_loss: 0.23387896865606309 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 191 Avg_loss: 0.23323088735342026 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 192 Avg_loss: 0.23250190913677216 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 193 Avg_loss: 0.23184189796447754 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 194 Avg_loss: 0.2310501903295517 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 195 Avg_loss: 0.23052365332841873 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 196 Avg_loss: 0.22966501712799073 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 197 Avg_loss: 0.22900602519512175 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 198 Avg_loss: 0.22831962257623672 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 199 Avg_loss: 0.22773803621530533 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 200 Avg_loss: 0.22707315683364868 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 201 Avg_loss: 0.22647680342197418 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 202 Avg_loss: 0.22584664821624756 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 203 Avg_loss: 0.22528953552246095 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 204 Avg_loss: 0.22469112724065782 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 205 Avg_loss: 0.22415715754032134 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 206 Avg_loss: 0.22358845323324203 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 207 Avg_loss: 0.22308708131313323 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 208 Avg_loss: 0.22260829508304597 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 209 Avg_loss: 0.22228077799081802 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 210 Avg_loss: 0.22137245535850525 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 211 Avg_loss: 0.22086769640445708 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 212 Avg_loss: 0.22034110575914384 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 213 Avg_loss: 0.21976314783096312 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 214 Avg_loss: 0.21946485191583634 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 215 Avg_loss: 0.2186507910490036 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 216 Avg_loss: 0.2182365283370018 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 217 Avg_loss: 0.21768517792224884 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 218 Avg_loss: 0.21726846545934678 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 219 Avg_loss: 0.21705740094184875 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 220 Avg_loss: 0.21619799137115478 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 221 Avg_loss: 0.2157485380768776 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 222 Avg_loss: 0.21526419818401338 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 223 Avg_loss: 0.21489063054323196 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 224 Avg_loss: 0.2146715357899666 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 225 Avg_loss: 0.21383906304836273 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 226 Avg_loss: 0.21349704563617705 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 227 Avg_loss: 0.2130187451839447 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 228 Avg_loss: 0.2125868856906891 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 229 Avg_loss: 0.21232297122478486 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 230 Avg_loss: 0.21164363175630568 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 231 Avg_loss: 0.211247256398201 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 232 Avg_loss: 0.21073361933231355 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 233 Avg_loss: 0.21039423942565919 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 234 Avg_loss: 0.20989056378602983 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 235 Avg_loss: 0.20952064841985701 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 236 Avg_loss: 0.20905034244060516 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 237 Avg_loss: 0.20874927788972855 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 238 Avg_loss: 0.20822279751300812 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 239 Avg_loss: 0.2078950121998787 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 240 Avg_loss: 0.2074768915772438 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 241 Avg_loss: 0.20712052881717682 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 242 Avg_loss: 0.20661402195692063 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 243 Avg_loss: 0.20639794319868088 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 244 Avg_loss: 0.20582227706909179 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 245 Avg_loss: 0.20550907999277115 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 246 Avg_loss: 0.20504335612058638 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 247 Avg_loss: 0.20469279885292052 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 248 Avg_loss: 0.20420958250761032 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 249 Avg_loss: 0.20396066904067994 training accuracy: 1.0 test accuracy: 0.29931972789115646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250 Avg_loss: 0.20348175317049028 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 251 Avg_loss: 0.20317238718271255 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 252 Avg_loss: 0.2027766451239586 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 253 Avg_loss: 0.20247769504785537 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 254 Avg_loss: 0.20203752368688582 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 255 Avg_loss: 0.20175745636224746 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 256 Avg_loss: 0.20128278136253358 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 257 Avg_loss: 0.20096681416034698 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 258 Avg_loss: 0.20053593218326568 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 259 Avg_loss: 0.20018824338912963 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 260 Avg_loss: 0.19978991001844407 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 261 Avg_loss: 0.19948389679193496 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 262 Avg_loss: 0.19906809329986572 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 263 Avg_loss: 0.19876629263162612 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 264 Avg_loss: 0.19835461378097535 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 265 Avg_loss: 0.19801499098539352 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 266 Avg_loss: 0.19769429564476013 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 267 Avg_loss: 0.19742142409086227 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 268 Avg_loss: 0.19700222015380858 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 269 Avg_loss: 0.19673122018575667 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 270 Avg_loss: 0.1963445097208023 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 271 Avg_loss: 0.19607643485069276 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 272 Avg_loss: 0.19579746425151826 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 273 Avg_loss: 0.19553348124027253 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 274 Avg_loss: 0.19516048431396485 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 275 Avg_loss: 0.19487714171409606 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 276 Avg_loss: 0.19453890174627303 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 277 Avg_loss: 0.19421763569116593 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 278 Avg_loss: 0.19393350183963776 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 279 Avg_loss: 0.19371135532855988 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 280 Avg_loss: 0.1934155985713005 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 281 Avg_loss: 0.1931083768606186 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 282 Avg_loss: 0.19279926121234894 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 283 Avg_loss: 0.19253873825073242 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 284 Avg_loss: 0.19227752685546876 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 285 Avg_loss: 0.19208017736673355 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 286 Avg_loss: 0.19176193773746492 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 287 Avg_loss: 0.19150598496198654 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 288 Avg_loss: 0.19111673533916473 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 289 Avg_loss: 0.19082642942667008 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 290 Avg_loss: 0.19078727215528488 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 291 Avg_loss: 0.19044256210327148 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 292 Avg_loss: 0.18992310911417007 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 293 Avg_loss: 0.18975625336170196 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 294 Avg_loss: 0.18973895758390427 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 295 Avg_loss: 0.190397047996521 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 296 Avg_loss: 0.19077361822128297 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 297 Avg_loss: 0.18967909812927247 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 298 Avg_loss: 0.18878056854009628 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 299 Avg_loss: 0.187968210875988 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 300 Avg_loss: 0.1876253977417946 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 301 Avg_loss: 0.18720462769269944 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 302 Avg_loss: 0.18709373325109482 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 303 Avg_loss: 0.18686254769563676 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 304 Avg_loss: 0.18664972484111786 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 305 Avg_loss: 0.186333729326725 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 306 Avg_loss: 0.18617211729288102 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 307 Avg_loss: 0.1857786387205124 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 308 Avg_loss: 0.18568405658006668 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 309 Avg_loss: 0.18571490794420242 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 310 Avg_loss: 0.2089085564017296 training accuracy: 0.99375 test accuracy: 0.30612244897959184\n",
      "Epoch: 311 Avg_loss: 0.9750289976596832 training accuracy: 0.725 test accuracy: 0.23129251700680273\n",
      "Epoch: 312 Avg_loss: 2.173416805267334 training accuracy: 0.590625 test accuracy: 0.23129251700680273\n",
      "Epoch: 313 Avg_loss: 2.445658731460571 training accuracy: 0.6875 test accuracy: 0.29931972789115646\n",
      "Epoch: 314 Avg_loss: 2.3109294056892393 training accuracy: 0.784375 test accuracy: 0.23809523809523808\n",
      "Epoch: 315 Avg_loss: 2.0995811104774473 training accuracy: 0.828125 test accuracy: 0.22448979591836735\n",
      "Epoch: 316 Avg_loss: 1.868669867515564 training accuracy: 0.853125 test accuracy: 0.272108843537415\n",
      "Epoch: 317 Avg_loss: 1.5792402386665345 training accuracy: 0.915625 test accuracy: 0.25170068027210885\n",
      "Epoch: 318 Avg_loss: 1.4141339540481568 training accuracy: 0.934375 test accuracy: 0.2857142857142857\n",
      "Epoch: 319 Avg_loss: 1.2903973817825318 training accuracy: 0.94375 test accuracy: 0.2857142857142857\n",
      "Epoch: 320 Avg_loss: 1.1878530144691468 training accuracy: 0.953125 test accuracy: 0.3129251700680272\n",
      "Epoch: 321 Avg_loss: 1.085227358341217 training accuracy: 0.98125 test accuracy: 0.3197278911564626\n",
      "Epoch: 322 Avg_loss: 1.0014885008335113 training accuracy: 0.98125 test accuracy: 0.2789115646258503\n",
      "Epoch: 323 Avg_loss: 0.9451585114002228 training accuracy: 0.990625 test accuracy: 0.3401360544217687\n",
      "Epoch: 324 Avg_loss: 0.850051897764206 training accuracy: 0.99375 test accuracy: 0.3401360544217687\n",
      "Epoch: 325 Avg_loss: 0.771086436510086 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 326 Avg_loss: 0.6983928442001343 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 327 Avg_loss: 0.6364275991916657 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 328 Avg_loss: 0.5848881125450134 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 329 Avg_loss: 0.5413038313388825 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 330 Avg_loss: 0.5049536645412445 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 331 Avg_loss: 0.47421756386756897 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 332 Avg_loss: 0.4478883475065231 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 333 Avg_loss: 0.4250787228345871 training accuracy: 1.0 test accuracy: 0.3401360544217687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 334 Avg_loss: 0.40523519814014436 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 335 Avg_loss: 0.38783019185066225 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 336 Avg_loss: 0.3725547671318054 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 337 Avg_loss: 0.35892176926136016 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 338 Avg_loss: 0.34698604643344877 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 339 Avg_loss: 0.33624337911605834 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 340 Avg_loss: 0.3267329096794128 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 341 Avg_loss: 0.31804895102977754 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 342 Avg_loss: 0.3104286640882492 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 343 Avg_loss: 0.30331181585788725 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 344 Avg_loss: 0.2970673978328705 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 345 Avg_loss: 0.29121056795120237 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 346 Avg_loss: 0.28614322543144227 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 347 Avg_loss: 0.2813646405935287 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 348 Avg_loss: 0.2772474080324173 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 349 Avg_loss: 0.27333599925041197 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 350 Avg_loss: 0.26992634534835813 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 351 Avg_loss: 0.26657153069972994 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 352 Avg_loss: 0.2636201471090317 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 353 Avg_loss: 0.26079779118299484 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 354 Avg_loss: 0.2583045348525047 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 355 Avg_loss: 0.2558938547968864 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 356 Avg_loss: 0.2536610171198845 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 357 Avg_loss: 0.2515295535326004 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 358 Avg_loss: 0.24968912899494172 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 359 Avg_loss: 0.24791555106639862 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 360 Avg_loss: 0.2463625565171242 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 361 Avg_loss: 0.24468048065900802 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 362 Avg_loss: 0.24336895644664763 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 363 Avg_loss: 0.24194420725107194 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 364 Avg_loss: 0.2407468691468239 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 365 Avg_loss: 0.23943038135766984 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 366 Avg_loss: 0.2382269725203514 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 367 Avg_loss: 0.23711283951997758 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 368 Avg_loss: 0.2361387312412262 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 369 Avg_loss: 0.23511724472045897 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 370 Avg_loss: 0.23427012711763381 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 371 Avg_loss: 0.23320512920618058 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 372 Avg_loss: 0.2324461057782173 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 373 Avg_loss: 0.23147833347320557 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 374 Avg_loss: 0.2306962341070175 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 375 Avg_loss: 0.22983911782503127 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 376 Avg_loss: 0.22918296754360198 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 377 Avg_loss: 0.2284097343683243 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 378 Avg_loss: 0.22780034691095352 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 379 Avg_loss: 0.22691164612770082 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 380 Avg_loss: 0.22640687972307205 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 381 Avg_loss: 0.2256422907114029 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 382 Avg_loss: 0.2250952422618866 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 383 Avg_loss: 0.2243631973862648 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 384 Avg_loss: 0.22387725114822388 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 385 Avg_loss: 0.22318619936704637 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 386 Avg_loss: 0.22254883646965026 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 387 Avg_loss: 0.22174254953861236 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 388 Avg_loss: 0.2211251050233841 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 389 Avg_loss: 0.22051285356283187 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 390 Avg_loss: 0.21995258182287217 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 391 Avg_loss: 0.21931221187114716 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 392 Avg_loss: 0.2188320577144623 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 393 Avg_loss: 0.21824164539575577 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 394 Avg_loss: 0.21788844466209412 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 395 Avg_loss: 0.21727778315544127 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 396 Avg_loss: 0.21686073988676072 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 397 Avg_loss: 0.21620002388954163 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 398 Avg_loss: 0.21573340892791748 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 399 Avg_loss: 0.21522993147373198 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 400 Avg_loss: 0.2148882120847702 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 401 Avg_loss: 0.21427157670259475 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 402 Avg_loss: 0.21382225751876832 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 403 Avg_loss: 0.2133200764656067 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 404 Avg_loss: 0.21295799016952516 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 405 Avg_loss: 0.21244191378355026 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 406 Avg_loss: 0.21242308169603347 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 407 Avg_loss: 0.21270528733730315 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 408 Avg_loss: 0.21193024665117263 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 409 Avg_loss: 0.21111102849245073 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 410 Avg_loss: 0.21047043353319167 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 411 Avg_loss: 0.21009726971387863 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 412 Avg_loss: 0.20966279357671738 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 413 Avg_loss: 0.2092764765024185 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 414 Avg_loss: 0.2088042214512825 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 415 Avg_loss: 0.2084277957677841 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 416 Avg_loss: 0.2080005705356598 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 417 Avg_loss: 0.20764870047569275 training accuracy: 1.0 test accuracy: 0.2789115646258503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 418 Avg_loss: 0.2072369322180748 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 419 Avg_loss: 0.20686821937561034 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 420 Avg_loss: 0.20652593672275543 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 421 Avg_loss: 0.2062589108943939 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 422 Avg_loss: 0.20608668327331542 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 423 Avg_loss: 0.2064904823899269 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 424 Avg_loss: 0.20640353113412857 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 425 Avg_loss: 0.20554912686347962 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 426 Avg_loss: 0.20473321676254272 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 427 Avg_loss: 0.20436870455741882 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 428 Avg_loss: 0.2053246259689331 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 429 Avg_loss: 0.20548510998487474 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 430 Avg_loss: 0.20435084402561188 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 431 Avg_loss: 0.20329115390777588 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 432 Avg_loss: 0.2039984107017517 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 433 Avg_loss: 0.2093815714120865 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 434 Avg_loss: 0.5299942001700402 training accuracy: 0.903125 test accuracy: 0.2857142857142857\n",
      "Epoch: 435 Avg_loss: 1.2443678081035614 training accuracy: 0.74375 test accuracy: 0.2857142857142857\n",
      "Epoch: 436 Avg_loss: 1.5818976998329162 training accuracy: 0.796875 test accuracy: 0.2585034013605442\n",
      "Epoch: 437 Avg_loss: 1.6421671628952026 training accuracy: 0.85625 test accuracy: 0.23809523809523808\n",
      "Epoch: 438 Avg_loss: 1.5251644611358643 training accuracy: 0.9125 test accuracy: 0.23129251700680273\n",
      "Epoch: 439 Avg_loss: 1.4672328591346742 training accuracy: 0.896875 test accuracy: 0.23129251700680273\n",
      "Epoch: 440 Avg_loss: 1.328623640537262 training accuracy: 0.94375 test accuracy: 0.3129251700680272\n",
      "Epoch: 441 Avg_loss: 1.3043545365333558 training accuracy: 0.934375 test accuracy: 0.25170068027210885\n",
      "Epoch: 442 Avg_loss: 1.1809875965118408 training accuracy: 0.965625 test accuracy: 0.2789115646258503\n",
      "Epoch: 443 Avg_loss: 1.0700403094291686 training accuracy: 0.975 test accuracy: 0.2653061224489796\n",
      "Epoch: 444 Avg_loss: 0.9428002595901489 training accuracy: 0.984375 test accuracy: 0.2653061224489796\n",
      "Epoch: 445 Avg_loss: 0.8457334935665131 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 446 Avg_loss: 0.7705739736557007 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 447 Avg_loss: 0.7081663191318512 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 448 Avg_loss: 0.6534505248069763 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 449 Avg_loss: 0.6049370110034943 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 450 Avg_loss: 0.5624890685081482 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 451 Avg_loss: 0.5259616613388062 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 452 Avg_loss: 0.4946970909833908 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 453 Avg_loss: 0.467302480340004 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 454 Avg_loss: 0.4430138200521469 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 455 Avg_loss: 0.421748623251915 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 456 Avg_loss: 0.4030299782752991 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 457 Avg_loss: 0.3862778216600418 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 458 Avg_loss: 0.3713378310203552 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 459 Avg_loss: 0.3580236345529556 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 460 Avg_loss: 0.3467175155878067 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 461 Avg_loss: 0.33599950671195983 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 462 Avg_loss: 0.3261377066373825 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 463 Avg_loss: 0.31721064150333406 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 464 Avg_loss: 0.30917043387889864 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 465 Avg_loss: 0.30309867560863496 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 466 Avg_loss: 0.2962921172380447 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 467 Avg_loss: 0.2896460801362991 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 468 Avg_loss: 0.2836539387702942 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 469 Avg_loss: 0.27824018597602845 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 470 Avg_loss: 0.27336292862892153 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 471 Avg_loss: 0.26869111955165864 training accuracy: 0.996875 test accuracy: 0.2789115646258503\n",
      "Epoch: 472 Avg_loss: 0.26426803767681123 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 473 Avg_loss: 0.26038592755794526 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 474 Avg_loss: 0.2568904459476471 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 475 Avg_loss: 0.2541055932641029 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 476 Avg_loss: 0.2511963039636612 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 477 Avg_loss: 0.2484532430768013 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 478 Avg_loss: 0.24589114636182785 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 479 Avg_loss: 0.24361438304185867 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 480 Avg_loss: 0.24243842363357543 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 481 Avg_loss: 0.24045873433351517 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 482 Avg_loss: 0.23822179138660432 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 483 Avg_loss: 0.236164128780365 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 484 Avg_loss: 0.23424046039581298 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 485 Avg_loss: 0.23276780992746354 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 486 Avg_loss: 0.2312791645526886 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 487 Avg_loss: 0.22994754165410997 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 488 Avg_loss: 0.22869866341352463 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 489 Avg_loss: 0.22744965851306914 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 490 Avg_loss: 0.22607071250677108 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 491 Avg_loss: 0.2251119464635849 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 492 Avg_loss: 0.2240317851305008 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 493 Avg_loss: 0.22305704206228255 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 494 Avg_loss: 0.2222095623612404 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 495 Avg_loss: 0.22133775651454926 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 496 Avg_loss: 0.22041874825954438 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 497 Avg_loss: 0.21963708847761154 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 498 Avg_loss: 0.21906862258911133 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 499 Avg_loss: 0.2183478444814682 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 500 Avg_loss: 0.21753368973731996 training accuracy: 1.0 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 501 Avg_loss: 0.21690966933965683 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 502 Avg_loss: 0.21658651083707808 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 503 Avg_loss: 0.2158709466457367 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 504 Avg_loss: 0.21523634046316148 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 505 Avg_loss: 0.21453849822282792 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 506 Avg_loss: 0.21412988007068634 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 507 Avg_loss: 0.21354392170906067 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 508 Avg_loss: 0.21302380710840224 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 509 Avg_loss: 0.2125631034374237 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 510 Avg_loss: 0.21210884302854538 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 511 Avg_loss: 0.21167061626911163 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 512 Avg_loss: 0.2112318381667137 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 513 Avg_loss: 0.2108113646507263 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 514 Avg_loss: 0.2103807732462883 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 515 Avg_loss: 0.21002817749977112 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 516 Avg_loss: 0.20961233377456664 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 517 Avg_loss: 0.20923290997743607 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 518 Avg_loss: 0.20881400108337403 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 519 Avg_loss: 0.20845768898725509 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 520 Avg_loss: 0.20806407928466797 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 521 Avg_loss: 0.2076903834939003 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 522 Avg_loss: 0.20729152411222457 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 523 Avg_loss: 0.2069820523262024 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 524 Avg_loss: 0.20661124736070632 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 525 Avg_loss: 0.2062482386827469 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 526 Avg_loss: 0.2061447098851204 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 527 Avg_loss: 0.2070099413394928 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 528 Avg_loss: 0.2066400468349457 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 529 Avg_loss: 0.20565345883369446 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 530 Avg_loss: 0.20491324365139008 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 531 Avg_loss: 0.20443626940250398 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 532 Avg_loss: 0.20418182760477066 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 533 Avg_loss: 0.20383509993553162 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 534 Avg_loss: 0.2036175400018692 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 535 Avg_loss: 0.20324485450983049 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 536 Avg_loss: 0.20298369228839874 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 537 Avg_loss: 0.2029111385345459 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 538 Avg_loss: 0.20286750197410583 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 539 Avg_loss: 0.20337967574596405 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 540 Avg_loss: 0.20291982740163803 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 541 Avg_loss: 0.20234498530626296 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 542 Avg_loss: 0.2038070961833 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 543 Avg_loss: 0.23170494735240937 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 544 Avg_loss: 0.2686376184225082 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 545 Avg_loss: 0.25199198722839355 training accuracy: 0.996875 test accuracy: 0.2585034013605442\n",
      "Epoch: 546 Avg_loss: 0.4207339406013489 training accuracy: 0.953125 test accuracy: 0.2789115646258503\n",
      "Epoch: 547 Avg_loss: 0.9124434947967529 training accuracy: 0.859375 test accuracy: 0.2585034013605442\n",
      "Epoch: 548 Avg_loss: 1.2971583306789398 training accuracy: 0.84375 test accuracy: 0.29931972789115646\n",
      "Epoch: 549 Avg_loss: 1.3727972626686096 training accuracy: 0.903125 test accuracy: 0.2857142857142857\n",
      "Epoch: 550 Avg_loss: 1.3641687035560608 training accuracy: 0.925 test accuracy: 0.32653061224489793\n",
      "Epoch: 551 Avg_loss: 1.3363418459892273 training accuracy: 0.925 test accuracy: 0.3469387755102041\n",
      "Epoch: 552 Avg_loss: 1.3768054604530335 training accuracy: 0.90625 test accuracy: 0.30612244897959184\n",
      "Epoch: 553 Avg_loss: 1.407376480102539 training accuracy: 0.934375 test accuracy: 0.2653061224489796\n",
      "Epoch: 554 Avg_loss: 1.260193693637848 training accuracy: 0.98125 test accuracy: 0.3333333333333333\n",
      "Epoch: 555 Avg_loss: 1.1537194490432738 training accuracy: 0.978125 test accuracy: 0.2925170068027211\n",
      "Epoch: 556 Avg_loss: 1.0422346889972687 training accuracy: 0.984375 test accuracy: 0.3129251700680272\n",
      "Epoch: 557 Avg_loss: 0.9817611396312713 training accuracy: 0.9875 test accuracy: 0.2789115646258503\n",
      "Epoch: 558 Avg_loss: 0.9059875249862671 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 559 Avg_loss: 0.8304902970790863 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 560 Avg_loss: 0.7603622436523437 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 561 Avg_loss: 0.6999570071697235 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 562 Avg_loss: 0.6473727405071259 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 563 Avg_loss: 0.6024667084217071 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 564 Avg_loss: 0.563790237903595 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 565 Avg_loss: 0.5300045073032379 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 566 Avg_loss: 0.5001277565956116 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 567 Avg_loss: 0.4747839987277985 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 568 Avg_loss: 0.4536522001028061 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 569 Avg_loss: 0.4332527548074722 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 570 Avg_loss: 0.4139998644590378 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 571 Avg_loss: 0.3961112707853317 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 572 Avg_loss: 0.37958810925483705 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 573 Avg_loss: 0.3650367707014084 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 574 Avg_loss: 0.35207689702510836 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 575 Avg_loss: 0.3416074186563492 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 576 Avg_loss: 0.3329960942268372 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 577 Avg_loss: 0.32359790802001953 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 578 Avg_loss: 0.31375170350074766 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 579 Avg_loss: 0.30463891923427583 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 580 Avg_loss: 0.2966335117816925 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 581 Avg_loss: 0.2896924614906311 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 582 Avg_loss: 0.28340276777744294 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 583 Avg_loss: 0.2774751424789429 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 584 Avg_loss: 0.2722226768732071 training accuracy: 1.0 test accuracy: 0.30612244897959184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 585 Avg_loss: 0.26768032610416415 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 586 Avg_loss: 0.263252317905426 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 587 Avg_loss: 0.2589597374200821 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 588 Avg_loss: 0.2551214963197708 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 589 Avg_loss: 0.2517234280705452 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 590 Avg_loss: 0.24887885004281998 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 591 Avg_loss: 0.2456541210412979 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 592 Avg_loss: 0.24716202020645142 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 593 Avg_loss: 0.27972865998744967 training accuracy: 0.996875 test accuracy: 0.3197278911564626\n",
      "Epoch: 594 Avg_loss: 0.3352941572666168 training accuracy: 0.996875 test accuracy: 0.2857142857142857\n",
      "Epoch: 595 Avg_loss: 0.40285548865795134 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 596 Avg_loss: 0.3879351019859314 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 597 Avg_loss: 0.39270553886890414 training accuracy: 0.99375 test accuracy: 0.2585034013605442\n",
      "Epoch: 598 Avg_loss: 0.46491743326187135 training accuracy: 0.978125 test accuracy: 0.2925170068027211\n",
      "Epoch: 599 Avg_loss: 0.6469630539417267 training accuracy: 0.95 test accuracy: 0.2789115646258503\n",
      "Epoch: 600 Avg_loss: 0.7993967473506928 training accuracy: 0.946875 test accuracy: 0.3333333333333333\n",
      "Epoch: 601 Avg_loss: 0.8076420485973358 training accuracy: 0.965625 test accuracy: 0.32653061224489793\n",
      "Epoch: 602 Avg_loss: 0.7804808676242828 training accuracy: 0.990625 test accuracy: 0.2925170068027211\n",
      "Epoch: 603 Avg_loss: 0.7232951641082763 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 604 Avg_loss: 0.7200522005558014 training accuracy: 0.99375 test accuracy: 0.3401360544217687\n",
      "Epoch: 605 Avg_loss: 0.7463991582393646 training accuracy: 0.98125 test accuracy: 0.29931972789115646\n",
      "Epoch: 606 Avg_loss: 0.6886777341365814 training accuracy: 0.996875 test accuracy: 0.35374149659863946\n",
      "Epoch: 607 Avg_loss: 0.6508381068706512 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 608 Avg_loss: 0.6024528980255127 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 609 Avg_loss: 0.5573882460594177 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 610 Avg_loss: 0.5177675545215606 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 611 Avg_loss: 0.48370424211025237 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 612 Avg_loss: 0.45464908182621 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 613 Avg_loss: 0.42953122556209566 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 614 Avg_loss: 0.4076572239398956 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 615 Avg_loss: 0.38845035433769226 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 616 Avg_loss: 0.3714197605848312 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 617 Avg_loss: 0.3563070476055145 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 618 Avg_loss: 0.34276315569877625 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 619 Avg_loss: 0.33059161305427553 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 620 Avg_loss: 0.3195785075426102 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 621 Avg_loss: 0.3096316158771515 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 622 Avg_loss: 0.3006087988615036 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 623 Avg_loss: 0.2924154430627823 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 624 Avg_loss: 0.2849735587835312 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 625 Avg_loss: 0.2781646966934204 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 626 Avg_loss: 0.27193117141723633 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 627 Avg_loss: 0.2662141889333725 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 628 Avg_loss: 0.26096283495426176 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 629 Avg_loss: 0.25612658709287645 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 630 Avg_loss: 0.25169921666383743 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 631 Avg_loss: 0.2475865364074707 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 632 Avg_loss: 0.24383453279733658 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 633 Avg_loss: 0.24034839868545532 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 634 Avg_loss: 0.23710847795009612 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 635 Avg_loss: 0.23407502323389054 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 636 Avg_loss: 0.2312498927116394 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 637 Avg_loss: 0.22868947982788085 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 638 Avg_loss: 0.22625385522842406 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 639 Avg_loss: 0.22405687421560289 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 640 Avg_loss: 0.22200048118829727 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 641 Avg_loss: 0.22010491341352462 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 642 Avg_loss: 0.218315751850605 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 643 Avg_loss: 0.2166927471756935 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 644 Avg_loss: 0.2151949092745781 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 645 Avg_loss: 0.21378855556249618 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 646 Avg_loss: 0.21246386617422103 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 647 Avg_loss: 0.21123155504465102 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 648 Avg_loss: 0.21006999164819717 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 649 Avg_loss: 0.2089776247739792 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 650 Avg_loss: 0.2079617291688919 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 651 Avg_loss: 0.20701770335435868 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 652 Avg_loss: 0.20610522627830505 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 653 Avg_loss: 0.20526452660560607 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 654 Avg_loss: 0.20444409251213075 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 655 Avg_loss: 0.20370105504989625 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 656 Avg_loss: 0.20295846909284593 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 657 Avg_loss: 0.20219604820013046 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 658 Avg_loss: 0.20151690393686295 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 659 Avg_loss: 0.20088142156600952 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 660 Avg_loss: 0.20029594153165817 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 661 Avg_loss: 0.19972157031297683 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 662 Avg_loss: 0.1991783156991005 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 663 Avg_loss: 0.1986578181385994 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 664 Avg_loss: 0.19824193865060807 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 665 Avg_loss: 0.19779222160577775 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 666 Avg_loss: 0.19732233434915541 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 667 Avg_loss: 0.196913281083107 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 668 Avg_loss: 0.19648135155439378 training accuracy: 1.0 test accuracy: 0.30612244897959184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 669 Avg_loss: 0.19605578780174254 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 670 Avg_loss: 0.19565825462341307 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 671 Avg_loss: 0.1952713683247566 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 672 Avg_loss: 0.19487760066986085 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 673 Avg_loss: 0.1945024237036705 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 674 Avg_loss: 0.194172203540802 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 675 Avg_loss: 0.19382306188344955 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 676 Avg_loss: 0.19348121285438538 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 677 Avg_loss: 0.19316141307353973 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 678 Avg_loss: 0.19281337708234786 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 679 Avg_loss: 0.19248783141374587 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 680 Avg_loss: 0.19223373830318452 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 681 Avg_loss: 0.1919446185231209 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 682 Avg_loss: 0.19164714068174363 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 683 Avg_loss: 0.19136128276586534 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 684 Avg_loss: 0.19107313007116317 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 685 Avg_loss: 0.1907849907875061 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 686 Avg_loss: 0.19052906781435014 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 687 Avg_loss: 0.19026408940553666 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 688 Avg_loss: 0.19000381082296372 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 689 Avg_loss: 0.18975180238485337 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 690 Avg_loss: 0.18950944840908052 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 691 Avg_loss: 0.18929339349269866 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 692 Avg_loss: 0.1890524536371231 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 693 Avg_loss: 0.18879076540470124 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 694 Avg_loss: 0.18853293508291244 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 695 Avg_loss: 0.1883690193295479 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 696 Avg_loss: 0.18815604150295256 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 697 Avg_loss: 0.18791599273681642 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 698 Avg_loss: 0.18768985867500304 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 699 Avg_loss: 0.18735162913799286 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 700 Avg_loss: 0.18711143881082534 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 701 Avg_loss: 0.18685131520032883 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 702 Avg_loss: 0.18662700951099395 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 703 Avg_loss: 0.18630285561084747 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 704 Avg_loss: 0.18618060350418092 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 705 Avg_loss: 0.18622851073741914 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 706 Avg_loss: 0.18603300899267197 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 707 Avg_loss: 0.18557704538106917 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 708 Avg_loss: 0.18526460081338883 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 709 Avg_loss: 0.18564614355564119 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 710 Avg_loss: 0.1968461111187935 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 711 Avg_loss: 0.2641431614756584 training accuracy: 0.9875 test accuracy: 0.30612244897959184\n",
      "Epoch: 712 Avg_loss: 0.6134385257959366 training accuracy: 0.88125 test accuracy: 0.272108843537415\n",
      "Epoch: 713 Avg_loss: 1.2351378440856933 training accuracy: 0.8375 test accuracy: 0.2653061224489796\n",
      "Epoch: 714 Avg_loss: 1.4456132769584655 training accuracy: 0.85 test accuracy: 0.2585034013605442\n",
      "Epoch: 715 Avg_loss: 1.3912274360656738 training accuracy: 0.94375 test accuracy: 0.2857142857142857\n",
      "Epoch: 716 Avg_loss: 1.2812106609344482 training accuracy: 0.965625 test accuracy: 0.2653061224489796\n",
      "Epoch: 717 Avg_loss: 1.121980655193329 training accuracy: 0.978125 test accuracy: 0.2653061224489796\n",
      "Epoch: 718 Avg_loss: 0.9503968179225921 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 719 Avg_loss: 0.8243780136108398 training accuracy: 0.99375 test accuracy: 0.2585034013605442\n",
      "Epoch: 720 Avg_loss: 0.7981321752071381 training accuracy: 0.984375 test accuracy: 0.23129251700680273\n",
      "Epoch: 721 Avg_loss: 0.747412258386612 training accuracy: 0.990625 test accuracy: 0.29931972789115646\n",
      "Epoch: 722 Avg_loss: 0.7657347917556763 training accuracy: 0.9875 test accuracy: 0.2108843537414966\n",
      "Epoch: 723 Avg_loss: 0.7296013474464417 training accuracy: 0.996875 test accuracy: 0.23129251700680273\n",
      "Epoch: 724 Avg_loss: 0.6840968310832978 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 725 Avg_loss: 0.6261831164360047 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 726 Avg_loss: 0.5707089304924011 training accuracy: 1.0 test accuracy: 0.23129251700680273\n",
      "Epoch: 727 Avg_loss: 0.519553256034851 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 728 Avg_loss: 0.47597930431365965 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 729 Avg_loss: 0.4405318647623062 training accuracy: 1.0 test accuracy: 0.19727891156462585\n",
      "Epoch: 730 Avg_loss: 0.4113103300333023 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 731 Avg_loss: 0.38719834983348844 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 732 Avg_loss: 0.36689983308315277 training accuracy: 1.0 test accuracy: 0.2108843537414966\n",
      "Epoch: 733 Avg_loss: 0.3493774265050888 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 734 Avg_loss: 0.33404835760593415 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 735 Avg_loss: 0.320639044046402 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 736 Avg_loss: 0.3096459686756134 training accuracy: 1.0 test accuracy: 0.21768707482993196\n",
      "Epoch: 737 Avg_loss: 0.29988974034786225 training accuracy: 1.0 test accuracy: 0.22448979591836735\n",
      "Epoch: 738 Avg_loss: 0.29017082452774046 training accuracy: 1.0 test accuracy: 0.23809523809523808\n",
      "Epoch: 739 Avg_loss: 0.28126390278339386 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 740 Avg_loss: 0.2734397679567337 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 741 Avg_loss: 0.2665668696165085 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 742 Avg_loss: 0.26349622905254366 training accuracy: 1.0 test accuracy: 0.24489795918367346\n",
      "Epoch: 743 Avg_loss: 0.2599658936262131 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 744 Avg_loss: 0.2541247621178627 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 745 Avg_loss: 0.24776933193206788 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 746 Avg_loss: 0.24211843609809874 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 747 Avg_loss: 0.2375609651207924 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 748 Avg_loss: 0.23377876728773117 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 749 Avg_loss: 0.23271974474191665 training accuracy: 1.0 test accuracy: 0.25170068027210885\n",
      "Epoch: 750 Avg_loss: 0.23117849677801133 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 751 Avg_loss: 0.22763800173997878 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 752 Avg_loss: 0.22386341094970702 training accuracy: 1.0 test accuracy: 0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 753 Avg_loss: 0.22065118253231047 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 754 Avg_loss: 0.21812162101268767 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 755 Avg_loss: 0.21596908271312715 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 756 Avg_loss: 0.21521449089050293 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 757 Avg_loss: 0.21441908478736876 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 758 Avg_loss: 0.21244317889213563 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 759 Avg_loss: 0.21027208417654036 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 760 Avg_loss: 0.20834876596927643 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 761 Avg_loss: 0.20688214153051376 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 762 Avg_loss: 0.20560024976730346 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 763 Avg_loss: 0.20468421280384064 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 764 Avg_loss: 0.20371938347816468 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 765 Avg_loss: 0.20270270705223084 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 766 Avg_loss: 0.2016325294971466 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 767 Avg_loss: 0.20074461102485658 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 768 Avg_loss: 0.20091672390699386 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 769 Avg_loss: 0.2013249635696411 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 770 Avg_loss: 0.20021217465400695 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 771 Avg_loss: 0.19877720922231673 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 772 Avg_loss: 0.1975533187389374 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 773 Avg_loss: 0.19676571637392043 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 774 Avg_loss: 0.1961985185742378 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 775 Avg_loss: 0.19556782990694047 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 776 Avg_loss: 0.19495387524366378 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 777 Avg_loss: 0.19445715844631195 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 778 Avg_loss: 0.1939137578010559 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 779 Avg_loss: 0.19324614703655243 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 780 Avg_loss: 0.1927218109369278 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 781 Avg_loss: 0.1922251060605049 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 782 Avg_loss: 0.19180018603801727 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 783 Avg_loss: 0.1913064956665039 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 784 Avg_loss: 0.19096942096948624 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 785 Avg_loss: 0.1904982164502144 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 786 Avg_loss: 0.1901300296187401 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 787 Avg_loss: 0.18971968442201614 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 788 Avg_loss: 0.18940917849540712 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 789 Avg_loss: 0.18897662609815596 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 790 Avg_loss: 0.18869828283786774 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 791 Avg_loss: 0.18833719044923783 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 792 Avg_loss: 0.1880447193980217 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 793 Avg_loss: 0.18773000687360764 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 794 Avg_loss: 0.18750009834766387 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 795 Avg_loss: 0.18712179362773895 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 796 Avg_loss: 0.18685566037893295 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 797 Avg_loss: 0.18658937960863115 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 798 Avg_loss: 0.18626732230186463 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 799 Avg_loss: 0.18607858717441558 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 800 Avg_loss: 0.1857869639992714 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 801 Avg_loss: 0.18546007126569747 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 802 Avg_loss: 0.185654416680336 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 803 Avg_loss: 0.18552276492118835 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 804 Avg_loss: 0.18499948382377623 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 805 Avg_loss: 0.18454757034778596 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 806 Avg_loss: 0.18455984443426132 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 807 Avg_loss: 0.18430378884077073 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 808 Avg_loss: 0.18392063677310944 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 809 Avg_loss: 0.1835300162434578 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 810 Avg_loss: 0.18970662504434585 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 811 Avg_loss: 0.19470061510801315 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 812 Avg_loss: 0.1924702987074852 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 813 Avg_loss: 0.18778497278690337 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 814 Avg_loss: 0.18473564833402634 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 815 Avg_loss: 0.183142027258873 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 816 Avg_loss: 0.18238379508256913 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 817 Avg_loss: 0.1819317102432251 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 818 Avg_loss: 0.1881733775138855 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 819 Avg_loss: 0.19008494466543197 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 820 Avg_loss: 0.1888309210538864 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 821 Avg_loss: 0.18518074601888657 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 822 Avg_loss: 0.18287284374237062 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 823 Avg_loss: 0.18163177520036697 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 824 Avg_loss: 0.18087786585092544 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 825 Avg_loss: 0.18038490563631057 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 826 Avg_loss: 0.18390759378671645 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 827 Avg_loss: 0.18913236856460572 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 828 Avg_loss: 0.18743613362312317 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 829 Avg_loss: 0.18338367938995362 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 830 Avg_loss: 0.18086060434579848 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 831 Avg_loss: 0.18011094480752946 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 832 Avg_loss: 0.18056169897317886 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 833 Avg_loss: 0.20614266842603685 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 834 Avg_loss: 0.2395700305700302 training accuracy: 0.996875 test accuracy: 0.30612244897959184\n",
      "Epoch: 835 Avg_loss: 0.35769345462322233 training accuracy: 0.975 test accuracy: 0.23129251700680273\n",
      "Epoch: 836 Avg_loss: 0.7138578593730927 training accuracy: 0.884375 test accuracy: 0.2585034013605442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 837 Avg_loss: 1.1982561230659485 training accuracy: 0.846875 test accuracy: 0.29931972789115646\n",
      "Epoch: 838 Avg_loss: 1.6503527402877807 training accuracy: 0.83125 test accuracy: 0.29931972789115646\n",
      "Epoch: 839 Avg_loss: 1.703976821899414 training accuracy: 0.884375 test accuracy: 0.23809523809523808\n",
      "Epoch: 840 Avg_loss: 1.5280343174934388 training accuracy: 0.90625 test accuracy: 0.2857142857142857\n",
      "Epoch: 841 Avg_loss: 1.3200774788856506 training accuracy: 0.94375 test accuracy: 0.29931972789115646\n",
      "Epoch: 842 Avg_loss: 1.2142262578010559 training accuracy: 0.959375 test accuracy: 0.30612244897959184\n",
      "Epoch: 843 Avg_loss: 1.1159695267677308 training accuracy: 0.96875 test accuracy: 0.29931972789115646\n",
      "Epoch: 844 Avg_loss: 1.0356613397598267 training accuracy: 0.975 test accuracy: 0.2925170068027211\n",
      "Epoch: 845 Avg_loss: 0.9429851710796356 training accuracy: 0.975 test accuracy: 0.25170068027210885\n",
      "Epoch: 846 Avg_loss: 0.885111254453659 training accuracy: 0.971875 test accuracy: 0.2857142857142857\n",
      "Epoch: 847 Avg_loss: 0.8590341329574585 training accuracy: 0.98125 test accuracy: 0.30612244897959184\n",
      "Epoch: 848 Avg_loss: 0.8325052559375763 training accuracy: 0.98125 test accuracy: 0.30612244897959184\n",
      "Epoch: 849 Avg_loss: 0.7671398162841797 training accuracy: 0.9875 test accuracy: 0.2653061224489796\n",
      "Epoch: 850 Avg_loss: 0.6997896492481231 training accuracy: 0.990625 test accuracy: 0.2789115646258503\n",
      "Epoch: 851 Avg_loss: 0.634196275472641 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 852 Avg_loss: 0.5782019913196563 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 853 Avg_loss: 0.534093976020813 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 854 Avg_loss: 0.4952462583780289 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 855 Avg_loss: 0.46193144023418425 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 856 Avg_loss: 0.43363675773143767 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 857 Avg_loss: 0.4094505488872528 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 858 Avg_loss: 0.38801289200782774 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 859 Avg_loss: 0.3695041835308075 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 860 Avg_loss: 0.3532172620296478 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 861 Avg_loss: 0.3387226164340973 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 862 Avg_loss: 0.32618009448051455 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 863 Avg_loss: 0.31454661786556243 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 864 Avg_loss: 0.3042615234851837 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 865 Avg_loss: 0.29488655626773835 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 866 Avg_loss: 0.28627594113349913 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 867 Avg_loss: 0.27861006557941437 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 868 Avg_loss: 0.27209609746932983 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 869 Avg_loss: 0.2658229827880859 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 870 Avg_loss: 0.2602390587329865 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 871 Avg_loss: 0.25506834387779237 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 872 Avg_loss: 0.2503815159201622 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 873 Avg_loss: 0.24607978463172914 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 874 Avg_loss: 0.2420979380607605 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 875 Avg_loss: 0.23849849551916122 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 876 Avg_loss: 0.2351992517709732 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 877 Avg_loss: 0.2321774408221245 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 878 Avg_loss: 0.22941796928644181 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 879 Avg_loss: 0.22688244432210922 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 880 Avg_loss: 0.22459927052259446 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 881 Avg_loss: 0.2224529966711998 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 882 Avg_loss: 0.22045185416936874 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 883 Avg_loss: 0.21900915652513503 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 884 Avg_loss: 0.21737006306648254 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 885 Avg_loss: 0.21583823263645172 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 886 Avg_loss: 0.21427974104881287 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 887 Avg_loss: 0.2128787785768509 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 888 Avg_loss: 0.2115113005042076 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 889 Avg_loss: 0.21024069637060167 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 890 Avg_loss: 0.20907904654741288 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 891 Avg_loss: 0.2080455392599106 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 892 Avg_loss: 0.20701891630887986 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 893 Avg_loss: 0.20630138218402863 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 894 Avg_loss: 0.20547811239957808 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 895 Avg_loss: 0.20465216487646104 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 896 Avg_loss: 0.2036973923444748 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 897 Avg_loss: 0.20290872752666472 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 898 Avg_loss: 0.2021068125963211 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 899 Avg_loss: 0.2014230892062187 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 900 Avg_loss: 0.2007440760731697 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 901 Avg_loss: 0.2001671627163887 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 902 Avg_loss: 0.19955476969480515 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 903 Avg_loss: 0.19902798384428025 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 904 Avg_loss: 0.19843535423278807 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 905 Avg_loss: 0.197966967523098 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 906 Avg_loss: 0.19744619429111482 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 907 Avg_loss: 0.19698851257562638 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 908 Avg_loss: 0.19650846123695373 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 909 Avg_loss: 0.19610778540372847 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 910 Avg_loss: 0.1956479087471962 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 911 Avg_loss: 0.19521004110574722 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 912 Avg_loss: 0.1947937622666359 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 913 Avg_loss: 0.19445165991783142 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 914 Avg_loss: 0.19449953287839888 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 915 Avg_loss: 0.194280144572258 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 916 Avg_loss: 0.193832665681839 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 917 Avg_loss: 0.19327515065670015 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 918 Avg_loss: 0.19264811724424363 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 919 Avg_loss: 0.1922604039311409 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 920 Avg_loss: 0.1919032484292984 training accuracy: 1.0 test accuracy: 0.30612244897959184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 921 Avg_loss: 0.19158301502466202 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 922 Avg_loss: 0.19139488488435746 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 923 Avg_loss: 0.1910160228610039 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 924 Avg_loss: 0.19064417332410813 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 925 Avg_loss: 0.19138916879892348 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 926 Avg_loss: 0.19162225276231765 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 927 Avg_loss: 0.19068729728460312 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 928 Avg_loss: 0.18976373374462127 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 929 Avg_loss: 0.18912527710199356 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 930 Avg_loss: 0.19020146876573563 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 931 Avg_loss: 0.19109487533569336 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 932 Avg_loss: 0.19012105017900466 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 933 Avg_loss: 0.18874189406633377 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 934 Avg_loss: 0.18791612535715102 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 935 Avg_loss: 0.20179699957370759 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 936 Avg_loss: 0.255571773648262 training accuracy: 0.99375 test accuracy: 0.3469387755102041\n",
      "Epoch: 937 Avg_loss: 0.45926507711410525 training accuracy: 0.95625 test accuracy: 0.3333333333333333\n",
      "Epoch: 938 Avg_loss: 0.8688633143901825 training accuracy: 0.878125 test accuracy: 0.2925170068027211\n",
      "Epoch: 939 Avg_loss: 1.1689433693885802 training accuracy: 0.896875 test accuracy: 0.272108843537415\n",
      "Epoch: 940 Avg_loss: 1.260463798046112 training accuracy: 0.921875 test accuracy: 0.272108843537415\n",
      "Epoch: 941 Avg_loss: 1.2176621198654174 training accuracy: 0.946875 test accuracy: 0.2925170068027211\n",
      "Epoch: 942 Avg_loss: 1.1529941797256469 training accuracy: 0.9625 test accuracy: 0.30612244897959184\n",
      "Epoch: 943 Avg_loss: 1.097671389579773 training accuracy: 0.96875 test accuracy: 0.30612244897959184\n",
      "Epoch: 944 Avg_loss: 1.027843576669693 training accuracy: 0.96875 test accuracy: 0.29931972789115646\n",
      "Epoch: 945 Avg_loss: 0.9554324984550476 training accuracy: 0.984375 test accuracy: 0.29931972789115646\n",
      "Epoch: 946 Avg_loss: 0.9203710854053497 training accuracy: 0.98125 test accuracy: 0.2925170068027211\n",
      "Epoch: 947 Avg_loss: 0.8705723285675049 training accuracy: 0.990625 test accuracy: 0.3197278911564626\n",
      "Epoch: 948 Avg_loss: 0.806533795595169 training accuracy: 0.99375 test accuracy: 0.3401360544217687\n",
      "Epoch: 949 Avg_loss: 0.7349936425685882 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 950 Avg_loss: 0.6691981852054596 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 951 Avg_loss: 0.6113972842693329 training accuracy: 0.996875 test accuracy: 0.35374149659863946\n",
      "Epoch: 952 Avg_loss: 0.56316277384758 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 953 Avg_loss: 0.5208525836467743 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 954 Avg_loss: 0.4854250818490982 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 955 Avg_loss: 0.4550861924886703 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 956 Avg_loss: 0.42876279950141905 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 957 Avg_loss: 0.4057654768228531 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 958 Avg_loss: 0.3856791704893112 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 959 Avg_loss: 0.36788263618946077 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 960 Avg_loss: 0.352092382311821 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 961 Avg_loss: 0.3380755454301834 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 962 Avg_loss: 0.32562997937202454 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 963 Avg_loss: 0.3143615126609802 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 964 Avg_loss: 0.30423246026039125 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 965 Avg_loss: 0.29515906274318693 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 966 Avg_loss: 0.28702822625637053 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 967 Avg_loss: 0.2796343296766281 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 968 Avg_loss: 0.2729363054037094 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 969 Avg_loss: 0.26685264706611633 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 970 Avg_loss: 0.2612901657819748 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 971 Avg_loss: 0.2562811285257339 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 972 Avg_loss: 0.25165788531303407 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 973 Avg_loss: 0.24746638536453247 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 974 Avg_loss: 0.2435310423374176 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 975 Avg_loss: 0.23988371938467026 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 976 Avg_loss: 0.23663500994443892 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 977 Avg_loss: 0.23365430533885956 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 978 Avg_loss: 0.23093661963939666 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 979 Avg_loss: 0.22842690199613572 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 980 Avg_loss: 0.2261016473174095 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 981 Avg_loss: 0.22397159785032272 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 982 Avg_loss: 0.22197443395853042 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 983 Avg_loss: 0.22012408673763276 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 984 Avg_loss: 0.2183508813381195 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 985 Avg_loss: 0.21679193377494813 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 986 Avg_loss: 0.21528251320123673 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 987 Avg_loss: 0.21386061012744903 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 988 Avg_loss: 0.21267923414707185 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 989 Avg_loss: 0.21165686398744582 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 990 Avg_loss: 0.21044195145368577 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 991 Avg_loss: 0.2092716544866562 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 992 Avg_loss: 0.209103824198246 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 993 Avg_loss: 0.21051526367664336 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 994 Avg_loss: 0.20923045724630357 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 995 Avg_loss: 0.2070521220564842 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 996 Avg_loss: 0.20545727014541626 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 997 Avg_loss: 0.20432681292295457 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 998 Avg_loss: 0.20352036654949188 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 999 Avg_loss: 0.20282368063926698 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1000 Avg_loss: 0.202157661318779 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1001 Avg_loss: 0.20161046981811523 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1002 Avg_loss: 0.20100909173488618 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1003 Avg_loss: 0.20024232119321822 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1004 Avg_loss: 0.19945768415927886 training accuracy: 1.0 test accuracy: 0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1005 Avg_loss: 0.1988963782787323 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1006 Avg_loss: 0.1983692541718483 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1007 Avg_loss: 0.19789907485246658 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1008 Avg_loss: 0.1974102646112442 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1009 Avg_loss: 0.1969558209180832 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1010 Avg_loss: 0.19652439504861832 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1011 Avg_loss: 0.1961288034915924 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1012 Avg_loss: 0.19573182612657547 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1013 Avg_loss: 0.19528164118528366 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1014 Avg_loss: 0.19513716995716096 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1015 Avg_loss: 0.19541703760623932 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1016 Avg_loss: 0.19566874504089354 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1017 Avg_loss: 0.1950533375144005 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1018 Avg_loss: 0.19412553906440735 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1019 Avg_loss: 0.1934424787759781 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1020 Avg_loss: 0.19338795393705369 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1021 Avg_loss: 0.19392099976539612 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1022 Avg_loss: 0.1933644101023674 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1023 Avg_loss: 0.19242511987686156 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1024 Avg_loss: 0.19175407141447068 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1025 Avg_loss: 0.19133977890014647 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1026 Avg_loss: 0.19101244658231736 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1027 Avg_loss: 0.19070726931095122 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1028 Avg_loss: 0.190437613427639 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1029 Avg_loss: 0.19017282575368882 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1030 Avg_loss: 0.1898968920111656 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1031 Avg_loss: 0.18967037349939347 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1032 Avg_loss: 0.18941597491502762 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1033 Avg_loss: 0.1891256958246231 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1034 Avg_loss: 0.18928875178098678 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1035 Avg_loss: 0.19032699912786483 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1036 Avg_loss: 0.18972127437591552 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1037 Avg_loss: 0.18864858895540237 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1038 Avg_loss: 0.18776954412460328 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1039 Avg_loss: 0.18734976947307586 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1040 Avg_loss: 0.1873753026127815 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1041 Avg_loss: 0.1878867045044899 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1042 Avg_loss: 0.18735965639352797 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1043 Avg_loss: 0.18659955710172654 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1044 Avg_loss: 0.1859976217150688 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1045 Avg_loss: 0.1859690248966217 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1046 Avg_loss: 0.1862366735935211 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1047 Avg_loss: 0.18578780740499495 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1048 Avg_loss: 0.18528392761945725 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1049 Avg_loss: 0.18478296101093292 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1050 Avg_loss: 0.1871417224407196 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1051 Avg_loss: 0.19485743194818497 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1052 Avg_loss: 0.20001018643379212 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1053 Avg_loss: 0.19506571143865586 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1054 Avg_loss: 0.1894993081688881 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1055 Avg_loss: 0.1861686110496521 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1056 Avg_loss: 0.1845733717083931 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1057 Avg_loss: 0.1847550168633461 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1058 Avg_loss: 0.18527292013168334 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1059 Avg_loss: 0.18480529338121415 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1060 Avg_loss: 0.18428665399551392 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1061 Avg_loss: 0.1832854449748993 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1062 Avg_loss: 0.18270417302846909 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1063 Avg_loss: 0.18242551237344742 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1064 Avg_loss: 0.18437933176755905 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1065 Avg_loss: 0.192259781062603 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1066 Avg_loss: 0.22879114896059036 training accuracy: 0.99375 test accuracy: 0.3333333333333333\n",
      "Epoch: 1067 Avg_loss: 0.4492973104119301 training accuracy: 0.95 test accuracy: 0.2585034013605442\n",
      "Epoch: 1068 Avg_loss: 1.2177578389644623 training accuracy: 0.759375 test accuracy: 0.272108843537415\n",
      "Epoch: 1069 Avg_loss: 1.6462210536003112 training accuracy: 0.821875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1070 Avg_loss: 1.5604223489761353 training accuracy: 0.86875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1071 Avg_loss: 1.4252178907394408 training accuracy: 0.896875 test accuracy: 0.272108843537415\n",
      "Epoch: 1072 Avg_loss: 1.231445574760437 training accuracy: 0.940625 test accuracy: 0.2653061224489796\n",
      "Epoch: 1073 Avg_loss: 1.0665789902210236 training accuracy: 0.96875 test accuracy: 0.25170068027210885\n",
      "Epoch: 1074 Avg_loss: 0.9508845448493958 training accuracy: 0.978125 test accuracy: 0.2653061224489796\n",
      "Epoch: 1075 Avg_loss: 0.9038138270378113 training accuracy: 0.98125 test accuracy: 0.25170068027210885\n",
      "Epoch: 1076 Avg_loss: 0.835411149263382 training accuracy: 0.990625 test accuracy: 0.24489795918367346\n",
      "Epoch: 1077 Avg_loss: 0.7625652611255646 training accuracy: 0.99375 test accuracy: 0.2653061224489796\n",
      "Epoch: 1078 Avg_loss: 0.6896606981754303 training accuracy: 0.99375 test accuracy: 0.2653061224489796\n",
      "Epoch: 1079 Avg_loss: 0.6296992659568786 training accuracy: 0.99375 test accuracy: 0.24489795918367346\n",
      "Epoch: 1080 Avg_loss: 0.5799066722393036 training accuracy: 0.99375 test accuracy: 0.25170068027210885\n",
      "Epoch: 1081 Avg_loss: 0.54024718105793 training accuracy: 0.99375 test accuracy: 0.2653061224489796\n",
      "Epoch: 1082 Avg_loss: 0.510228568315506 training accuracy: 0.99375 test accuracy: 0.2653061224489796\n",
      "Epoch: 1083 Avg_loss: 0.4863625347614288 training accuracy: 0.99375 test accuracy: 0.2585034013605442\n",
      "Epoch: 1084 Avg_loss: 0.46203685998916627 training accuracy: 0.99375 test accuracy: 0.2653061224489796\n",
      "Epoch: 1085 Avg_loss: 0.4399005681276321 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 1086 Avg_loss: 0.4199040949344635 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 1087 Avg_loss: 0.4017032653093338 training accuracy: 0.99375 test accuracy: 0.2925170068027211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1088 Avg_loss: 0.38446587026119233 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 1089 Avg_loss: 0.3683285295963287 training accuracy: 0.996875 test accuracy: 0.2925170068027211\n",
      "Epoch: 1090 Avg_loss: 0.35567894876003264 training accuracy: 0.996875 test accuracy: 0.272108843537415\n",
      "Epoch: 1091 Avg_loss: 0.34909247756004336 training accuracy: 1.0 test accuracy: 0.2585034013605442\n",
      "Epoch: 1092 Avg_loss: 0.3459321975708008 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1093 Avg_loss: 0.3240534454584122 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1094 Avg_loss: 0.3266035795211792 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1095 Avg_loss: 0.30691485702991483 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1096 Avg_loss: 0.2975454658269882 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1097 Avg_loss: 0.3012237846851349 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1098 Avg_loss: 0.3331520348787308 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1099 Avg_loss: 0.31206369400024414 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1100 Avg_loss: 0.289501827955246 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1101 Avg_loss: 0.2731137484312057 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1102 Avg_loss: 0.2645700931549072 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1103 Avg_loss: 0.2585804253816605 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1104 Avg_loss: 0.25858800411224364 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1105 Avg_loss: 0.2670156240463257 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1106 Avg_loss: 0.2635574072599411 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1107 Avg_loss: 0.2528443083167076 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1108 Avg_loss: 0.24544245153665542 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1109 Avg_loss: 0.24083177596330643 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1110 Avg_loss: 0.2374107450246811 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1111 Avg_loss: 0.23479717820882798 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1112 Avg_loss: 0.23245059549808503 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1113 Avg_loss: 0.23043100237846376 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1114 Avg_loss: 0.22853973954916001 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1115 Avg_loss: 0.2267598479986191 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1116 Avg_loss: 0.2250899150967598 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1117 Avg_loss: 0.2235603377223015 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1118 Avg_loss: 0.22175553888082505 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1119 Avg_loss: 0.22034194320440292 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1120 Avg_loss: 0.21900599598884582 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1121 Avg_loss: 0.21769490987062454 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1122 Avg_loss: 0.21643227487802505 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1123 Avg_loss: 0.21506999135017396 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1124 Avg_loss: 0.21374498158693314 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1125 Avg_loss: 0.21264055073261262 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1126 Avg_loss: 0.21150796562433244 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1127 Avg_loss: 0.2105537921190262 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1128 Avg_loss: 0.20966774970293045 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1129 Avg_loss: 0.20891278237104416 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1130 Avg_loss: 0.20803216844797134 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1131 Avg_loss: 0.20726496428251268 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1132 Avg_loss: 0.20652463287115097 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1133 Avg_loss: 0.2057977557182312 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1134 Avg_loss: 0.2051083669066429 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1135 Avg_loss: 0.20443326681852342 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1136 Avg_loss: 0.20373838394880295 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1137 Avg_loss: 0.2032851755619049 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1138 Avg_loss: 0.2026828035712242 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1139 Avg_loss: 0.20211455672979356 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1140 Avg_loss: 0.201479771733284 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1141 Avg_loss: 0.20098164677619934 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1142 Avg_loss: 0.2005259394645691 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1143 Avg_loss: 0.20007769018411636 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1144 Avg_loss: 0.19962556958198546 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1145 Avg_loss: 0.19916673749685287 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1146 Avg_loss: 0.198757503926754 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1147 Avg_loss: 0.1983986586332321 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1148 Avg_loss: 0.1980893909931183 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1149 Avg_loss: 0.19782736897468567 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1150 Avg_loss: 0.19739087522029877 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1151 Avg_loss: 0.19692310690879822 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1152 Avg_loss: 0.1968416690826416 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1153 Avg_loss: 0.1966949701309204 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1154 Avg_loss: 0.19629855901002885 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1155 Avg_loss: 0.19640793204307555 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1156 Avg_loss: 0.19591241776943208 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1157 Avg_loss: 0.19869219958782197 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1158 Avg_loss: 0.20464264303445817 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1159 Avg_loss: 0.2224563628435135 training accuracy: 0.996875 test accuracy: 0.29931972789115646\n",
      "Epoch: 1160 Avg_loss: 0.23982111364603043 training accuracy: 0.99375 test accuracy: 0.272108843537415\n",
      "Epoch: 1161 Avg_loss: 0.33803685903549197 training accuracy: 1.0 test accuracy: 0.272108843537415\n",
      "Epoch: 1162 Avg_loss: 0.2869102329015732 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1163 Avg_loss: 0.27147799730300903 training accuracy: 0.996875 test accuracy: 0.3129251700680272\n",
      "Epoch: 1164 Avg_loss: 0.2629696190357208 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1165 Avg_loss: 0.28177388310432433 training accuracy: 0.996875 test accuracy: 0.36054421768707484\n",
      "Epoch: 1166 Avg_loss: 0.3763046830892563 training accuracy: 0.984375 test accuracy: 0.2925170068027211\n",
      "Epoch: 1167 Avg_loss: 0.5853565216064454 training accuracy: 0.975 test accuracy: 0.2857142857142857\n",
      "Epoch: 1168 Avg_loss: 0.9693597018718719 training accuracy: 0.9 test accuracy: 0.2653061224489796\n",
      "Epoch: 1169 Avg_loss: 1.2435284376144409 training accuracy: 0.878125 test accuracy: 0.272108843537415\n",
      "Epoch: 1170 Avg_loss: 1.2446820855140686 training accuracy: 0.93125 test accuracy: 0.3129251700680272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1171 Avg_loss: 1.179998016357422 training accuracy: 0.959375 test accuracy: 0.2925170068027211\n",
      "Epoch: 1172 Avg_loss: 1.0638394474983215 training accuracy: 0.971875 test accuracy: 0.3129251700680272\n",
      "Epoch: 1173 Avg_loss: 0.9612888395786285 training accuracy: 0.984375 test accuracy: 0.32653061224489793\n",
      "Epoch: 1174 Avg_loss: 0.8932323276996612 training accuracy: 0.98125 test accuracy: 0.2857142857142857\n",
      "Epoch: 1175 Avg_loss: 0.828607153892517 training accuracy: 0.984375 test accuracy: 0.29931972789115646\n",
      "Epoch: 1176 Avg_loss: 0.7604131400585175 training accuracy: 0.99375 test accuracy: 0.2925170068027211\n",
      "Epoch: 1177 Avg_loss: 0.7279495596885681 training accuracy: 0.99375 test accuracy: 0.29931972789115646\n",
      "Epoch: 1178 Avg_loss: 0.71160808801651 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1179 Avg_loss: 0.6798560798168183 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1180 Avg_loss: 0.6345299363136292 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1181 Avg_loss: 0.5884839951992035 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1182 Avg_loss: 0.5479572832584381 training accuracy: 1.0 test accuracy: 0.2653061224489796\n",
      "Epoch: 1183 Avg_loss: 0.5122708559036255 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1184 Avg_loss: 0.481426814198494 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1185 Avg_loss: 0.4546524673700333 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1186 Avg_loss: 0.431038498878479 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1187 Avg_loss: 0.4098974496126175 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1188 Avg_loss: 0.3909481704235077 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1189 Avg_loss: 0.3739695638418198 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1190 Avg_loss: 0.358757358789444 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1191 Avg_loss: 0.34492875933647155 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1192 Avg_loss: 0.33246547877788546 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1193 Avg_loss: 0.3212065815925598 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1194 Avg_loss: 0.31094667315483093 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1195 Avg_loss: 0.3015775978565216 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1196 Avg_loss: 0.29309241771697997 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1197 Avg_loss: 0.2854006618261337 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1198 Avg_loss: 0.2783610999584198 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1199 Avg_loss: 0.2718947947025299 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1200 Avg_loss: 0.26591902375221255 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1201 Avg_loss: 0.26036510765552523 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1202 Avg_loss: 0.25527780652046206 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1203 Avg_loss: 0.25066935569047927 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1204 Avg_loss: 0.2464177206158638 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1205 Avg_loss: 0.24252381026744843 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1206 Avg_loss: 0.23895522505044936 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1207 Avg_loss: 0.2356530174612999 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1208 Avg_loss: 0.23262381851673125 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1209 Avg_loss: 0.22981596142053604 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1210 Avg_loss: 0.227215938270092 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1211 Avg_loss: 0.22480553090572358 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1212 Avg_loss: 0.22257930040359497 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1213 Avg_loss: 0.2204963430762291 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1214 Avg_loss: 0.2185753270983696 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1215 Avg_loss: 0.21675710380077362 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1216 Avg_loss: 0.2150871530175209 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1217 Avg_loss: 0.2135558933019638 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1218 Avg_loss: 0.21209881454706192 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1219 Avg_loss: 0.2106446623802185 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1220 Avg_loss: 0.20937311202287673 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1221 Avg_loss: 0.20822602063417434 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1222 Avg_loss: 0.20712009370326995 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1223 Avg_loss: 0.20610513538122177 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1224 Avg_loss: 0.20512900203466417 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1225 Avg_loss: 0.20421800017356873 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1226 Avg_loss: 0.20336492359638214 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1227 Avg_loss: 0.20255538076162338 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1228 Avg_loss: 0.20181146562099456 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1229 Avg_loss: 0.2011249303817749 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1230 Avg_loss: 0.20047917515039443 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1231 Avg_loss: 0.19984491616487504 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1232 Avg_loss: 0.19925384521484374 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1233 Avg_loss: 0.19868826419115065 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1234 Avg_loss: 0.19814273566007615 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1235 Avg_loss: 0.19763091653585435 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1236 Avg_loss: 0.19715443700551988 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1237 Avg_loss: 0.19669707417488097 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1238 Avg_loss: 0.1962534010410309 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1239 Avg_loss: 0.1958355575799942 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1240 Avg_loss: 0.1954111009836197 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1241 Avg_loss: 0.19500758945941926 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1242 Avg_loss: 0.19459719359874725 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1243 Avg_loss: 0.19421219527721406 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1244 Avg_loss: 0.19382798075675964 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1245 Avg_loss: 0.19345737397670745 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1246 Avg_loss: 0.19310341477394105 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1247 Avg_loss: 0.19275826811790467 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1248 Avg_loss: 0.19243918657302855 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1249 Avg_loss: 0.19212482422590255 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1250 Avg_loss: 0.1918235719203949 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1251 Avg_loss: 0.19153342247009278 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1252 Avg_loss: 0.19125380367040634 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1253 Avg_loss: 0.1909734383225441 training accuracy: 1.0 test accuracy: 0.32653061224489793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1254 Avg_loss: 0.19068578779697418 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1255 Avg_loss: 0.1904439941048622 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1256 Avg_loss: 0.1901937335729599 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1257 Avg_loss: 0.18995485156774522 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1258 Avg_loss: 0.18970258980989457 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1259 Avg_loss: 0.18948111087083816 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1260 Avg_loss: 0.1892348051071167 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1261 Avg_loss: 0.18899902552366257 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1262 Avg_loss: 0.18876685947179794 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1263 Avg_loss: 0.18854817897081375 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1264 Avg_loss: 0.18828631788492203 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1265 Avg_loss: 0.18806153833866118 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1266 Avg_loss: 0.1877889081835747 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1267 Avg_loss: 0.18760863244533538 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1268 Avg_loss: 0.18735408931970596 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1269 Avg_loss: 0.1871127590537071 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1270 Avg_loss: 0.18687433749437332 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1271 Avg_loss: 0.18666038364171983 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1272 Avg_loss: 0.1864362895488739 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1273 Avg_loss: 0.18621277958154678 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1274 Avg_loss: 0.1859921172261238 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1275 Avg_loss: 0.1857956424355507 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1276 Avg_loss: 0.18569317162036897 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1277 Avg_loss: 0.18551221638917922 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1278 Avg_loss: 0.18519786596298218 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1279 Avg_loss: 0.18539001643657685 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1280 Avg_loss: 0.18767023086547852 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1281 Avg_loss: 0.18878890573978424 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1282 Avg_loss: 0.18759692162275315 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1283 Avg_loss: 0.18569573909044265 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1284 Avg_loss: 0.1848266139626503 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1285 Avg_loss: 0.18459734320640564 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1286 Avg_loss: 0.18412947803735732 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1287 Avg_loss: 0.18357718586921692 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1288 Avg_loss: 0.1842756524682045 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1289 Avg_loss: 0.18497780561447144 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1290 Avg_loss: 0.18411215394735336 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1291 Avg_loss: 0.18303823918104173 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1292 Avg_loss: 0.18246561884880066 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1293 Avg_loss: 0.19602980315685273 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1294 Avg_loss: 0.29253407269716264 training accuracy: 0.98125 test accuracy: 0.3129251700680272\n",
      "Epoch: 1295 Avg_loss: 0.5891750007867813 training accuracy: 0.94375 test accuracy: 0.272108843537415\n",
      "Epoch: 1296 Avg_loss: 0.9022374868392944 training accuracy: 0.89375 test accuracy: 0.2857142857142857\n",
      "Epoch: 1297 Avg_loss: 1.1385352611541748 training accuracy: 0.884375 test accuracy: 0.3333333333333333\n",
      "Epoch: 1298 Avg_loss: 1.121058464050293 training accuracy: 0.95 test accuracy: 0.3197278911564626\n",
      "Epoch: 1299 Avg_loss: 1.0991266191005706 training accuracy: 0.94375 test accuracy: 0.2857142857142857\n",
      "Epoch: 1300 Avg_loss: 1.040582972764969 training accuracy: 0.9625 test accuracy: 0.3469387755102041\n",
      "Epoch: 1301 Avg_loss: 1.033810293674469 training accuracy: 0.953125 test accuracy: 0.3197278911564626\n",
      "Epoch: 1302 Avg_loss: 1.0363813161849975 training accuracy: 0.9375 test accuracy: 0.2585034013605442\n",
      "Epoch: 1303 Avg_loss: 0.9735930562019348 training accuracy: 0.978125 test accuracy: 0.2925170068027211\n",
      "Epoch: 1304 Avg_loss: 0.9330347001552581 training accuracy: 0.9875 test accuracy: 0.2857142857142857\n",
      "Epoch: 1305 Avg_loss: 0.8449995219707489 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 1306 Avg_loss: 0.7682657361030578 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1307 Avg_loss: 0.7098560869693756 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1308 Avg_loss: 0.6557985186576843 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1309 Avg_loss: 0.6085501968860626 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1310 Avg_loss: 0.5678459763526916 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1311 Avg_loss: 0.5329756081104279 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1312 Avg_loss: 0.5028212696313858 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1313 Avg_loss: 0.4762797623872757 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1314 Avg_loss: 0.4530136674642563 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1315 Avg_loss: 0.4319992184638977 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1316 Avg_loss: 0.41304813623428344 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1317 Avg_loss: 0.39595607221126555 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1318 Avg_loss: 0.38076291680336 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1319 Avg_loss: 0.36666435897350313 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1320 Avg_loss: 0.3537974447011948 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1321 Avg_loss: 0.3420482337474823 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1322 Avg_loss: 0.33158853054046633 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1323 Avg_loss: 0.3216226249933243 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1324 Avg_loss: 0.3124481558799744 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1325 Avg_loss: 0.303913825750351 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1326 Avg_loss: 0.29611222743988036 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1327 Avg_loss: 0.2889497071504593 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1328 Avg_loss: 0.2823293924331665 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1329 Avg_loss: 0.27620663940906526 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1330 Avg_loss: 0.2704672396183014 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1331 Avg_loss: 0.2651858925819397 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1332 Avg_loss: 0.2602408677339554 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1333 Avg_loss: 0.25570273101329805 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1334 Avg_loss: 0.2514657318592072 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1335 Avg_loss: 0.2475608304142952 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1336 Avg_loss: 0.24391143321990966 training accuracy: 1.0 test accuracy: 0.3129251700680272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1337 Avg_loss: 0.24055210500955582 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1338 Avg_loss: 0.23738736510276795 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1339 Avg_loss: 0.23448707461357116 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1340 Avg_loss: 0.23172737509012223 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1341 Avg_loss: 0.22920612394809722 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1342 Avg_loss: 0.22678131461143494 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1343 Avg_loss: 0.2245654582977295 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1344 Avg_loss: 0.22243380844593047 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1345 Avg_loss: 0.22050208002328872 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1346 Avg_loss: 0.21864173859357833 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1347 Avg_loss: 0.21695904433727264 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1348 Avg_loss: 0.21534159481525422 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1349 Avg_loss: 0.21385685056447984 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1350 Avg_loss: 0.21241926848888398 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1351 Avg_loss: 0.21113072633743285 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1352 Avg_loss: 0.20987567752599717 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1353 Avg_loss: 0.20874714106321335 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1354 Avg_loss: 0.20759804993867875 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1355 Avg_loss: 0.20660565048456192 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1356 Avg_loss: 0.2055915728211403 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1357 Avg_loss: 0.2047166034579277 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1358 Avg_loss: 0.20381672084331512 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1359 Avg_loss: 0.20303616523742676 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1360 Avg_loss: 0.2022449791431427 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1361 Avg_loss: 0.20156174004077912 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1362 Avg_loss: 0.20084104388952256 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1363 Avg_loss: 0.20025518536567688 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1364 Avg_loss: 0.19960844218730928 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1365 Avg_loss: 0.19908447563648224 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1366 Avg_loss: 0.19847476482391357 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1367 Avg_loss: 0.19800586253404617 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1368 Avg_loss: 0.1974649727344513 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1369 Avg_loss: 0.19698773324489594 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1370 Avg_loss: 0.19650933593511583 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1371 Avg_loss: 0.19608593434095384 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1372 Avg_loss: 0.19560789167881013 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1373 Avg_loss: 0.19524290710687636 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1374 Avg_loss: 0.1947893425822258 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1375 Avg_loss: 0.19437628984451294 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1376 Avg_loss: 0.1940867066383362 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1377 Avg_loss: 0.1936785638332367 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1378 Avg_loss: 0.19324567019939423 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1379 Avg_loss: 0.19365231990814208 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1380 Avg_loss: 0.19360981732606888 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1381 Avg_loss: 0.19280767887830735 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1382 Avg_loss: 0.19206532984972 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1383 Avg_loss: 0.19154721200466157 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1384 Avg_loss: 0.21748003363609314 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1385 Avg_loss: 0.23035913109779357 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1386 Avg_loss: 0.2293331116437912 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1387 Avg_loss: 0.2174371600151062 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1388 Avg_loss: 0.20707428753376006 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1389 Avg_loss: 0.20027540177106856 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1390 Avg_loss: 0.1960476443171501 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1391 Avg_loss: 0.19353368133306503 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1392 Avg_loss: 0.19201749712228774 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1393 Avg_loss: 0.19079191535711287 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1394 Avg_loss: 0.1897479847073555 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1395 Avg_loss: 0.1889428660273552 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1396 Avg_loss: 0.18843018263578415 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1397 Avg_loss: 0.18797528892755508 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1398 Avg_loss: 0.1875889539718628 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1399 Avg_loss: 0.1871871367096901 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1400 Avg_loss: 0.18699259012937547 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1401 Avg_loss: 0.1867483988404274 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1402 Avg_loss: 0.18645493388175965 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1403 Avg_loss: 0.18607307374477386 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1404 Avg_loss: 0.18569265455007553 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1405 Avg_loss: 0.18545853197574616 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1406 Avg_loss: 0.1852638989686966 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1407 Avg_loss: 0.1849547877907753 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1408 Avg_loss: 0.18475986868143082 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1409 Avg_loss: 0.18488679677248002 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1410 Avg_loss: 0.1845605731010437 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1411 Avg_loss: 0.18410273343324662 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1412 Avg_loss: 0.18381731063127518 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1413 Avg_loss: 0.18359304666519166 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1414 Avg_loss: 0.1832720920443535 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1415 Avg_loss: 0.1829748421907425 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1416 Avg_loss: 0.1828774705529213 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1417 Avg_loss: 0.18302252292633056 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1418 Avg_loss: 0.18264910876750945 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1419 Avg_loss: 0.18221316784620284 training accuracy: 1.0 test accuracy: 0.35374149659863946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1420 Avg_loss: 0.18185979574918748 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1421 Avg_loss: 0.18171485215425492 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1422 Avg_loss: 0.1814484030008316 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1423 Avg_loss: 0.1812574565410614 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1424 Avg_loss: 0.18102939128875734 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1425 Avg_loss: 0.1808657392859459 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1426 Avg_loss: 0.18070126622915267 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1427 Avg_loss: 0.18071327805519105 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1428 Avg_loss: 0.1806134343147278 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1429 Avg_loss: 0.18064916878938675 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1430 Avg_loss: 0.180487722158432 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1431 Avg_loss: 0.18059455454349518 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1432 Avg_loss: 0.18002821058034896 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1433 Avg_loss: 0.180678291618824 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1434 Avg_loss: 0.18331473916769028 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1435 Avg_loss: 0.1919281601905823 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1436 Avg_loss: 0.19993736892938613 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1437 Avg_loss: 0.21228787451982498 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1438 Avg_loss: 0.22341936826705933 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1439 Avg_loss: 0.23042300045490266 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1440 Avg_loss: 0.2628407791256905 training accuracy: 0.99375 test accuracy: 0.36054421768707484\n",
      "Epoch: 1441 Avg_loss: 0.35595586001873014 training accuracy: 0.96875 test accuracy: 0.2585034013605442\n",
      "Epoch: 1442 Avg_loss: 0.8597136616706849 training accuracy: 0.9125 test accuracy: 0.32653061224489793\n",
      "Epoch: 1443 Avg_loss: 1.2538622498512269 training accuracy: 0.9125 test accuracy: 0.2925170068027211\n",
      "Epoch: 1444 Avg_loss: 1.1838103890419007 training accuracy: 0.971875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1445 Avg_loss: 1.0991946518421174 training accuracy: 0.975 test accuracy: 0.3197278911564626\n",
      "Epoch: 1446 Avg_loss: 0.9213391304016113 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1447 Avg_loss: 0.8392050802707672 training accuracy: 0.984375 test accuracy: 0.272108843537415\n",
      "Epoch: 1448 Avg_loss: 0.783644288778305 training accuracy: 0.9875 test accuracy: 0.29931972789115646\n",
      "Epoch: 1449 Avg_loss: 0.7446781039237976 training accuracy: 0.990625 test accuracy: 0.3469387755102041\n",
      "Epoch: 1450 Avg_loss: 0.7138424634933471 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1451 Avg_loss: 0.6991660296916962 training accuracy: 0.9875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1452 Avg_loss: 0.6860813498497009 training accuracy: 0.990625 test accuracy: 0.3129251700680272\n",
      "Epoch: 1453 Avg_loss: 0.6626330018043518 training accuracy: 0.996875 test accuracy: 0.2653061224489796\n",
      "Epoch: 1454 Avg_loss: 0.6251998543739319 training accuracy: 1.0 test accuracy: 0.2789115646258503\n",
      "Epoch: 1455 Avg_loss: 0.5846333503723145 training accuracy: 1.0 test accuracy: 0.2857142857142857\n",
      "Epoch: 1456 Avg_loss: 0.5373982548713684 training accuracy: 1.0 test accuracy: 0.2925170068027211\n",
      "Epoch: 1457 Avg_loss: 0.4912391096353531 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1458 Avg_loss: 0.45222354829311373 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1459 Avg_loss: 0.4206919252872467 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1460 Avg_loss: 0.3950769901275635 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1461 Avg_loss: 0.3733355075120926 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1462 Avg_loss: 0.35476048588752745 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1463 Avg_loss: 0.33846894204616546 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1464 Avg_loss: 0.3241042971611023 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1465 Avg_loss: 0.311445426940918 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1466 Avg_loss: 0.3002122759819031 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1467 Avg_loss: 0.2900737404823303 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1468 Avg_loss: 0.2810125231742859 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1469 Avg_loss: 0.27287346720695493 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1470 Avg_loss: 0.26549296379089354 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1471 Avg_loss: 0.25885638892650603 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1472 Avg_loss: 0.25279087871313094 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1473 Avg_loss: 0.24736683815717697 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1474 Avg_loss: 0.24237325191497802 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1475 Avg_loss: 0.2378501683473587 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1476 Avg_loss: 0.23371702283620835 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1477 Avg_loss: 0.22993746399879456 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1478 Avg_loss: 0.22643698006868362 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1479 Avg_loss: 0.22312976121902467 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1480 Avg_loss: 0.22009419798851013 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1481 Avg_loss: 0.21735418140888213 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1482 Avg_loss: 0.2148723527789116 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1483 Avg_loss: 0.21257149875164033 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1484 Avg_loss: 0.21048059463500976 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1485 Avg_loss: 0.20852073282003403 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1486 Avg_loss: 0.20669177621603013 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1487 Avg_loss: 0.20496461689472198 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1488 Avg_loss: 0.2033616229891777 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1489 Avg_loss: 0.2019152745604515 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1490 Avg_loss: 0.20055511593818665 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1491 Avg_loss: 0.19931627064943314 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1492 Avg_loss: 0.19813756346702577 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1493 Avg_loss: 0.19705704152584075 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1494 Avg_loss: 0.1960243970155716 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1495 Avg_loss: 0.19508924186229706 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1496 Avg_loss: 0.1941911295056343 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1497 Avg_loss: 0.19333462715148925 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1498 Avg_loss: 0.19257828444242478 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1499 Avg_loss: 0.1918237939476967 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1500 Avg_loss: 0.1910621017217636 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1501 Avg_loss: 0.19043964743614197 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1502 Avg_loss: 0.18982587307691573 training accuracy: 1.0 test accuracy: 0.35374149659863946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1503 Avg_loss: 0.18916936218738556 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1504 Avg_loss: 0.1886272221803665 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1505 Avg_loss: 0.18807886093854903 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1506 Avg_loss: 0.1875153049826622 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1507 Avg_loss: 0.18702610731124877 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1508 Avg_loss: 0.18651995658874512 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1509 Avg_loss: 0.18604047149419783 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1510 Avg_loss: 0.18559592515230178 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1511 Avg_loss: 0.18510527014732361 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1512 Avg_loss: 0.18473829329013824 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1513 Avg_loss: 0.18433032631874086 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1514 Avg_loss: 0.18392667323350906 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1515 Avg_loss: 0.18363784551620482 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1516 Avg_loss: 0.18328843712806703 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1517 Avg_loss: 0.18304264694452285 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1518 Avg_loss: 0.1829278439283371 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1519 Avg_loss: 0.1827916607260704 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1520 Avg_loss: 0.18257788568735123 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1521 Avg_loss: 0.18189333230257035 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1522 Avg_loss: 0.18222550451755523 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1523 Avg_loss: 0.18235164135694504 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1524 Avg_loss: 0.18203253895044327 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1525 Avg_loss: 0.18176144361495972 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1526 Avg_loss: 0.1808403566479683 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1527 Avg_loss: 0.18020719885826111 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1528 Avg_loss: 0.17960552871227264 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1529 Avg_loss: 0.2043293908238411 training accuracy: 0.996875 test accuracy: 0.3741496598639456\n",
      "Epoch: 1530 Avg_loss: 0.23013725280761718 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1531 Avg_loss: 0.2486730694770813 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1532 Avg_loss: 0.2860234692692757 training accuracy: 0.990625 test accuracy: 0.29931972789115646\n",
      "Epoch: 1533 Avg_loss: 0.7103636175394058 training accuracy: 0.890625 test accuracy: 0.3197278911564626\n",
      "Epoch: 1534 Avg_loss: 1.011660450696945 training accuracy: 0.9125 test accuracy: 0.2789115646258503\n",
      "Epoch: 1535 Avg_loss: 1.1719449996948241 training accuracy: 0.940625 test accuracy: 0.2925170068027211\n",
      "Epoch: 1536 Avg_loss: 1.075367271900177 training accuracy: 0.96875 test accuracy: 0.2925170068027211\n",
      "Epoch: 1537 Avg_loss: 0.9677370846271515 training accuracy: 0.978125 test accuracy: 0.30612244897959184\n",
      "Epoch: 1538 Avg_loss: 0.9167757511138916 training accuracy: 0.978125 test accuracy: 0.35374149659863946\n",
      "Epoch: 1539 Avg_loss: 0.85887531042099 training accuracy: 0.984375 test accuracy: 0.3741496598639456\n",
      "Epoch: 1540 Avg_loss: 0.8299676358699799 training accuracy: 0.98125 test accuracy: 0.32653061224489793\n",
      "Epoch: 1541 Avg_loss: 0.788644540309906 training accuracy: 0.9875 test accuracy: 0.3197278911564626\n",
      "Epoch: 1542 Avg_loss: 0.7570356488227844 training accuracy: 0.996875 test accuracy: 0.3197278911564626\n",
      "Epoch: 1543 Avg_loss: 0.703610873222351 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1544 Avg_loss: 0.6516092896461487 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1545 Avg_loss: 0.629205447435379 training accuracy: 0.99375 test accuracy: 0.3401360544217687\n",
      "Epoch: 1546 Avg_loss: 0.6153014481067658 training accuracy: 0.996875 test accuracy: 0.35374149659863946\n",
      "Epoch: 1547 Avg_loss: 0.5827440321445465 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1548 Avg_loss: 0.5436777532100677 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1549 Avg_loss: 0.502902626991272 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1550 Avg_loss: 0.4670765221118927 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1551 Avg_loss: 0.43656834959983826 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1552 Avg_loss: 0.41067532896995546 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1553 Avg_loss: 0.3883069962263107 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1554 Avg_loss: 0.36881464421749116 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1555 Avg_loss: 0.3518350630998611 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1556 Avg_loss: 0.3368635058403015 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1557 Avg_loss: 0.32361968159675597 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1558 Avg_loss: 0.31182700097560884 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1559 Avg_loss: 0.30131923854351045 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1560 Avg_loss: 0.2919012397527695 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1561 Avg_loss: 0.28333967328071596 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1562 Avg_loss: 0.27566729187965394 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1563 Avg_loss: 0.2686921119689941 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1564 Avg_loss: 0.26238032579422 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1565 Avg_loss: 0.2566440060734749 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1566 Avg_loss: 0.25138607174158095 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1567 Avg_loss: 0.2465275689959526 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1568 Avg_loss: 0.24183701127767562 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1569 Avg_loss: 0.23751612305641173 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1570 Avg_loss: 0.23364779055118562 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1571 Avg_loss: 0.2300752356648445 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1572 Avg_loss: 0.22680936455726625 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1573 Avg_loss: 0.22381635755300522 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1574 Avg_loss: 0.22105647921562194 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1575 Avg_loss: 0.21852733194828033 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1576 Avg_loss: 0.21614232957363128 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1577 Avg_loss: 0.2139113426208496 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1578 Avg_loss: 0.21184155642986296 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1579 Avg_loss: 0.209974767267704 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1580 Avg_loss: 0.20823222398757935 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1581 Avg_loss: 0.20667522102594377 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1582 Avg_loss: 0.2051532581448555 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1583 Avg_loss: 0.2038828745484352 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1584 Avg_loss: 0.2024388864636421 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1585 Avg_loss: 0.20120700001716613 training accuracy: 1.0 test accuracy: 0.3197278911564626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1586 Avg_loss: 0.200035060942173 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1587 Avg_loss: 0.1989338532090187 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1588 Avg_loss: 0.19789106547832488 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1589 Avg_loss: 0.19692476242780685 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1590 Avg_loss: 0.19601808339357377 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1591 Avg_loss: 0.19517481774091722 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1592 Avg_loss: 0.19436564296483994 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1593 Avg_loss: 0.19359074383974076 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1594 Avg_loss: 0.1928314134478569 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1595 Avg_loss: 0.19211506098508835 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1596 Avg_loss: 0.19142428189516067 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1597 Avg_loss: 0.19071740210056304 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1598 Avg_loss: 0.1901518866419792 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1599 Avg_loss: 0.1899828776717186 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1600 Avg_loss: 0.18961501270532607 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1601 Avg_loss: 0.18874600976705552 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1602 Avg_loss: 0.18804769068956376 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1603 Avg_loss: 0.1876821771264076 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1604 Avg_loss: 0.1885227933526039 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1605 Avg_loss: 0.18894252181053162 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1606 Avg_loss: 0.18743377923965454 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1607 Avg_loss: 0.1862331062555313 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1608 Avg_loss: 0.18547398895025252 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1609 Avg_loss: 0.18510380536317825 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1610 Avg_loss: 0.18578463345766066 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1611 Avg_loss: 0.18605471700429915 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1612 Avg_loss: 0.18494870215654374 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1613 Avg_loss: 0.1839277669787407 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1614 Avg_loss: 0.1832987919449806 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1615 Avg_loss: 0.18305452316999435 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1616 Avg_loss: 0.18466041684150697 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1617 Avg_loss: 0.1853215679526329 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1618 Avg_loss: 0.18372311294078827 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1619 Avg_loss: 0.1822890430688858 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1620 Avg_loss: 0.18139195144176484 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1621 Avg_loss: 0.18081143349409104 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1622 Avg_loss: 0.1806703582406044 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1623 Avg_loss: 0.1825140044093132 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1624 Avg_loss: 0.1832250624895096 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1625 Avg_loss: 0.18173086643218994 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1626 Avg_loss: 0.18034024834632872 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1627 Avg_loss: 0.1794343188405037 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1628 Avg_loss: 0.1788807213306427 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1629 Avg_loss: 0.17877739667892456 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1630 Avg_loss: 0.18034274280071258 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1631 Avg_loss: 0.1808674916625023 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1632 Avg_loss: 0.1796848401427269 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1633 Avg_loss: 0.17843400239944457 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1634 Avg_loss: 0.17780181765556335 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1635 Avg_loss: 0.17727308124303817 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1636 Avg_loss: 0.17716358751058578 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1637 Avg_loss: 0.17853579074144363 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1638 Avg_loss: 0.17908318489789962 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1639 Avg_loss: 0.17804916799068451 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1640 Avg_loss: 0.17692772746086122 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1641 Avg_loss: 0.17620742619037627 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1642 Avg_loss: 0.17565201371908187 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1643 Avg_loss: 0.17555966824293137 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1644 Avg_loss: 0.176667420566082 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1645 Avg_loss: 0.17715762555599213 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1646 Avg_loss: 0.17630120515823364 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1647 Avg_loss: 0.1752822831273079 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1648 Avg_loss: 0.17462983280420302 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1649 Avg_loss: 0.174268040060997 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1650 Avg_loss: 0.17438287585973739 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1651 Avg_loss: 0.17676519602537155 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1652 Avg_loss: 0.17884567528963088 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1653 Avg_loss: 0.1768396645784378 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1654 Avg_loss: 0.17489629089832306 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1655 Avg_loss: 0.1738581880927086 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1656 Avg_loss: 0.1731747195124626 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1657 Avg_loss: 0.17284740507602692 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1658 Avg_loss: 0.17257334738969804 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1659 Avg_loss: 0.1724065735936165 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1660 Avg_loss: 0.17221040278673172 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1661 Avg_loss: 0.1720509335398674 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1662 Avg_loss: 0.17190944105386735 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1663 Avg_loss: 0.17177369445562363 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1664 Avg_loss: 0.1717013880610466 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1665 Avg_loss: 0.1714725002646446 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1666 Avg_loss: 0.1713288888335228 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1667 Avg_loss: 0.1711834266781807 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1668 Avg_loss: 0.17100821286439896 training accuracy: 1.0 test accuracy: 0.3129251700680272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1669 Avg_loss: 0.17088706493377687 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1670 Avg_loss: 0.17074906826019287 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1671 Avg_loss: 0.1706584632396698 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1672 Avg_loss: 0.17045178711414338 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1673 Avg_loss: 0.1706537589430809 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1674 Avg_loss: 0.17151785492897034 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1675 Avg_loss: 0.17105544358491898 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1676 Avg_loss: 0.17079183757305144 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1677 Avg_loss: 0.1706324115395546 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1678 Avg_loss: 0.17069289088249207 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1679 Avg_loss: 0.17129243314266204 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1680 Avg_loss: 0.170632041990757 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1681 Avg_loss: 0.16982004642486573 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1682 Avg_loss: 0.1704711824655533 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1683 Avg_loss: 0.17069671154022217 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1684 Avg_loss: 0.17820126712322235 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1685 Avg_loss: 0.2549453631043434 training accuracy: 0.990625 test accuracy: 0.3129251700680272\n",
      "Epoch: 1686 Avg_loss: 0.5890485435724259 training accuracy: 0.95 test accuracy: 0.2925170068027211\n",
      "Epoch: 1687 Avg_loss: 1.097857815027237 training accuracy: 0.846875 test accuracy: 0.30612244897959184\n",
      "Epoch: 1688 Avg_loss: 1.3122283816337585 training accuracy: 0.859375 test accuracy: 0.3401360544217687\n",
      "Epoch: 1689 Avg_loss: 1.5145671010017394 training accuracy: 0.796875 test accuracy: 0.2925170068027211\n",
      "Epoch: 1690 Avg_loss: 1.4080645799636842 training accuracy: 0.85625 test accuracy: 0.36054421768707484\n",
      "Epoch: 1691 Avg_loss: 1.1948892712593078 training accuracy: 0.940625 test accuracy: 0.2653061224489796\n",
      "Epoch: 1692 Avg_loss: 1.056605327129364 training accuracy: 0.959375 test accuracy: 0.2857142857142857\n",
      "Epoch: 1693 Avg_loss: 0.9335067451000214 training accuracy: 0.98125 test accuracy: 0.3401360544217687\n",
      "Epoch: 1694 Avg_loss: 0.8654976785182953 training accuracy: 0.98125 test accuracy: 0.3401360544217687\n",
      "Epoch: 1695 Avg_loss: 0.7949512124061584 training accuracy: 0.990625 test accuracy: 0.35374149659863946\n",
      "Epoch: 1696 Avg_loss: 0.7847852766513824 training accuracy: 0.98125 test accuracy: 0.3333333333333333\n",
      "Epoch: 1697 Avg_loss: 0.7348135411739349 training accuracy: 0.990625 test accuracy: 0.3197278911564626\n",
      "Epoch: 1698 Avg_loss: 0.6841946482658386 training accuracy: 0.990625 test accuracy: 0.32653061224489793\n",
      "Epoch: 1699 Avg_loss: 0.6266725659370422 training accuracy: 0.99375 test accuracy: 0.3401360544217687\n",
      "Epoch: 1700 Avg_loss: 0.5745329082012176 training accuracy: 0.99375 test accuracy: 0.3333333333333333\n",
      "Epoch: 1701 Avg_loss: 0.5311347365379333 training accuracy: 0.99375 test accuracy: 0.3333333333333333\n",
      "Epoch: 1702 Avg_loss: 0.493528938293457 training accuracy: 0.99375 test accuracy: 0.3333333333333333\n",
      "Epoch: 1703 Avg_loss: 0.4604563355445862 training accuracy: 0.99375 test accuracy: 0.3333333333333333\n",
      "Epoch: 1704 Avg_loss: 0.4326557904481888 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1705 Avg_loss: 0.4089734464883804 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1706 Avg_loss: 0.3880983620882034 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1707 Avg_loss: 0.3702972173690796 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1708 Avg_loss: 0.35438520908355714 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1709 Avg_loss: 0.34027485847473143 training accuracy: 0.996875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1710 Avg_loss: 0.33210186660289764 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1711 Avg_loss: 0.3272416204214096 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1712 Avg_loss: 0.310499382019043 training accuracy: 0.996875 test accuracy: 0.35374149659863946\n",
      "Epoch: 1713 Avg_loss: 0.2982516556978226 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1714 Avg_loss: 0.2907102644443512 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1715 Avg_loss: 0.2900747299194336 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1716 Avg_loss: 0.2816736429929733 training accuracy: 0.996875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1717 Avg_loss: 0.27087523937225344 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1718 Avg_loss: 0.26303990483283995 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1719 Avg_loss: 0.25752548724412916 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1720 Avg_loss: 0.2528503566980362 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1721 Avg_loss: 0.24856991022825242 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1722 Avg_loss: 0.2447507843375206 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1723 Avg_loss: 0.24116506576538085 training accuracy: 0.996875 test accuracy: 0.3197278911564626\n",
      "Epoch: 1724 Avg_loss: 0.2379624366760254 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1725 Avg_loss: 0.2350910484790802 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1726 Avg_loss: 0.2322985753417015 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1727 Avg_loss: 0.2299020692706108 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1728 Avg_loss: 0.22758483290672302 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1729 Avg_loss: 0.22553157657384873 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1730 Avg_loss: 0.22357698827981948 training accuracy: 0.996875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1731 Avg_loss: 0.22182806581258774 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1732 Avg_loss: 0.22013491094112397 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1733 Avg_loss: 0.2184888795018196 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1734 Avg_loss: 0.21702387630939485 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1735 Avg_loss: 0.21557040214538575 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1736 Avg_loss: 0.21399418860673905 training accuracy: 0.996875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1737 Avg_loss: 0.2126576378941536 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1738 Avg_loss: 0.21152541786432266 training accuracy: 0.996875 test accuracy: 0.3197278911564626\n",
      "Epoch: 1739 Avg_loss: 0.21041457504034042 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1740 Avg_loss: 0.20938808768987655 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1741 Avg_loss: 0.20844749510288238 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1742 Avg_loss: 0.2075418248772621 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1743 Avg_loss: 0.20675353556871415 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1744 Avg_loss: 0.20597776472568513 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1745 Avg_loss: 0.20522122979164123 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1746 Avg_loss: 0.20449664294719697 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1747 Avg_loss: 0.20382058173418044 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1748 Avg_loss: 0.20314016491174697 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1749 Avg_loss: 0.20244835466146469 training accuracy: 1.0 test accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1750 Avg_loss: 0.2018576294183731 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1751 Avg_loss: 0.20123905837535858 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1752 Avg_loss: 0.20061311572790147 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1753 Avg_loss: 0.20003274232149124 training accuracy: 0.996875 test accuracy: 0.3469387755102041\n",
      "Epoch: 1754 Avg_loss: 0.19944927245378494 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1755 Avg_loss: 0.1989117369055748 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1756 Avg_loss: 0.19841568619012834 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1757 Avg_loss: 0.19800253957509995 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1758 Avg_loss: 0.1974785178899765 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1759 Avg_loss: 0.19705894142389296 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1760 Avg_loss: 0.19663989990949632 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1761 Avg_loss: 0.19627103209495544 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1762 Avg_loss: 0.1958649694919586 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1763 Avg_loss: 0.19555414319038392 training accuracy: 0.996875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1764 Avg_loss: 0.19512379616498948 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1765 Avg_loss: 0.19474395364522934 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1766 Avg_loss: 0.1943327233195305 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1767 Avg_loss: 0.1940313383936882 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1768 Avg_loss: 0.19381226152181624 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1769 Avg_loss: 0.19335663467645645 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1770 Avg_loss: 0.19304632097482682 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1771 Avg_loss: 0.19274175614118577 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1772 Avg_loss: 0.19251606613397598 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1773 Avg_loss: 0.1921654000878334 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1774 Avg_loss: 0.19192692637443542 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1775 Avg_loss: 0.1917963370680809 training accuracy: 0.996875 test accuracy: 0.3333333333333333\n",
      "Epoch: 1776 Avg_loss: 0.19140136986970901 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1777 Avg_loss: 0.1911488503217697 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1778 Avg_loss: 0.19086170196533203 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1779 Avg_loss: 0.1906025543808937 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1780 Avg_loss: 0.19030775278806686 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1781 Avg_loss: 0.19008589535951614 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1782 Avg_loss: 0.1898081824183464 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1783 Avg_loss: 0.1895734116435051 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1784 Avg_loss: 0.18930411338806152 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1785 Avg_loss: 0.18903738856315613 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1786 Avg_loss: 0.18877796232700347 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1787 Avg_loss: 0.18861262798309325 training accuracy: 0.996875 test accuracy: 0.3197278911564626\n",
      "Epoch: 1788 Avg_loss: 0.18839596658945085 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1789 Avg_loss: 0.18820876330137254 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1790 Avg_loss: 0.18793742656707763 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1791 Avg_loss: 0.18771274387836456 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1792 Avg_loss: 0.18744034469127654 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1793 Avg_loss: 0.18720197379589082 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1794 Avg_loss: 0.18697201758623122 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1795 Avg_loss: 0.1867588460445404 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1796 Avg_loss: 0.18652899712324142 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1797 Avg_loss: 0.1863829404115677 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1798 Avg_loss: 0.18611130267381668 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1799 Avg_loss: 0.18586149215698242 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1800 Avg_loss: 0.18563248664140702 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1801 Avg_loss: 0.1854422315955162 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1802 Avg_loss: 0.18520652055740355 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1803 Avg_loss: 0.1850924476981163 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1804 Avg_loss: 0.1848461613059044 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1805 Avg_loss: 0.18466019332408906 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1806 Avg_loss: 0.18444429337978363 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1807 Avg_loss: 0.1842558816075325 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1808 Avg_loss: 0.1840563163161278 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1809 Avg_loss: 0.18389545679092406 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1810 Avg_loss: 0.18371867686510085 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1811 Avg_loss: 0.1835872858762741 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1812 Avg_loss: 0.1834063708782196 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1813 Avg_loss: 0.183213672041893 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1814 Avg_loss: 0.18327620923519133 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1815 Avg_loss: 0.18407437056303025 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1816 Avg_loss: 0.18366326838731767 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1817 Avg_loss: 0.18293441087007523 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1818 Avg_loss: 0.1824224427342415 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1819 Avg_loss: 0.18373272567987442 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1820 Avg_loss: 0.18737698644399642 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1821 Avg_loss: 0.18756535798311233 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1822 Avg_loss: 0.18476758897304535 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1823 Avg_loss: 0.1828315496444702 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1824 Avg_loss: 0.18184081614017486 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1825 Avg_loss: 0.18957191556692124 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1826 Avg_loss: 0.25725818425416946 training accuracy: 0.99375 test accuracy: 0.2857142857142857\n",
      "Epoch: 1827 Avg_loss: 0.4807177871465683 training accuracy: 0.95625 test accuracy: 0.3401360544217687\n",
      "Epoch: 1828 Avg_loss: 0.9181465268135071 training accuracy: 0.865625 test accuracy: 0.2857142857142857\n",
      "Epoch: 1829 Avg_loss: 1.2441243767738341 training accuracy: 0.84375 test accuracy: 0.3197278911564626\n",
      "Epoch: 1830 Avg_loss: 1.3714224338531493 training accuracy: 0.840625 test accuracy: 0.272108843537415\n",
      "Epoch: 1831 Avg_loss: 1.2580604672431945 training accuracy: 0.915625 test accuracy: 0.2857142857142857\n",
      "Epoch: 1832 Avg_loss: 1.1392752408981324 training accuracy: 0.940625 test accuracy: 0.2653061224489796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1833 Avg_loss: 1.0229355096817017 training accuracy: 0.971875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1834 Avg_loss: 1.001638251543045 training accuracy: 0.95 test accuracy: 0.32653061224489793\n",
      "Epoch: 1835 Avg_loss: 0.9318555414676666 training accuracy: 0.971875 test accuracy: 0.3197278911564626\n",
      "Epoch: 1836 Avg_loss: 0.9093832790851593 training accuracy: 0.9875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1837 Avg_loss: 0.7884541153907776 training accuracy: 0.996875 test accuracy: 0.3877551020408163\n",
      "Epoch: 1838 Avg_loss: 0.703834342956543 training accuracy: 0.996875 test accuracy: 0.3673469387755102\n",
      "Epoch: 1839 Avg_loss: 0.6393381536006928 training accuracy: 0.996875 test accuracy: 0.35374149659863946\n",
      "Epoch: 1840 Avg_loss: 0.5915814697742462 training accuracy: 0.996875 test accuracy: 0.3741496598639456\n",
      "Epoch: 1841 Avg_loss: 0.5536887526512146 training accuracy: 0.996875 test accuracy: 0.3877551020408163\n",
      "Epoch: 1842 Avg_loss: 0.5900746583938599 training accuracy: 0.996875 test accuracy: 0.38095238095238093\n",
      "Epoch: 1843 Avg_loss: 0.5095029354095459 training accuracy: 1.0 test accuracy: 0.3877551020408163\n",
      "Epoch: 1844 Avg_loss: 0.4610633224248886 training accuracy: 0.996875 test accuracy: 0.3741496598639456\n",
      "Epoch: 1845 Avg_loss: 0.4323076784610748 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1846 Avg_loss: 0.42342009842395784 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1847 Avg_loss: 0.41148374378681185 training accuracy: 1.0 test accuracy: 0.3877551020408163\n",
      "Epoch: 1848 Avg_loss: 0.4154615193605423 training accuracy: 0.996875 test accuracy: 0.36054421768707484\n",
      "Epoch: 1849 Avg_loss: 0.40918912291526793 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1850 Avg_loss: 0.45380258560180664 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1851 Avg_loss: 0.41188582479953767 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1852 Avg_loss: 0.3727089077234268 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1853 Avg_loss: 0.33843042850494387 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1854 Avg_loss: 0.31824620962142947 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1855 Avg_loss: 0.3053868055343628 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1856 Avg_loss: 0.29472708106040957 training accuracy: 1.0 test accuracy: 0.3945578231292517\n",
      "Epoch: 1857 Avg_loss: 0.28498675525188444 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1858 Avg_loss: 0.27809720635414126 training accuracy: 1.0 test accuracy: 0.3877551020408163\n",
      "Epoch: 1859 Avg_loss: 0.2827959507703781 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1860 Avg_loss: 0.27930009067058564 training accuracy: 1.0 test accuracy: 0.3877551020408163\n",
      "Epoch: 1861 Avg_loss: 0.26909062564373015 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1862 Avg_loss: 0.2596255451440811 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1863 Avg_loss: 0.2530018910765648 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1864 Avg_loss: 0.2476455330848694 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1865 Avg_loss: 0.24301383048295974 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1866 Avg_loss: 0.23939180821180345 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1867 Avg_loss: 0.236421574652195 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1868 Avg_loss: 0.23358863294124604 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1869 Avg_loss: 0.23093429654836656 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1870 Avg_loss: 0.22836684584617614 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1871 Avg_loss: 0.22684528529644013 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1872 Avg_loss: 0.22670456320047377 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1873 Avg_loss: 0.2248418614268303 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1874 Avg_loss: 0.2219458192586899 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1875 Avg_loss: 0.2195469930768013 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1876 Avg_loss: 0.21755272001028061 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1877 Avg_loss: 0.21597593426704406 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1878 Avg_loss: 0.21496017426252365 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1879 Avg_loss: 0.2141803339123726 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1880 Avg_loss: 0.212989342212677 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1881 Avg_loss: 0.21143987029790878 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1882 Avg_loss: 0.20991421937942506 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1883 Avg_loss: 0.20886876583099365 training accuracy: 1.0 test accuracy: 0.38095238095238093\n",
      "Epoch: 1884 Avg_loss: 0.20801696479320525 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1885 Avg_loss: 0.20819962173700332 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1886 Avg_loss: 0.20819458663463591 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1887 Avg_loss: 0.20794237405061722 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1888 Avg_loss: 0.20695869773626327 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1889 Avg_loss: 0.2050768956542015 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1890 Avg_loss: 0.2035023644566536 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1891 Avg_loss: 0.2038394808769226 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1892 Avg_loss: 0.20346626341342927 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1893 Avg_loss: 0.20240564942359923 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1894 Avg_loss: 0.20294769555330278 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1895 Avg_loss: 0.202895587682724 training accuracy: 1.0 test accuracy: 0.3741496598639456\n",
      "Epoch: 1896 Avg_loss: 0.2011089116334915 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1897 Avg_loss: 0.19969196021556854 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1898 Avg_loss: 0.1984924465417862 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1899 Avg_loss: 0.19765064716339112 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1900 Avg_loss: 0.1973746031522751 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1901 Avg_loss: 0.19951303899288178 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1902 Avg_loss: 0.2006064236164093 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1903 Avg_loss: 0.19844166487455367 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1904 Avg_loss: 0.19663492143154143 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1905 Avg_loss: 0.19554111063480378 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1906 Avg_loss: 0.1947408691048622 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1907 Avg_loss: 0.19440122395753862 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1908 Avg_loss: 0.1941423997282982 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1909 Avg_loss: 0.19362839460372924 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1910 Avg_loss: 0.19329986423254014 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1911 Avg_loss: 0.19304420948028564 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1912 Avg_loss: 0.19258648604154588 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1913 Avg_loss: 0.19219405949115753 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1914 Avg_loss: 0.192017824947834 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1915 Avg_loss: 0.19163135588169097 training accuracy: 1.0 test accuracy: 0.35374149659863946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1916 Avg_loss: 0.19122399985790253 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1917 Avg_loss: 0.19098006337881088 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1918 Avg_loss: 0.19093565493822098 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1919 Avg_loss: 0.1906801000237465 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1920 Avg_loss: 0.1902298852801323 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1921 Avg_loss: 0.1897297665476799 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1922 Avg_loss: 0.18962065130472183 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1923 Avg_loss: 0.1895664244890213 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1924 Avg_loss: 0.18930122405290603 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1925 Avg_loss: 0.18902253210544587 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1926 Avg_loss: 0.18897931575775145 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1927 Avg_loss: 0.18920782953500748 training accuracy: 1.0 test accuracy: 0.3673469387755102\n",
      "Epoch: 1928 Avg_loss: 0.2026741772890091 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1929 Avg_loss: 0.22461798340082167 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1930 Avg_loss: 0.22336070090532303 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1931 Avg_loss: 0.21217491179704667 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1932 Avg_loss: 0.20259325057268143 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1933 Avg_loss: 0.1962587997317314 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1934 Avg_loss: 0.19267043471336365 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1935 Avg_loss: 0.19014933854341506 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1936 Avg_loss: 0.18848373889923095 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1937 Avg_loss: 0.18787676692008973 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1938 Avg_loss: 0.187165068089962 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1939 Avg_loss: 0.1866269201040268 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1940 Avg_loss: 0.18617465645074843 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1941 Avg_loss: 0.18562417477369308 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1942 Avg_loss: 0.18603774160146713 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1943 Avg_loss: 0.18706384301185608 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1944 Avg_loss: 0.18620453923940658 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1945 Avg_loss: 0.18477967977523804 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1946 Avg_loss: 0.1838671788573265 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1947 Avg_loss: 0.18341346681118012 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1948 Avg_loss: 0.18305444866418838 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1949 Avg_loss: 0.1828566834330559 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1950 Avg_loss: 0.18261444419622422 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1951 Avg_loss: 0.18232616633176804 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1952 Avg_loss: 0.18211384266614913 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1953 Avg_loss: 0.18187799900770188 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1954 Avg_loss: 0.1817921444773674 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1955 Avg_loss: 0.1818898066878319 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1956 Avg_loss: 0.1818208247423172 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1957 Avg_loss: 0.1815129190683365 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1958 Avg_loss: 0.1810249149799347 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1959 Avg_loss: 0.18078590631484986 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1960 Avg_loss: 0.1806371718645096 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1961 Avg_loss: 0.18043471723794938 training accuracy: 1.0 test accuracy: 0.3469387755102041\n",
      "Epoch: 1962 Avg_loss: 0.18055719435214995 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1963 Avg_loss: 0.18101296573877335 training accuracy: 1.0 test accuracy: 0.35374149659863946\n",
      "Epoch: 1964 Avg_loss: 0.18112824708223343 training accuracy: 1.0 test accuracy: 0.36054421768707484\n",
      "Epoch: 1965 Avg_loss: 0.18923542648553848 training accuracy: 0.996875 test accuracy: 0.3945578231292517\n",
      "Epoch: 1966 Avg_loss: 0.5544112026691437 training accuracy: 0.89375 test accuracy: 0.32653061224489793\n",
      "Epoch: 1967 Avg_loss: 0.9820044755935669 training accuracy: 0.85625 test accuracy: 0.32653061224489793\n",
      "Epoch: 1968 Avg_loss: 1.1699760735034943 training accuracy: 0.875 test accuracy: 0.3129251700680272\n",
      "Epoch: 1969 Avg_loss: 1.142199957370758 training accuracy: 0.921875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1970 Avg_loss: 1.0286123156547546 training accuracy: 0.9625 test accuracy: 0.2925170068027211\n",
      "Epoch: 1971 Avg_loss: 0.9521798193454742 training accuracy: 0.98125 test accuracy: 0.2789115646258503\n",
      "Epoch: 1972 Avg_loss: 0.8642637848854064 training accuracy: 0.99375 test accuracy: 0.3401360544217687\n",
      "Epoch: 1973 Avg_loss: 0.8430966675281525 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1974 Avg_loss: 0.7247319698333741 training accuracy: 1.0 test accuracy: 0.3401360544217687\n",
      "Epoch: 1975 Avg_loss: 0.650999253988266 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1976 Avg_loss: 0.6091204941272735 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1977 Avg_loss: 0.5927423477172852 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1978 Avg_loss: 0.5999792754650116 training accuracy: 0.9875 test accuracy: 0.3129251700680272\n",
      "Epoch: 1979 Avg_loss: 0.6198976695537567 training accuracy: 0.990625 test accuracy: 0.3129251700680272\n",
      "Epoch: 1980 Avg_loss: 0.6692638635635376 training accuracy: 0.990625 test accuracy: 0.30612244897959184\n",
      "Epoch: 1981 Avg_loss: 0.6258357644081116 training accuracy: 0.996875 test accuracy: 0.3197278911564626\n",
      "Epoch: 1982 Avg_loss: 0.5805970549583435 training accuracy: 0.996875 test accuracy: 0.32653061224489793\n",
      "Epoch: 1983 Avg_loss: 0.5397997736930847 training accuracy: 0.996875 test accuracy: 0.3401360544217687\n",
      "Epoch: 1984 Avg_loss: 0.5056067436933518 training accuracy: 0.996875 test accuracy: 0.3741496598639456\n",
      "Epoch: 1985 Avg_loss: 0.4647697776556015 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1986 Avg_loss: 0.4357743948698044 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1987 Avg_loss: 0.4101250320672989 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1988 Avg_loss: 0.3878204464912415 training accuracy: 1.0 test accuracy: 0.29931972789115646\n",
      "Epoch: 1989 Avg_loss: 0.3683724790811539 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1990 Avg_loss: 0.35127073228359224 training accuracy: 1.0 test accuracy: 0.3197278911564626\n",
      "Epoch: 1991 Avg_loss: 0.33618213832378385 training accuracy: 1.0 test accuracy: 0.30612244897959184\n",
      "Epoch: 1992 Avg_loss: 0.32291664481163024 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1993 Avg_loss: 0.3110883623361588 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1994 Avg_loss: 0.30056101977825167 training accuracy: 1.0 test accuracy: 0.3129251700680272\n",
      "Epoch: 1995 Avg_loss: 0.29117265343666077 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1996 Avg_loss: 0.2826003223657608 training accuracy: 1.0 test accuracy: 0.32653061224489793\n",
      "Epoch: 1997 Avg_loss: 0.2749261289834976 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "Epoch: 1998 Avg_loss: 0.26809526681900026 training accuracy: 1.0 test accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1999 Avg_loss: 0.2616805136203766 training accuracy: 1.0 test accuracy: 0.3333333333333333\n",
      "best accuracy: 0.4013605442176871\n"
     ]
    }
   ],
   "source": [
    "model1, best_state1, best_acc1, loss1, acc1 = train_model(training_data, training_labels,\n",
    "                                                             test_data, test_labels, 2000, 64, 16,\n",
    "                                                             lr=0.0005, lamb=0.01, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-bradford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Avg_loss: 1.8151039753109217 training accuracy: 0.221875 test accuracy: 0.22448979591836735\n",
      "Epoch: 1 Avg_loss: 1.4822997376322746 training accuracy: 0.253125 test accuracy: 0.38095238095238093\n",
      "Epoch: 2 Avg_loss: 1.449833869561553 training accuracy: 0.265625 test accuracy: 0.29931972789115646\n",
      "Epoch: 3 Avg_loss: 1.424248882383108 training accuracy: 0.253125 test accuracy: 0.23129251700680273\n",
      "Epoch: 4 Avg_loss: 1.521490865200758 training accuracy: 0.234375 test accuracy: 0.2108843537414966\n",
      "Epoch: 5 Avg_loss: 1.4311349954456092 training accuracy: 0.259375 test accuracy: 0.22448979591836735\n",
      "Epoch: 6 Avg_loss: 1.411452055722475 training accuracy: 0.253125 test accuracy: 0.2108843537414966\n",
      "Epoch: 7 Avg_loss: 1.4431085471063851 training accuracy: 0.278125 test accuracy: 0.35374149659863946\n",
      "Epoch: 8 Avg_loss: 1.5208096001297235 training accuracy: 0.2375 test accuracy: 0.2789115646258503\n",
      "Epoch: 9 Avg_loss: 1.4246196579188108 training accuracy: 0.234375 test accuracy: 0.24489795918367346\n",
      "Epoch: 10 Avg_loss: 1.397835822030902 training accuracy: 0.240625 test accuracy: 0.22448979591836735\n",
      "Epoch: 11 Avg_loss: 1.3930417690426111 training accuracy: 0.25 test accuracy: 0.21768707482993196\n",
      "Epoch: 12 Avg_loss: 1.4343430627137423 training accuracy: 0.240625 test accuracy: 0.2585034013605442\n",
      "Epoch: 13 Avg_loss: 1.4231371391564607 training accuracy: 0.25 test accuracy: 0.3129251700680272\n",
      "Epoch: 14 Avg_loss: 1.4046787686645985 training accuracy: 0.234375 test accuracy: 0.22448979591836735\n",
      "Epoch: 15 Avg_loss: 1.4227839414030314 training accuracy: 0.25625 test accuracy: 0.32653061224489793\n",
      "Epoch: 16 Avg_loss: 1.3932822212576865 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 17 Avg_loss: 1.3890392113476993 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 18 Avg_loss: 1.3879736308008432 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 19 Avg_loss: 1.3874163638800383 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 20 Avg_loss: 1.3871055290102958 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 21 Avg_loss: 1.3869006458669901 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 22 Avg_loss: 1.3867776948958634 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 23 Avg_loss: 1.386693850159645 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 24 Avg_loss: 1.3868022322654725 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 25 Avg_loss: 1.3865925785154105 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 26 Avg_loss: 1.3865595441311598 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 27 Avg_loss: 1.3865337532013655 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 28 Avg_loss: 1.3865138344466685 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 29 Avg_loss: 1.3864973235875369 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 30 Avg_loss: 1.3864836663007736 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 31 Avg_loss: 1.3864719927310944 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 32 Avg_loss: 1.3864628572016955 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 33 Avg_loss: 1.3864564836025237 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 34 Avg_loss: 1.3864502225071191 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 35 Avg_loss: 1.3866521421819926 training accuracy: 0.23125 test accuracy: 0.32653061224489793\n",
      "Epoch: 36 Avg_loss: 1.3865154094994068 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 37 Avg_loss: 1.3864493530243636 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 38 Avg_loss: 1.3864482525736093 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 39 Avg_loss: 1.3864498414099216 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 40 Avg_loss: 1.386448036134243 training accuracy: 0.25 test accuracy: 0.32653061224489793\n",
      "Epoch: 41 Avg_loss: 1.3864496797323227 training accuracy: 0.25 test accuracy: 0.32653061224489793\n"
     ]
    }
   ],
   "source": [
    "model1, best_state1, best_acc1, loss1, acc1 = train_model(training_data, training_labels,\n",
    "                                                             test_data, test_labels, 2000, 128, 32,\n",
    "                                                             lr=0.0005, lamb=0.005, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-syntax",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
